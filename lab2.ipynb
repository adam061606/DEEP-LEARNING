{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Hello World \n",
    "import tensorflow as tf \n",
    "#sess = tf.Session() \n",
    "# This is only needed for TF 1.X \n",
    "# Computational Graph to be compiled and then run using the session \n",
    "a = tf.constant(10) \n",
    "b = tf.constant(32) \n",
    "# print(sess.run(a+b))  # Not session.run not needed in TF2.X\n",
    "# In TF2.X eager execution compiles the computation graph in the background print(a+b) \n",
    "# TF 2.X is more direct. Just write a+b \n",
    "print(a)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Keras Hello World \n",
    "from keras.models  import Sequential \n",
    "from keras.layers import Dense \n",
    "# create model \n",
    "model = Sequential() \n",
    "model.add(Dense(12, input_dim=8, activation='relu')) # first layer has 12 neurons and expects 8 input variables\n",
    "model.add(Dense(8, activation='relu')) # second hidden layer has 8 neurons\n",
    "# Compile model \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_152 (Dense)           (None, 12)                108       \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 8)                 104       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212\n",
      "Trainable params: 212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.9140098], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n",
      "W: [-0.4434941], b: [0.7834802]\n",
      "W: [-0.02686788], b: [0.36551723]\n",
      "W: [0.07429572], b: [0.31327423]\n",
      "W: [0.09479214], b: [0.30268946]\n",
      "W: [0.09894486], b: [0.30054492]\n",
      "W: [0.09978624], b: [0.3001104]\n",
      "W: [0.0999567], b: [0.30002236]\n",
      "W: [0.09999123], b: [0.30000454]\n",
      "W: [0.09999824], b: [0.30000094]\n",
      "W: [0.09999964], b: [0.3000002]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np   \n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3 \n",
    "x_data = np.random.rand(100).astype(np.float32) \n",
    "y_data = x_data * 0.1 + 0.3   \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_data, y_data)\n",
    "plt.show()\n",
    "\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b \n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will figure that out for us.) \n",
    "W = tf.Variable(tf.random.uniform(shape=(1,), minval=-1.0, maxval=1.0)) \n",
    "b = tf.Variable(tf.zeros(shape=(1,))) \n",
    "\n",
    "print(W)\n",
    "print(b)\n",
    "\n",
    "# Minimize the mean squared errors. \n",
    "def cost():     \n",
    "    y = W * x_data + b     \n",
    "    loss = tf.reduce_mean(tf.square(y - y_data))     \n",
    "    return loss \n",
    "\n",
    "# SGD is the equivalent for GradientDescentOptimizer\n",
    "optimizer = tf.optimizers.SGD(0.5)  \n",
    "\n",
    "for e in range(200):     \n",
    "    optimizer.minimize(cost, var_list=[W, b])     \n",
    "    if e % 20 == 0:         \n",
    "        print(f'W: {W.numpy()}, b: {b.numpy()}')  \n",
    "        \n",
    "# Learns best fit is W: [0.1], b: [0.3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "# create model \n",
    "model = Sequential([ \n",
    "        Dense(12, input_dim=8, activation='relu'), \n",
    "        Dense(8, activation='relu'),             \n",
    "        Dense(1, activation='sigmoid') \n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris two class dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Keras version of Iris classifier \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn import model_selection \n",
    "from sklearn import preprocessing \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# loading and pre-processing of the data \n",
    "# We use the 2 class version of iris data set \n",
    "iris = pd.read_csv(\"IrisTwoClass.csv\") \n",
    "x = np.array(iris.drop(\"Class\",axis=1)) \n",
    "y = np.array(iris[\"Class\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "[[6.3 2.9 5.6 1.8]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.  2.2 5.  1.5]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.5 3.  5.8 2.2]]\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1\n",
      " 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4)\n",
      "(20, 4)\n",
      "(80,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train / test \n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=42) \n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# Scale data (training set) to 0 mean and unit standard deviation. \n",
    "scaler = preprocessing.StandardScaler() \n",
    "x_train = scaler.fit_transform(x_train) \n",
    "x_test = scaler.fit_transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72103295 -1.03004748  1.08200425  1.10481261]\n",
      " [ 1.16135842 -0.54245104  1.03321037  1.10481261]\n",
      " [-0.37978071  0.43274184 -0.91854476 -0.76402464]\n",
      " [ 1.27143978 -0.0548546   1.13079813  1.32467581]\n",
      " [-1.04026891 -0.29865282 -0.86975088 -0.98388784]\n",
      " [-1.04026891 -0.54245104 -0.96733864 -0.87395624]\n",
      " [ 2.15209071 -0.54245104  1.32597364  1.32467581]\n",
      " [-0.59994345  2.13932938 -0.91854476 -1.09381945]\n",
      " [ 0.39078885 -1.51764392  1.08200425  0.33529139]\n",
      " [ 0.17062612 -0.54245104  0.83803486  0.7750178 ]\n",
      " [ 0.28070748 -2.4928368   0.78924098  0.44522299]\n",
      " [-0.82010618 -0.54245104 -0.86975088 -0.98388784]\n",
      " [-1.37051301 -2.24903858 -1.01613251 -0.87395624]\n",
      " [ 0.61095158 -1.76144214  0.78924098  0.8849494 ]\n",
      " [ 0.50087022 -1.03004748  0.69165322  0.7750178 ]\n",
      " [-0.93018755  0.92033828 -0.96733864 -1.09381945]\n",
      " [-0.82010618  0.43274184 -0.91854476 -0.98388784]\n",
      " [-0.71002481  0.18894362 -0.820957   -0.65409304]\n",
      " [ 0.50087022  0.43274184  0.98441649  1.32467581]\n",
      " [-0.71002481  1.1641365  -0.91854476 -0.76402464]\n",
      " [ 0.61095158 -1.2738457   0.7404471   0.7750178 ]\n",
      " [-1.04026891  0.43274184 -0.72336924 -0.98388784]\n",
      " [-0.48986208  1.1641365  -0.91854476 -0.98388784]\n",
      " [ 0.83111432 -0.54245104  0.88682874  0.994881  ]\n",
      " [-0.04953661 -1.76144214  0.78924098  0.994881  ]\n",
      " [ 2.04200935 -0.54245104  1.56994303  1.10481261]\n",
      " [ 0.83111432 -0.54245104  1.03321037  0.7750178 ]\n",
      " [ 1.49160252 -0.54245104  1.22838588  1.10481261]\n",
      " [-0.37978071  1.1641365  -0.91854476 -0.98388784]\n",
      " [-0.37978071  1.65173294 -1.01613251 -0.76402464]\n",
      " [-1.59067575 -0.54245104 -1.11372027 -1.09381945]\n",
      " [-0.59994345  0.43274184 -0.96733864 -0.98388784]\n",
      " [-0.71002481  1.40793472 -0.86975088 -0.98388784]\n",
      " [-1.15035028 -0.0548546  -0.86975088 -0.98388784]\n",
      " [ 0.72103295 -0.29865282  1.03321037  0.7750178 ]\n",
      " [-0.04953661  1.40793472 -0.820957   -0.87395624]\n",
      " [-0.26969935  0.67654006 -1.01613251 -0.98388784]\n",
      " [ 0.61095158 -1.03004748  0.83803486  0.44522299]\n",
      " [-0.71002481  0.67654006 -0.96733864 -0.98388784]\n",
      " [-0.37978071  1.65173294 -0.820957   -0.76402464]\n",
      " [ 1.60168388  0.92033828  1.32597364  1.54453902]\n",
      " [ 0.83111432 -0.54245104  1.17959201  1.21474421]\n",
      " [-0.82010618  0.67654006 -0.86975088 -0.54416143]\n",
      " [ 0.06054475  1.89553116 -1.06492639 -0.98388784]\n",
      " [ 0.61095158  0.18894362  1.27717976  1.54453902]\n",
      " [-0.82010618  0.92033828 -0.96733864 -0.98388784]\n",
      " [-1.48059438 -0.0548546  -1.01613251 -0.98388784]\n",
      " [-0.71002481  1.40793472 -0.72336924 -0.76402464]\n",
      " [-1.04026891 -0.54245104 -0.96733864 -1.09381945]\n",
      " [ 1.05127705 -0.54245104  0.88682874  1.32467581]\n",
      " [-0.82010618  0.67654006 -1.01613251 -0.87395624]\n",
      " [ 2.37225345  1.40793472  1.47235527  0.994881  ]\n",
      " [-1.48059438 -0.78624926 -0.96733864 -0.98388784]\n",
      " [-1.26043165  0.92033828 -1.16251415 -0.98388784]\n",
      " [-0.26969935  2.3831276  -0.96733864 -0.98388784]\n",
      " [ 0.06054475 -1.03004748  0.83803486  1.43460741]\n",
      " [ 1.27143978 -0.29865282  0.98441649  1.10481261]\n",
      " [ 0.61095158  0.43274184  1.08200425  1.43460741]\n",
      " [-0.82010618  0.43274184 -0.86975088 -0.76402464]\n",
      " [ 1.27143978 -0.29865282  0.83803486  1.32467581]\n",
      " [-1.15035028 -0.0548546  -1.01613251 -0.98388784]\n",
      " [ 1.05127705 -1.76144214  1.17959201  0.7750178 ]\n",
      " [ 1.82184661 -1.03004748  1.32597364  0.8849494 ]\n",
      " [ 0.39078885 -0.54245104  0.7404471   0.7750178 ]\n",
      " [-1.04026891  0.43274184 -0.86975088 -0.98388784]\n",
      " [-0.15961798 -1.03004748  0.7404471   0.994881  ]\n",
      " [-1.26043165  0.43274184 -0.96733864 -0.87395624]\n",
      " [ 1.60168388 -0.0548546   1.27717976  0.7750178 ]\n",
      " [ 0.72103295 -1.03004748  1.08200425  1.21474421]\n",
      " [ 1.16135842 -0.0548546   1.22838588  1.32467581]\n",
      " [-1.26043165 -0.29865282 -0.91854476 -0.98388784]\n",
      " [ 1.60168388 -0.54245104  1.17959201  0.55515459]\n",
      " [-0.82010618 -0.0548546  -1.06492639 -0.98388784]\n",
      " [-0.71002481  0.67654006 -0.96733864 -0.87395624]\n",
      " [-1.26043165 -0.0548546  -0.96733864 -0.98388784]\n",
      " [ 0.72103295 -0.0548546   0.93562261  1.32467581]\n",
      " [ 1.05127705  0.18894362  1.13079813  1.10481261]\n",
      " [ 0.06054475 -1.2738457   0.83803486  0.8849494 ]\n",
      " [-0.71002481  0.43274184 -0.91854476 -0.98388784]\n",
      " [-0.71002481  1.40793472 -0.91854476 -0.87395624]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model using keras hypertuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamt\\AppData\\Local\\Temp\\ipykernel_26256\\3752203788.py:24: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 252ms/step - loss: 0.7552 - accuracy: 0.5660 - val_loss: 0.7611 - val_accuracy: 0.4000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7390 - accuracy: 0.5660 - val_loss: 0.7455 - val_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7225 - accuracy: 0.5660 - val_loss: 0.7306 - val_accuracy: 0.4000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7074 - accuracy: 0.5660 - val_loss: 0.7162 - val_accuracy: 0.4000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6926 - accuracy: 0.5660 - val_loss: 0.7030 - val_accuracy: 0.4000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6785 - accuracy: 0.5660 - val_loss: 0.6902 - val_accuracy: 0.4000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6651 - accuracy: 0.5660 - val_loss: 0.6778 - val_accuracy: 0.4000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6521 - accuracy: 0.5660 - val_loss: 0.6664 - val_accuracy: 0.4000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6402 - accuracy: 0.5660 - val_loss: 0.6559 - val_accuracy: 0.4000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6289 - accuracy: 0.5660 - val_loss: 0.6461 - val_accuracy: 0.4500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6183 - accuracy: 0.5660 - val_loss: 0.6365 - val_accuracy: 0.6000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6079 - accuracy: 0.6981 - val_loss: 0.6273 - val_accuracy: 0.6000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5978 - accuracy: 0.7925 - val_loss: 0.6183 - val_accuracy: 0.6500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5878 - accuracy: 0.8113 - val_loss: 0.6092 - val_accuracy: 0.7000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5779 - accuracy: 0.8679 - val_loss: 0.6004 - val_accuracy: 0.8500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5681 - accuracy: 0.9057 - val_loss: 0.5916 - val_accuracy: 0.8500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5584 - accuracy: 0.9057 - val_loss: 0.5830 - val_accuracy: 0.9000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5488 - accuracy: 0.9057 - val_loss: 0.5747 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5395 - accuracy: 0.9245 - val_loss: 0.5665 - val_accuracy: 0.9000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5297 - accuracy: 0.9434 - val_loss: 0.5581 - val_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5670 - accuracy: 0.8889\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 242ms/step - loss: 0.6468 - accuracy: 0.5660 - val_loss: 0.6513 - val_accuracy: 0.6000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6340 - accuracy: 0.5660 - val_loss: 0.6391 - val_accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6216 - accuracy: 0.5660 - val_loss: 0.6282 - val_accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6099 - accuracy: 0.5660 - val_loss: 0.6175 - val_accuracy: 0.6500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5980 - accuracy: 0.5849 - val_loss: 0.6072 - val_accuracy: 0.6500\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5868 - accuracy: 0.6415 - val_loss: 0.5972 - val_accuracy: 0.6500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5760 - accuracy: 0.6604 - val_loss: 0.5871 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5657 - accuracy: 0.7170 - val_loss: 0.5771 - val_accuracy: 0.7500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5557 - accuracy: 0.7925 - val_loss: 0.5673 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5459 - accuracy: 0.8491 - val_loss: 0.5574 - val_accuracy: 0.8500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5361 - accuracy: 0.8679 - val_loss: 0.5477 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5265 - accuracy: 0.8679 - val_loss: 0.5380 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5167 - accuracy: 0.9057 - val_loss: 0.5281 - val_accuracy: 0.9500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5065 - accuracy: 0.9245 - val_loss: 0.5183 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4960 - accuracy: 0.9434 - val_loss: 0.5078 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4851 - accuracy: 0.9434 - val_loss: 0.4962 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4736 - accuracy: 0.9811 - val_loss: 0.4845 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4616 - accuracy: 0.9811 - val_loss: 0.4721 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4489 - accuracy: 0.9811 - val_loss: 0.4590 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4348 - accuracy: 0.9811 - val_loss: 0.4449 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4755 - accuracy: 1.0000\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 248ms/step - loss: 0.6500 - accuracy: 0.9259 - val_loss: 0.6428 - val_accuracy: 0.8500\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6411 - accuracy: 0.9259 - val_loss: 0.6357 - val_accuracy: 0.8500\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6327 - accuracy: 0.9444 - val_loss: 0.6287 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6240 - accuracy: 0.9630 - val_loss: 0.6217 - val_accuracy: 0.8500\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6157 - accuracy: 0.9630 - val_loss: 0.6148 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6071 - accuracy: 0.9815 - val_loss: 0.6077 - val_accuracy: 0.9500\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5989 - accuracy: 1.0000 - val_loss: 0.6008 - val_accuracy: 0.9500\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5906 - accuracy: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.9500\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5821 - accuracy: 1.0000 - val_loss: 0.5866 - val_accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5737 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.9500\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5652 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.9500\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5563 - accuracy: 1.0000 - val_loss: 0.5643 - val_accuracy: 0.9500\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5471 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.9500\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5375 - accuracy: 1.0000 - val_loss: 0.5483 - val_accuracy: 0.9500\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5274 - accuracy: 1.0000 - val_loss: 0.5400 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5173 - accuracy: 1.0000 - val_loss: 0.5315 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5065 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4952 - accuracy: 1.0000 - val_loss: 0.5136 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4834 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4710 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4709 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 857ms/step - loss: 1.2514 - accuracy: 0.0000e+00 - val_loss: 1.1723 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.2287 - accuracy: 0.0000e+00 - val_loss: 1.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.2062 - accuracy: 0.0000e+00 - val_loss: 1.1361 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.1839 - accuracy: 0.0000e+00 - val_loss: 1.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.1615 - accuracy: 0.0000e+00 - val_loss: 1.1002 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1395 - accuracy: 0.0000e+00 - val_loss: 1.0826 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 1.1177 - accuracy: 0.0000e+00 - val_loss: 1.0651 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0960 - accuracy: 0.0000e+00 - val_loss: 1.0476 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0744 - accuracy: 0.0000e+00 - val_loss: 1.0303 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0531 - accuracy: 0.0000e+00 - val_loss: 1.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0320 - accuracy: 0.0000e+00 - val_loss: 0.9964 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 1.0112 - accuracy: 0.0000e+00 - val_loss: 0.9797 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.9905 - accuracy: 0.0000e+00 - val_loss: 0.9631 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.9700 - accuracy: 0.0000e+00 - val_loss: 0.9465 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.9496 - accuracy: 0.0000e+00 - val_loss: 0.9303 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9297 - accuracy: 0.0000e+00 - val_loss: 0.9142 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.9099 - accuracy: 0.0000e+00 - val_loss: 0.8985 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8905 - accuracy: 0.0000e+00 - val_loss: 0.8830 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8715 - accuracy: 0.0000e+00 - val_loss: 0.8676 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.8525 - accuracy: 0.0000e+00 - val_loss: 0.8523 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8337 - accuracy: 0.0000e+00 - val_loss: 0.8375 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.8155 - accuracy: 0.0000e+00 - val_loss: 0.8227 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7974 - accuracy: 0.0000e+00 - val_loss: 0.8080 - val_accuracy: 0.0500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7795 - accuracy: 0.1132 - val_loss: 0.7938 - val_accuracy: 0.2500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.7621 - accuracy: 0.3585 - val_loss: 0.7797 - val_accuracy: 0.3500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7448 - accuracy: 0.4717 - val_loss: 0.7659 - val_accuracy: 0.3500\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7279 - accuracy: 0.5472 - val_loss: 0.7522 - val_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7113 - accuracy: 0.5660 - val_loss: 0.7388 - val_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6949 - accuracy: 0.5849 - val_loss: 0.7256 - val_accuracy: 0.4500\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6789 - accuracy: 0.6415 - val_loss: 0.7124 - val_accuracy: 0.6000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6629 - accuracy: 0.6415 - val_loss: 0.6997 - val_accuracy: 0.6000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6475 - accuracy: 0.6792 - val_loss: 0.6870 - val_accuracy: 0.6000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6323 - accuracy: 0.6792 - val_loss: 0.6746 - val_accuracy: 0.6000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6174 - accuracy: 0.6981 - val_loss: 0.6624 - val_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6028 - accuracy: 0.7547 - val_loss: 0.6504 - val_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5885 - accuracy: 0.8113 - val_loss: 0.6384 - val_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5743 - accuracy: 0.8302 - val_loss: 0.6268 - val_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5606 - accuracy: 0.8302 - val_loss: 0.6154 - val_accuracy: 0.6500\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5471 - accuracy: 0.8868 - val_loss: 0.6040 - val_accuracy: 0.6500\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5338 - accuracy: 0.8868 - val_loss: 0.5930 - val_accuracy: 0.6500\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5209 - accuracy: 0.9434 - val_loss: 0.5820 - val_accuracy: 0.6500\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5082 - accuracy: 0.9434 - val_loss: 0.5711 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4957 - accuracy: 0.9434 - val_loss: 0.5604 - val_accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4834 - accuracy: 0.9623 - val_loss: 0.5499 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4716 - accuracy: 0.9623 - val_loss: 0.5396 - val_accuracy: 0.8500\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4599 - accuracy: 0.9623 - val_loss: 0.5294 - val_accuracy: 0.8500\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4484 - accuracy: 0.9623 - val_loss: 0.5194 - val_accuracy: 0.8500\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4372 - accuracy: 0.9811 - val_loss: 0.5095 - val_accuracy: 0.8500\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4264 - accuracy: 0.9811 - val_loss: 0.4998 - val_accuracy: 0.8500\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4156 - accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.8500\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4053 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.8500\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3951 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.8500\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3851 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.8500\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3755 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.8500\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3660 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.8500\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3568 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.9000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3479 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9500\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3391 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9500\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3306 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3223 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9500\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3142 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9500\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3064 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9500\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2988 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.9500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2913 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9500\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2841 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2771 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9500\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2703 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2637 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.9500\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2573 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9500\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2511 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2450 - accuracy: 1.0000 - val_loss: 0.3277 - val_accuracy: 0.9500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2392 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9500\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2336 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9500\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2281 - accuracy: 1.0000 - val_loss: 0.3102 - val_accuracy: 0.9500\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2227 - accuracy: 1.0000 - val_loss: 0.3047 - val_accuracy: 0.9500\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2175 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9500\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2125 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 0.9500\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2077 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2030 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9500\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1984 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9500\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1940 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9500\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1897 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9500\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1856 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9500\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1816 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.9500\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1777 - accuracy: 1.0000 - val_loss: 0.2568 - val_accuracy: 0.9500\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1739 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1703 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9500\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1668 - accuracy: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9500\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1634 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9500\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1601 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 0.9500\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1569 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9500\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1538 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9500\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1509 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9500\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1479 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9500\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1451 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9500\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1424 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9500\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1398 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9500\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1372 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9500\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1348 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9500\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1324 - accuracy: 1.0000 - val_loss: 0.2063 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1407 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 835ms/step - loss: 0.6188 - accuracy: 0.9245 - val_loss: 0.5924 - val_accuracy: 0.9000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6025 - accuracy: 0.9623 - val_loss: 0.5771 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5865 - accuracy: 0.9811 - val_loss: 0.5622 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5709 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5556 - accuracy: 1.0000 - val_loss: 0.5332 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5406 - accuracy: 1.0000 - val_loss: 0.5192 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5260 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5119 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4980 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4845 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4714 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4587 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4464 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4343 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4226 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4111 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4001 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3895 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3790 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3688 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3590 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3493 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3400 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3311 - accuracy: 1.0000 - val_loss: 0.3252 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3222 - accuracy: 1.0000 - val_loss: 0.3170 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3136 - accuracy: 1.0000 - val_loss: 0.3093 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3053 - accuracy: 1.0000 - val_loss: 0.3016 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2972 - accuracy: 1.0000 - val_loss: 0.2942 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2893 - accuracy: 1.0000 - val_loss: 0.2869 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2815 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2741 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2668 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2598 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2530 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2464 - accuracy: 1.0000 - val_loss: 0.2477 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2399 - accuracy: 1.0000 - val_loss: 0.2418 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2336 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2276 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2217 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2159 - accuracy: 1.0000 - val_loss: 0.2197 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2103 - accuracy: 1.0000 - val_loss: 0.2146 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2049 - accuracy: 1.0000 - val_loss: 0.2096 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1997 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1946 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1897 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1848 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1802 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1757 - accuracy: 1.0000 - val_loss: 0.1823 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1713 - accuracy: 1.0000 - val_loss: 0.1782 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1671 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1629 - accuracy: 1.0000 - val_loss: 0.1703 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1589 - accuracy: 1.0000 - val_loss: 0.1666 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1551 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1513 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1477 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1442 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1408 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1374 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1342 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1311 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1252 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1195 - accuracy: 1.0000 - val_loss: 0.1286 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1169 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1143 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1118 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1069 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1003 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0982 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0962 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0942 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0886 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0760 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0607 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.7804 - accuracy: 0.0926 - val_loss: 0.7766 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7612 - accuracy: 0.2037 - val_loss: 0.7602 - val_accuracy: 0.2000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7423 - accuracy: 0.2963 - val_loss: 0.7440 - val_accuracy: 0.3000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7236 - accuracy: 0.4074 - val_loss: 0.7280 - val_accuracy: 0.3500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7052 - accuracy: 0.5000 - val_loss: 0.7122 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6871 - accuracy: 0.6296 - val_loss: 0.6968 - val_accuracy: 0.5500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6694 - accuracy: 0.7222 - val_loss: 0.6817 - val_accuracy: 0.6500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6521 - accuracy: 0.7593 - val_loss: 0.6668 - val_accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6351 - accuracy: 0.8148 - val_loss: 0.6522 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6184 - accuracy: 0.8519 - val_loss: 0.6380 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6022 - accuracy: 0.8889 - val_loss: 0.6240 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5863 - accuracy: 0.9074 - val_loss: 0.6103 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5707 - accuracy: 0.9074 - val_loss: 0.5970 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5556 - accuracy: 0.9074 - val_loss: 0.5839 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5408 - accuracy: 0.9259 - val_loss: 0.5711 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5264 - accuracy: 0.9630 - val_loss: 0.5586 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5123 - accuracy: 0.9630 - val_loss: 0.5465 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4987 - accuracy: 0.9630 - val_loss: 0.5347 - val_accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4854 - accuracy: 0.9630 - val_loss: 0.5230 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4723 - accuracy: 0.9630 - val_loss: 0.5116 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4596 - accuracy: 0.9815 - val_loss: 0.5005 - val_accuracy: 0.9500\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4473 - accuracy: 0.9815 - val_loss: 0.4897 - val_accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4353 - accuracy: 0.9815 - val_loss: 0.4791 - val_accuracy: 0.9500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4235 - accuracy: 0.9815 - val_loss: 0.4688 - val_accuracy: 0.9500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4123 - accuracy: 0.9815 - val_loss: 0.4587 - val_accuracy: 0.9500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4012 - accuracy: 0.9815 - val_loss: 0.4487 - val_accuracy: 0.9500\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3904 - accuracy: 0.9815 - val_loss: 0.4391 - val_accuracy: 0.9500\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3799 - accuracy: 0.9815 - val_loss: 0.4296 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3698 - accuracy: 0.9815 - val_loss: 0.4203 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3599 - accuracy: 0.9815 - val_loss: 0.4114 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3503 - accuracy: 0.9815 - val_loss: 0.4026 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3411 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3319 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3232 - accuracy: 1.0000 - val_loss: 0.3771 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3146 - accuracy: 1.0000 - val_loss: 0.3691 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3063 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2982 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2904 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2828 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2754 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2683 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2613 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2546 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2481 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2418 - accuracy: 1.0000 - val_loss: 0.2976 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2357 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2298 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2241 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.2737 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2130 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2078 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2028 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1979 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1932 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1886 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1841 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1799 - accuracy: 1.0000 - val_loss: 0.2329 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1757 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1717 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1678 - accuracy: 1.0000 - val_loss: 0.2198 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1640 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1603 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1569 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1534 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1501 - accuracy: 1.0000 - val_loss: 0.2005 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1469 - accuracy: 1.0000 - val_loss: 0.1969 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1438 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1408 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1379 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1350 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1296 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1271 - accuracy: 1.0000 - val_loss: 0.1749 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1246 - accuracy: 1.0000 - val_loss: 0.1721 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1222 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1199 - accuracy: 1.0000 - val_loss: 0.1668 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1155 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1113 - accuracy: 1.0000 - val_loss: 0.1570 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1093 - accuracy: 1.0000 - val_loss: 0.1548 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.1526 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1055 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1037 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1019 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0969 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0954 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0924 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0909 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0868 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0807 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0802 - accuracy: 1.0000\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 1s 246ms/step - loss: 0.6943 - accuracy: 0.5660 - val_loss: 0.7062 - val_accuracy: 0.4000\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6929 - accuracy: 0.5660 - val_loss: 0.7081 - val_accuracy: 0.4000\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6912 - accuracy: 0.5660 - val_loss: 0.7093 - val_accuracy: 0.4000\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6901 - accuracy: 0.5660 - val_loss: 0.7104 - val_accuracy: 0.4000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6897 - accuracy: 0.5660 - val_loss: 0.7120 - val_accuracy: 0.4000\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6885 - accuracy: 0.5660 - val_loss: 0.7133 - val_accuracy: 0.4000\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6877 - accuracy: 0.5660 - val_loss: 0.7145 - val_accuracy: 0.4000\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6870 - accuracy: 0.5660 - val_loss: 0.7155 - val_accuracy: 0.4000\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6860 - accuracy: 0.5660 - val_loss: 0.7161 - val_accuracy: 0.4000\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6853 - accuracy: 0.5660 - val_loss: 0.7168 - val_accuracy: 0.4000\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6848 - accuracy: 0.5660 - val_loss: 0.7179 - val_accuracy: 0.4000\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6842 - accuracy: 0.5660 - val_loss: 0.7189 - val_accuracy: 0.4000\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6840 - accuracy: 0.5660 - val_loss: 0.7199 - val_accuracy: 0.4000\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6831 - accuracy: 0.5660 - val_loss: 0.7202 - val_accuracy: 0.4000\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6824 - accuracy: 0.5660 - val_loss: 0.7202 - val_accuracy: 0.4000\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6818 - accuracy: 0.5660 - val_loss: 0.7204 - val_accuracy: 0.4000\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6816 - accuracy: 0.5660 - val_loss: 0.7207 - val_accuracy: 0.4000\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6808 - accuracy: 0.5660 - val_loss: 0.7206 - val_accuracy: 0.4000\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6803 - accuracy: 0.5660 - val_loss: 0.7203 - val_accuracy: 0.4000\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6797 - accuracy: 0.5660 - val_loss: 0.7199 - val_accuracy: 0.4000\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6794 - accuracy: 0.5660 - val_loss: 0.7198 - val_accuracy: 0.4000\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6786 - accuracy: 0.5660 - val_loss: 0.7191 - val_accuracy: 0.4000\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6781 - accuracy: 0.5660 - val_loss: 0.7187 - val_accuracy: 0.4000\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6775 - accuracy: 0.5660 - val_loss: 0.7181 - val_accuracy: 0.4000\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6769 - accuracy: 0.5660 - val_loss: 0.7177 - val_accuracy: 0.4000\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6763 - accuracy: 0.5660 - val_loss: 0.7175 - val_accuracy: 0.4000\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6757 - accuracy: 0.5660 - val_loss: 0.7173 - val_accuracy: 0.4000\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6752 - accuracy: 0.5660 - val_loss: 0.7168 - val_accuracy: 0.4000\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6745 - accuracy: 0.5660 - val_loss: 0.7166 - val_accuracy: 0.4000\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6737 - accuracy: 0.5660 - val_loss: 0.7169 - val_accuracy: 0.4000\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6731 - accuracy: 0.5660 - val_loss: 0.7172 - val_accuracy: 0.4000\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6727 - accuracy: 0.5660 - val_loss: 0.7175 - val_accuracy: 0.4000\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6719 - accuracy: 0.5660 - val_loss: 0.7173 - val_accuracy: 0.4000\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6712 - accuracy: 0.5660 - val_loss: 0.7169 - val_accuracy: 0.4000\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6705 - accuracy: 0.5660 - val_loss: 0.7167 - val_accuracy: 0.4000\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6699 - accuracy: 0.5660 - val_loss: 0.7167 - val_accuracy: 0.4000\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6692 - accuracy: 0.5660 - val_loss: 0.7163 - val_accuracy: 0.4000\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6684 - accuracy: 0.5660 - val_loss: 0.7155 - val_accuracy: 0.4000\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6676 - accuracy: 0.5660 - val_loss: 0.7148 - val_accuracy: 0.4000\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6668 - accuracy: 0.5660 - val_loss: 0.7137 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7012 - accuracy: 0.4444\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 1s 247ms/step - loss: 0.7717 - accuracy: 0.5660 - val_loss: 0.7283 - val_accuracy: 0.6000\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7661 - accuracy: 0.5660 - val_loss: 0.7236 - val_accuracy: 0.6000\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7604 - accuracy: 0.5660 - val_loss: 0.7191 - val_accuracy: 0.6000\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7550 - accuracy: 0.5660 - val_loss: 0.7148 - val_accuracy: 0.6000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7494 - accuracy: 0.5660 - val_loss: 0.7107 - val_accuracy: 0.6000\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7449 - accuracy: 0.5660 - val_loss: 0.7067 - val_accuracy: 0.6000\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7393 - accuracy: 0.5660 - val_loss: 0.7031 - val_accuracy: 0.6000\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7350 - accuracy: 0.5660 - val_loss: 0.6996 - val_accuracy: 0.6000\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7302 - accuracy: 0.5660 - val_loss: 0.6963 - val_accuracy: 0.6000\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7273 - accuracy: 0.5660 - val_loss: 0.6932 - val_accuracy: 0.6000\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7224 - accuracy: 0.5660 - val_loss: 0.6904 - val_accuracy: 0.6000\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7194 - accuracy: 0.5660 - val_loss: 0.6877 - val_accuracy: 0.6000\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7155 - accuracy: 0.5660 - val_loss: 0.6852 - val_accuracy: 0.6000\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7122 - accuracy: 0.5660 - val_loss: 0.6828 - val_accuracy: 0.6000\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7091 - accuracy: 0.5660 - val_loss: 0.6806 - val_accuracy: 0.6000\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7065 - accuracy: 0.5660 - val_loss: 0.6785 - val_accuracy: 0.6000\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7033 - accuracy: 0.5660 - val_loss: 0.6766 - val_accuracy: 0.6000\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7007 - accuracy: 0.5660 - val_loss: 0.6748 - val_accuracy: 0.6000\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6984 - accuracy: 0.5660 - val_loss: 0.6731 - val_accuracy: 0.6000\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6955 - accuracy: 0.5660 - val_loss: 0.6715 - val_accuracy: 0.6000\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6940 - accuracy: 0.5660 - val_loss: 0.6700 - val_accuracy: 0.6000\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6912 - accuracy: 0.5660 - val_loss: 0.6687 - val_accuracy: 0.6000\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6897 - accuracy: 0.5660 - val_loss: 0.6674 - val_accuracy: 0.6000\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6873 - accuracy: 0.5660 - val_loss: 0.6662 - val_accuracy: 0.6000\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6871 - accuracy: 0.5660 - val_loss: 0.6651 - val_accuracy: 0.6000\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6840 - accuracy: 0.5660 - val_loss: 0.6641 - val_accuracy: 0.6000\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6830 - accuracy: 0.5660 - val_loss: 0.6631 - val_accuracy: 0.6000\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6812 - accuracy: 0.5660 - val_loss: 0.6623 - val_accuracy: 0.6000\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6804 - accuracy: 0.5660 - val_loss: 0.6614 - val_accuracy: 0.6000\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6787 - accuracy: 0.5660 - val_loss: 0.6606 - val_accuracy: 0.6000\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6776 - accuracy: 0.5660 - val_loss: 0.6598 - val_accuracy: 0.6000\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6761 - accuracy: 0.5660 - val_loss: 0.6591 - val_accuracy: 0.6000\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6752 - accuracy: 0.5660 - val_loss: 0.6583 - val_accuracy: 0.6000\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6739 - accuracy: 0.5660 - val_loss: 0.6576 - val_accuracy: 0.6000\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6729 - accuracy: 0.5660 - val_loss: 0.6569 - val_accuracy: 0.6000\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6718 - accuracy: 0.5660 - val_loss: 0.6562 - val_accuracy: 0.6000\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6709 - accuracy: 0.5660 - val_loss: 0.6555 - val_accuracy: 0.6000\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6698 - accuracy: 0.5660 - val_loss: 0.6549 - val_accuracy: 0.6000\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6687 - accuracy: 0.5660 - val_loss: 0.6542 - val_accuracy: 0.6000\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6677 - accuracy: 0.5660 - val_loss: 0.6535 - val_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7824 - accuracy: 0.2963\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 1s 253ms/step - loss: 0.6856 - accuracy: 0.5741 - val_loss: 0.7437 - val_accuracy: 0.4000\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6848 - accuracy: 0.5741 - val_loss: 0.7429 - val_accuracy: 0.4000\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6843 - accuracy: 0.5741 - val_loss: 0.7411 - val_accuracy: 0.4000\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6834 - accuracy: 0.5741 - val_loss: 0.7401 - val_accuracy: 0.4000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6827 - accuracy: 0.5741 - val_loss: 0.7393 - val_accuracy: 0.4000\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6822 - accuracy: 0.5741 - val_loss: 0.7382 - val_accuracy: 0.4000\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6815 - accuracy: 0.5741 - val_loss: 0.7375 - val_accuracy: 0.4000\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6809 - accuracy: 0.5741 - val_loss: 0.7369 - val_accuracy: 0.4000\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6802 - accuracy: 0.5741 - val_loss: 0.7362 - val_accuracy: 0.4000\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6796 - accuracy: 0.5741 - val_loss: 0.7353 - val_accuracy: 0.4000\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6790 - accuracy: 0.5741 - val_loss: 0.7344 - val_accuracy: 0.4000\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6783 - accuracy: 0.5741 - val_loss: 0.7339 - val_accuracy: 0.4000\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6776 - accuracy: 0.5741 - val_loss: 0.7332 - val_accuracy: 0.4000\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6770 - accuracy: 0.5741 - val_loss: 0.7324 - val_accuracy: 0.4000\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6763 - accuracy: 0.5741 - val_loss: 0.7314 - val_accuracy: 0.4000\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6756 - accuracy: 0.5741 - val_loss: 0.7302 - val_accuracy: 0.4000\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6749 - accuracy: 0.5741 - val_loss: 0.7290 - val_accuracy: 0.4000\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6741 - accuracy: 0.5741 - val_loss: 0.7279 - val_accuracy: 0.4000\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6734 - accuracy: 0.5741 - val_loss: 0.7269 - val_accuracy: 0.4000\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6727 - accuracy: 0.5741 - val_loss: 0.7257 - val_accuracy: 0.4000\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6718 - accuracy: 0.5741 - val_loss: 0.7247 - val_accuracy: 0.4000\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6711 - accuracy: 0.5741 - val_loss: 0.7239 - val_accuracy: 0.4000\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6703 - accuracy: 0.5741 - val_loss: 0.7227 - val_accuracy: 0.4000\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6694 - accuracy: 0.5741 - val_loss: 0.7215 - val_accuracy: 0.4000\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6686 - accuracy: 0.5741 - val_loss: 0.7204 - val_accuracy: 0.4000\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6678 - accuracy: 0.5741 - val_loss: 0.7195 - val_accuracy: 0.4000\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6669 - accuracy: 0.5741 - val_loss: 0.7182 - val_accuracy: 0.4000\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6660 - accuracy: 0.5741 - val_loss: 0.7172 - val_accuracy: 0.4000\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6650 - accuracy: 0.5741 - val_loss: 0.7158 - val_accuracy: 0.4000\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6642 - accuracy: 0.5741 - val_loss: 0.7143 - val_accuracy: 0.4000\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6632 - accuracy: 0.5741 - val_loss: 0.7128 - val_accuracy: 0.4000\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6622 - accuracy: 0.5741 - val_loss: 0.7116 - val_accuracy: 0.4000\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6613 - accuracy: 0.5741 - val_loss: 0.7103 - val_accuracy: 0.4000\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6603 - accuracy: 0.5741 - val_loss: 0.7091 - val_accuracy: 0.4000\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6592 - accuracy: 0.5741 - val_loss: 0.7083 - val_accuracy: 0.4000\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6581 - accuracy: 0.5741 - val_loss: 0.7072 - val_accuracy: 0.4000\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6569 - accuracy: 0.5741 - val_loss: 0.7062 - val_accuracy: 0.4000\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6559 - accuracy: 0.5741 - val_loss: 0.7049 - val_accuracy: 0.4000\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6546 - accuracy: 0.5741 - val_loss: 0.7040 - val_accuracy: 0.4000\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6534 - accuracy: 0.5741 - val_loss: 0.7032 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6928 - accuracy: 0.4231\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.8146 - accuracy: 0.5660 - val_loss: 1.0291 - val_accuracy: 0.4000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.8108 - accuracy: 0.5660 - val_loss: 1.0226 - val_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.8070 - accuracy: 0.5660 - val_loss: 1.0162 - val_accuracy: 0.4000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8034 - accuracy: 0.5660 - val_loss: 1.0099 - val_accuracy: 0.4000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7997 - accuracy: 0.5660 - val_loss: 1.0036 - val_accuracy: 0.4000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7962 - accuracy: 0.5660 - val_loss: 0.9974 - val_accuracy: 0.4000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7926 - accuracy: 0.5660 - val_loss: 0.9913 - val_accuracy: 0.4000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7892 - accuracy: 0.5660 - val_loss: 0.9852 - val_accuracy: 0.4000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7858 - accuracy: 0.5660 - val_loss: 0.9792 - val_accuracy: 0.4000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.7825 - accuracy: 0.5660 - val_loss: 0.9733 - val_accuracy: 0.4000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7792 - accuracy: 0.5660 - val_loss: 0.9675 - val_accuracy: 0.4000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7760 - accuracy: 0.5660 - val_loss: 0.9617 - val_accuracy: 0.4000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7729 - accuracy: 0.5660 - val_loss: 0.9560 - val_accuracy: 0.4000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7698 - accuracy: 0.5660 - val_loss: 0.9504 - val_accuracy: 0.4000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7667 - accuracy: 0.5660 - val_loss: 0.9449 - val_accuracy: 0.4000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7638 - accuracy: 0.5660 - val_loss: 0.9395 - val_accuracy: 0.4000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7609 - accuracy: 0.5660 - val_loss: 0.9341 - val_accuracy: 0.4000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7581 - accuracy: 0.5660 - val_loss: 0.9289 - val_accuracy: 0.4000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7553 - accuracy: 0.5660 - val_loss: 0.9237 - val_accuracy: 0.4000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7526 - accuracy: 0.5660 - val_loss: 0.9186 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8741 - accuracy: 0.4444\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 877ms/step - loss: 0.7070 - accuracy: 0.5660 - val_loss: 0.6827 - val_accuracy: 0.6000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7053 - accuracy: 0.5660 - val_loss: 0.6817 - val_accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7037 - accuracy: 0.5660 - val_loss: 0.6807 - val_accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7022 - accuracy: 0.5660 - val_loss: 0.6797 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7008 - accuracy: 0.5660 - val_loss: 0.6789 - val_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6994 - accuracy: 0.5660 - val_loss: 0.6780 - val_accuracy: 0.6000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6980 - accuracy: 0.5660 - val_loss: 0.6773 - val_accuracy: 0.6000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6967 - accuracy: 0.5660 - val_loss: 0.6766 - val_accuracy: 0.6000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6955 - accuracy: 0.5660 - val_loss: 0.6759 - val_accuracy: 0.6000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6944 - accuracy: 0.5660 - val_loss: 0.6753 - val_accuracy: 0.6000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6933 - accuracy: 0.5660 - val_loss: 0.6748 - val_accuracy: 0.6000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6922 - accuracy: 0.5660 - val_loss: 0.6743 - val_accuracy: 0.6000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6913 - accuracy: 0.5660 - val_loss: 0.6739 - val_accuracy: 0.6000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6904 - accuracy: 0.5660 - val_loss: 0.6735 - val_accuracy: 0.6000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6895 - accuracy: 0.5660 - val_loss: 0.6731 - val_accuracy: 0.6000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6887 - accuracy: 0.5660 - val_loss: 0.6728 - val_accuracy: 0.6000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6879 - accuracy: 0.5660 - val_loss: 0.6725 - val_accuracy: 0.6000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6872 - accuracy: 0.5660 - val_loss: 0.6723 - val_accuracy: 0.6000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6866 - accuracy: 0.5660 - val_loss: 0.6721 - val_accuracy: 0.6000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6859 - accuracy: 0.5660 - val_loss: 0.6719 - val_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7885 - accuracy: 0.2963\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.7386 - accuracy: 0.4259 - val_loss: 0.6774 - val_accuracy: 0.6000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7358 - accuracy: 0.4259 - val_loss: 0.6776 - val_accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7331 - accuracy: 0.4259 - val_loss: 0.6779 - val_accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.7305 - accuracy: 0.4259 - val_loss: 0.6782 - val_accuracy: 0.6000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7279 - accuracy: 0.4259 - val_loss: 0.6786 - val_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7254 - accuracy: 0.4259 - val_loss: 0.6790 - val_accuracy: 0.6000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7230 - accuracy: 0.4259 - val_loss: 0.6795 - val_accuracy: 0.6000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7207 - accuracy: 0.4259 - val_loss: 0.6801 - val_accuracy: 0.6000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7184 - accuracy: 0.4259 - val_loss: 0.6808 - val_accuracy: 0.6000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7162 - accuracy: 0.4259 - val_loss: 0.6814 - val_accuracy: 0.6000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7141 - accuracy: 0.4259 - val_loss: 0.6822 - val_accuracy: 0.6000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7121 - accuracy: 0.4259 - val_loss: 0.6830 - val_accuracy: 0.6000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7101 - accuracy: 0.4259 - val_loss: 0.6838 - val_accuracy: 0.6000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7082 - accuracy: 0.4259 - val_loss: 0.6847 - val_accuracy: 0.6000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7064 - accuracy: 0.4259 - val_loss: 0.6857 - val_accuracy: 0.6000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7047 - accuracy: 0.4259 - val_loss: 0.6867 - val_accuracy: 0.6000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7030 - accuracy: 0.4259 - val_loss: 0.6877 - val_accuracy: 0.6000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7014 - accuracy: 0.4259 - val_loss: 0.6888 - val_accuracy: 0.6000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6999 - accuracy: 0.4259 - val_loss: 0.6899 - val_accuracy: 0.6000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6985 - accuracy: 0.4259 - val_loss: 0.6910 - val_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6919 - accuracy: 0.5769\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6729 - accuracy: 0.4340 - val_loss: 0.6414 - val_accuracy: 0.6000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6654 - accuracy: 0.4340 - val_loss: 0.6352 - val_accuracy: 0.6000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6581 - accuracy: 0.4340 - val_loss: 0.6289 - val_accuracy: 0.6000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6509 - accuracy: 0.4340 - val_loss: 0.6225 - val_accuracy: 0.6000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6437 - accuracy: 0.4340 - val_loss: 0.6163 - val_accuracy: 0.6000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6366 - accuracy: 0.4340 - val_loss: 0.6100 - val_accuracy: 0.6000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6296 - accuracy: 0.4340 - val_loss: 0.6038 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6225 - accuracy: 0.4340 - val_loss: 0.5975 - val_accuracy: 0.6000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6156 - accuracy: 0.4340 - val_loss: 0.5913 - val_accuracy: 0.6000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6087 - accuracy: 0.4340 - val_loss: 0.5851 - val_accuracy: 0.6000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6017 - accuracy: 0.4340 - val_loss: 0.5789 - val_accuracy: 0.6000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5948 - accuracy: 0.4528 - val_loss: 0.5727 - val_accuracy: 0.6000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5878 - accuracy: 0.4528 - val_loss: 0.5665 - val_accuracy: 0.6000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5810 - accuracy: 0.4717 - val_loss: 0.5603 - val_accuracy: 0.6000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5742 - accuracy: 0.4717 - val_loss: 0.5539 - val_accuracy: 0.6000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5673 - accuracy: 0.4906 - val_loss: 0.5476 - val_accuracy: 0.6000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5605 - accuracy: 0.5094 - val_loss: 0.5411 - val_accuracy: 0.6500\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5538 - accuracy: 0.5283 - val_loss: 0.5347 - val_accuracy: 0.7000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5470 - accuracy: 0.6038 - val_loss: 0.5281 - val_accuracy: 0.8000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5400 - accuracy: 0.6038 - val_loss: 0.5213 - val_accuracy: 0.8000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5328 - accuracy: 0.6415 - val_loss: 0.5143 - val_accuracy: 0.8500\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5256 - accuracy: 0.6604 - val_loss: 0.5073 - val_accuracy: 0.9000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5182 - accuracy: 0.7170 - val_loss: 0.5001 - val_accuracy: 0.9000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5107 - accuracy: 0.7736 - val_loss: 0.4930 - val_accuracy: 0.9500\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5031 - accuracy: 0.8113 - val_loss: 0.4859 - val_accuracy: 0.9500\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4956 - accuracy: 0.8302 - val_loss: 0.4787 - val_accuracy: 0.9500\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4881 - accuracy: 0.9245 - val_loss: 0.4715 - val_accuracy: 0.9500\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4806 - accuracy: 0.9434 - val_loss: 0.4644 - val_accuracy: 0.9500\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4731 - accuracy: 0.9623 - val_loss: 0.4573 - val_accuracy: 0.9500\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4656 - accuracy: 0.9623 - val_loss: 0.4502 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4137 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 841ms/step - loss: 0.6425 - accuracy: 0.4340 - val_loss: 0.6338 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6349 - accuracy: 0.4340 - val_loss: 0.6271 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6274 - accuracy: 0.4340 - val_loss: 0.6206 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6200 - accuracy: 0.4340 - val_loss: 0.6142 - val_accuracy: 0.4500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6127 - accuracy: 0.4340 - val_loss: 0.6079 - val_accuracy: 0.4500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6056 - accuracy: 0.4340 - val_loss: 0.6019 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5986 - accuracy: 0.4340 - val_loss: 0.5961 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5918 - accuracy: 0.4340 - val_loss: 0.5904 - val_accuracy: 0.4500\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5851 - accuracy: 0.4340 - val_loss: 0.5849 - val_accuracy: 0.4500\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5786 - accuracy: 0.4340 - val_loss: 0.5795 - val_accuracy: 0.4500\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5720 - accuracy: 0.4340 - val_loss: 0.5742 - val_accuracy: 0.4500\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5656 - accuracy: 0.4340 - val_loss: 0.5689 - val_accuracy: 0.4500\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5593 - accuracy: 0.4528 - val_loss: 0.5638 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5530 - accuracy: 0.4717 - val_loss: 0.5588 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5468 - accuracy: 0.4717 - val_loss: 0.5539 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5407 - accuracy: 0.4717 - val_loss: 0.5491 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5347 - accuracy: 0.4717 - val_loss: 0.5443 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5289 - accuracy: 0.4717 - val_loss: 0.5397 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5232 - accuracy: 0.4717 - val_loss: 0.5351 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5176 - accuracy: 0.4717 - val_loss: 0.5306 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5120 - accuracy: 0.4906 - val_loss: 0.5262 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5067 - accuracy: 0.4906 - val_loss: 0.5219 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5014 - accuracy: 0.4906 - val_loss: 0.5177 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4963 - accuracy: 0.5094 - val_loss: 0.5135 - val_accuracy: 0.5500\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4912 - accuracy: 0.5094 - val_loss: 0.5095 - val_accuracy: 0.5500\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4862 - accuracy: 0.5094 - val_loss: 0.5055 - val_accuracy: 0.5500\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4813 - accuracy: 0.5283 - val_loss: 0.5015 - val_accuracy: 0.5500\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4764 - accuracy: 0.5660 - val_loss: 0.4978 - val_accuracy: 0.6000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4717 - accuracy: 0.5660 - val_loss: 0.4940 - val_accuracy: 0.6500\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4671 - accuracy: 0.6038 - val_loss: 0.4904 - val_accuracy: 0.6500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3051 - accuracy: 0.7037\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8395 - accuracy: 0.5741 - val_loss: 0.8649 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8269 - accuracy: 0.5741 - val_loss: 0.8518 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.8143 - accuracy: 0.5741 - val_loss: 0.8387 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8020 - accuracy: 0.5741 - val_loss: 0.8256 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.7898 - accuracy: 0.5741 - val_loss: 0.8124 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7774 - accuracy: 0.5741 - val_loss: 0.7994 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7652 - accuracy: 0.5741 - val_loss: 0.7863 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7529 - accuracy: 0.5741 - val_loss: 0.7736 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7408 - accuracy: 0.5741 - val_loss: 0.7612 - val_accuracy: 0.4000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7290 - accuracy: 0.5741 - val_loss: 0.7490 - val_accuracy: 0.4000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7172 - accuracy: 0.5741 - val_loss: 0.7370 - val_accuracy: 0.4000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7058 - accuracy: 0.5741 - val_loss: 0.7253 - val_accuracy: 0.4000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6945 - accuracy: 0.5741 - val_loss: 0.7137 - val_accuracy: 0.4000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6835 - accuracy: 0.5741 - val_loss: 0.7025 - val_accuracy: 0.4000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6726 - accuracy: 0.5741 - val_loss: 0.6916 - val_accuracy: 0.4000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6620 - accuracy: 0.5741 - val_loss: 0.6808 - val_accuracy: 0.4000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6516 - accuracy: 0.5741 - val_loss: 0.6702 - val_accuracy: 0.4000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6414 - accuracy: 0.5741 - val_loss: 0.6598 - val_accuracy: 0.4000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6313 - accuracy: 0.5741 - val_loss: 0.6498 - val_accuracy: 0.4000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6216 - accuracy: 0.5741 - val_loss: 0.6399 - val_accuracy: 0.4500\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6120 - accuracy: 0.5741 - val_loss: 0.6302 - val_accuracy: 0.4500\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6027 - accuracy: 0.5741 - val_loss: 0.6207 - val_accuracy: 0.4500\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5935 - accuracy: 0.5741 - val_loss: 0.6115 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5845 - accuracy: 0.5741 - val_loss: 0.6026 - val_accuracy: 0.6000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5759 - accuracy: 0.5741 - val_loss: 0.5938 - val_accuracy: 0.6000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5673 - accuracy: 0.6296 - val_loss: 0.5851 - val_accuracy: 0.6500\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5589 - accuracy: 0.6296 - val_loss: 0.5765 - val_accuracy: 0.7500\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5506 - accuracy: 0.6481 - val_loss: 0.5682 - val_accuracy: 0.8500\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5425 - accuracy: 0.6852 - val_loss: 0.5600 - val_accuracy: 0.9000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5344 - accuracy: 0.8148 - val_loss: 0.5521 - val_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5714 - accuracy: 0.9231\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 249ms/step - loss: 0.6861 - accuracy: 0.5660 - val_loss: 0.7473 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6847 - accuracy: 0.5660 - val_loss: 0.7434 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6842 - accuracy: 0.5660 - val_loss: 0.7401 - val_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6831 - accuracy: 0.5660 - val_loss: 0.7381 - val_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6824 - accuracy: 0.5660 - val_loss: 0.7364 - val_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6820 - accuracy: 0.5660 - val_loss: 0.7352 - val_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6810 - accuracy: 0.5660 - val_loss: 0.7349 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6805 - accuracy: 0.5660 - val_loss: 0.7343 - val_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6799 - accuracy: 0.5660 - val_loss: 0.7332 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6794 - accuracy: 0.5660 - val_loss: 0.7321 - val_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6788 - accuracy: 0.5660 - val_loss: 0.7310 - val_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6783 - accuracy: 0.5660 - val_loss: 0.7299 - val_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6776 - accuracy: 0.5660 - val_loss: 0.7294 - val_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6769 - accuracy: 0.5660 - val_loss: 0.7285 - val_accuracy: 0.4000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6763 - accuracy: 0.5660 - val_loss: 0.7275 - val_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6758 - accuracy: 0.5660 - val_loss: 0.7267 - val_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6750 - accuracy: 0.5660 - val_loss: 0.7253 - val_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6743 - accuracy: 0.5660 - val_loss: 0.7240 - val_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6738 - accuracy: 0.5660 - val_loss: 0.7225 - val_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6730 - accuracy: 0.5660 - val_loss: 0.7214 - val_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6723 - accuracy: 0.5660 - val_loss: 0.7200 - val_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6717 - accuracy: 0.5660 - val_loss: 0.7186 - val_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6710 - accuracy: 0.5660 - val_loss: 0.7174 - val_accuracy: 0.4000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6701 - accuracy: 0.5660 - val_loss: 0.7167 - val_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6693 - accuracy: 0.5660 - val_loss: 0.7159 - val_accuracy: 0.4000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6686 - accuracy: 0.5660 - val_loss: 0.7150 - val_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6677 - accuracy: 0.5660 - val_loss: 0.7145 - val_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6669 - accuracy: 0.5660 - val_loss: 0.7142 - val_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6659 - accuracy: 0.5660 - val_loss: 0.7134 - val_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6650 - accuracy: 0.5660 - val_loss: 0.7129 - val_accuracy: 0.4000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6641 - accuracy: 0.5660 - val_loss: 0.7120 - val_accuracy: 0.4000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6630 - accuracy: 0.5660 - val_loss: 0.7114 - val_accuracy: 0.4000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6620 - accuracy: 0.5660 - val_loss: 0.7106 - val_accuracy: 0.4000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6609 - accuracy: 0.5660 - val_loss: 0.7099 - val_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6598 - accuracy: 0.5660 - val_loss: 0.7089 - val_accuracy: 0.4000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6587 - accuracy: 0.5660 - val_loss: 0.7082 - val_accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6575 - accuracy: 0.5660 - val_loss: 0.7071 - val_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6563 - accuracy: 0.5660 - val_loss: 0.7059 - val_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6550 - accuracy: 0.5660 - val_loss: 0.7047 - val_accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6537 - accuracy: 0.5660 - val_loss: 0.7033 - val_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6523 - accuracy: 0.5660 - val_loss: 0.7015 - val_accuracy: 0.4000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6509 - accuracy: 0.5660 - val_loss: 0.6999 - val_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6498 - accuracy: 0.5660 - val_loss: 0.6979 - val_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6480 - accuracy: 0.5660 - val_loss: 0.6966 - val_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6464 - accuracy: 0.5660 - val_loss: 0.6952 - val_accuracy: 0.4000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6448 - accuracy: 0.5660 - val_loss: 0.6939 - val_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6431 - accuracy: 0.5660 - val_loss: 0.6923 - val_accuracy: 0.4000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6414 - accuracy: 0.5660 - val_loss: 0.6905 - val_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6397 - accuracy: 0.5660 - val_loss: 0.6887 - val_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6378 - accuracy: 0.5660 - val_loss: 0.6870 - val_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6359 - accuracy: 0.5660 - val_loss: 0.6853 - val_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6339 - accuracy: 0.5660 - val_loss: 0.6833 - val_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6319 - accuracy: 0.5660 - val_loss: 0.6813 - val_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6297 - accuracy: 0.5660 - val_loss: 0.6796 - val_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6275 - accuracy: 0.5660 - val_loss: 0.6776 - val_accuracy: 0.4000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6253 - accuracy: 0.5660 - val_loss: 0.6758 - val_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6229 - accuracy: 0.5660 - val_loss: 0.6736 - val_accuracy: 0.4000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6205 - accuracy: 0.5660 - val_loss: 0.6711 - val_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6180 - accuracy: 0.5660 - val_loss: 0.6687 - val_accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6154 - accuracy: 0.5660 - val_loss: 0.6660 - val_accuracy: 0.4000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6128 - accuracy: 0.5660 - val_loss: 0.6633 - val_accuracy: 0.4000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6101 - accuracy: 0.5660 - val_loss: 0.6603 - val_accuracy: 0.4000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6073 - accuracy: 0.5660 - val_loss: 0.6574 - val_accuracy: 0.4000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6044 - accuracy: 0.5660 - val_loss: 0.6548 - val_accuracy: 0.4000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6014 - accuracy: 0.5660 - val_loss: 0.6519 - val_accuracy: 0.4000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5984 - accuracy: 0.5849 - val_loss: 0.6490 - val_accuracy: 0.4500\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5952 - accuracy: 0.5849 - val_loss: 0.6462 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5920 - accuracy: 0.5849 - val_loss: 0.6434 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5887 - accuracy: 0.6226 - val_loss: 0.6400 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.5852 - accuracy: 0.6792 - val_loss: 0.6369 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5817 - accuracy: 0.6792 - val_loss: 0.6339 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5781 - accuracy: 0.7358 - val_loss: 0.6308 - val_accuracy: 0.5500\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5744 - accuracy: 0.7547 - val_loss: 0.6275 - val_accuracy: 0.5500\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5706 - accuracy: 0.8113 - val_loss: 0.6243 - val_accuracy: 0.5500\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5667 - accuracy: 0.8302 - val_loss: 0.6211 - val_accuracy: 0.5500\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5628 - accuracy: 0.8302 - val_loss: 0.6180 - val_accuracy: 0.5500\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5586 - accuracy: 0.8491 - val_loss: 0.6143 - val_accuracy: 0.5500\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5545 - accuracy: 0.8491 - val_loss: 0.6108 - val_accuracy: 0.6000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5502 - accuracy: 0.8868 - val_loss: 0.6068 - val_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5459 - accuracy: 0.9057 - val_loss: 0.6027 - val_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5414 - accuracy: 0.9245 - val_loss: 0.5987 - val_accuracy: 0.6500\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5369 - accuracy: 0.9434 - val_loss: 0.5946 - val_accuracy: 0.6500\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5323 - accuracy: 0.9623 - val_loss: 0.5905 - val_accuracy: 0.6500\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5276 - accuracy: 0.9623 - val_loss: 0.5866 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5228 - accuracy: 0.9623 - val_loss: 0.5824 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5179 - accuracy: 0.9811 - val_loss: 0.5781 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5129 - accuracy: 0.9811 - val_loss: 0.5737 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5078 - accuracy: 0.9811 - val_loss: 0.5693 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5028 - accuracy: 0.9811 - val_loss: 0.5646 - val_accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4974 - accuracy: 1.0000 - val_loss: 0.5603 - val_accuracy: 0.8000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4922 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4868 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.8000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4814 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.8000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4759 - accuracy: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.8000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4703 - accuracy: 1.0000 - val_loss: 0.5359 - val_accuracy: 0.8500\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4648 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.8500\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4591 - accuracy: 1.0000 - val_loss: 0.5255 - val_accuracy: 0.8500\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4534 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8500\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4476 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.9000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4419 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4695 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 0.7918 - accuracy: 0.4340 - val_loss: 0.8089 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7845 - accuracy: 0.4340 - val_loss: 0.8011 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7789 - accuracy: 0.4340 - val_loss: 0.7937 - val_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7723 - accuracy: 0.4340 - val_loss: 0.7868 - val_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7659 - accuracy: 0.4340 - val_loss: 0.7802 - val_accuracy: 0.4000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7610 - accuracy: 0.4340 - val_loss: 0.7738 - val_accuracy: 0.4000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7544 - accuracy: 0.4340 - val_loss: 0.7679 - val_accuracy: 0.4000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7489 - accuracy: 0.4340 - val_loss: 0.7621 - val_accuracy: 0.4000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.7450 - accuracy: 0.4340 - val_loss: 0.7565 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7399 - accuracy: 0.4340 - val_loss: 0.7512 - val_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7367 - accuracy: 0.4340 - val_loss: 0.7460 - val_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7318 - accuracy: 0.4340 - val_loss: 0.7413 - val_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7281 - accuracy: 0.4340 - val_loss: 0.7368 - val_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7244 - accuracy: 0.4340 - val_loss: 0.7325 - val_accuracy: 0.4000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7204 - accuracy: 0.4340 - val_loss: 0.7285 - val_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7170 - accuracy: 0.4340 - val_loss: 0.7247 - val_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7146 - accuracy: 0.4340 - val_loss: 0.7210 - val_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7114 - accuracy: 0.4340 - val_loss: 0.7175 - val_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7095 - accuracy: 0.4340 - val_loss: 0.7142 - val_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7067 - accuracy: 0.4340 - val_loss: 0.7112 - val_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7048 - accuracy: 0.4340 - val_loss: 0.7084 - val_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7021 - accuracy: 0.4340 - val_loss: 0.7060 - val_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6998 - accuracy: 0.4340 - val_loss: 0.7037 - val_accuracy: 0.4000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6986 - accuracy: 0.4340 - val_loss: 0.7014 - val_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6968 - accuracy: 0.4340 - val_loss: 0.6993 - val_accuracy: 0.4000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6949 - accuracy: 0.4340 - val_loss: 0.6973 - val_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6936 - accuracy: 0.4340 - val_loss: 0.6954 - val_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6922 - accuracy: 0.4340 - val_loss: 0.6936 - val_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6905 - accuracy: 0.4340 - val_loss: 0.6919 - val_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6894 - accuracy: 0.4340 - val_loss: 0.6901 - val_accuracy: 0.4000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6882 - accuracy: 0.4717 - val_loss: 0.6885 - val_accuracy: 0.6500\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6872 - accuracy: 0.9434 - val_loss: 0.6869 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6859 - accuracy: 0.9434 - val_loss: 0.6854 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6851 - accuracy: 0.6415 - val_loss: 0.6840 - val_accuracy: 0.6000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6838 - accuracy: 0.5660 - val_loss: 0.6827 - val_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6829 - accuracy: 0.5660 - val_loss: 0.6814 - val_accuracy: 0.6000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6824 - accuracy: 0.5660 - val_loss: 0.6802 - val_accuracy: 0.6000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6814 - accuracy: 0.5660 - val_loss: 0.6790 - val_accuracy: 0.6000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6803 - accuracy: 0.5660 - val_loss: 0.6780 - val_accuracy: 0.6000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6796 - accuracy: 0.5660 - val_loss: 0.6769 - val_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6788 - accuracy: 0.5660 - val_loss: 0.6759 - val_accuracy: 0.6000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6782 - accuracy: 0.5660 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6779 - accuracy: 0.5660 - val_loss: 0.6739 - val_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6769 - accuracy: 0.5660 - val_loss: 0.6730 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6761 - accuracy: 0.5660 - val_loss: 0.6722 - val_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6757 - accuracy: 0.5660 - val_loss: 0.6714 - val_accuracy: 0.6000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6749 - accuracy: 0.5660 - val_loss: 0.6706 - val_accuracy: 0.6000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6744 - accuracy: 0.5660 - val_loss: 0.6698 - val_accuracy: 0.6000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6738 - accuracy: 0.5660 - val_loss: 0.6691 - val_accuracy: 0.6000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6731 - accuracy: 0.5660 - val_loss: 0.6684 - val_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6726 - accuracy: 0.5660 - val_loss: 0.6676 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6721 - accuracy: 0.5660 - val_loss: 0.6669 - val_accuracy: 0.6000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6713 - accuracy: 0.5660 - val_loss: 0.6662 - val_accuracy: 0.6000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6707 - accuracy: 0.5660 - val_loss: 0.6655 - val_accuracy: 0.6000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6701 - accuracy: 0.5660 - val_loss: 0.6648 - val_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6694 - accuracy: 0.5660 - val_loss: 0.6640 - val_accuracy: 0.6000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6690 - accuracy: 0.5660 - val_loss: 0.6633 - val_accuracy: 0.6000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6681 - accuracy: 0.5660 - val_loss: 0.6626 - val_accuracy: 0.6000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6675 - accuracy: 0.5660 - val_loss: 0.6619 - val_accuracy: 0.6000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6668 - accuracy: 0.5660 - val_loss: 0.6612 - val_accuracy: 0.6000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6661 - accuracy: 0.5660 - val_loss: 0.6605 - val_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6654 - accuracy: 0.5660 - val_loss: 0.6597 - val_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.6647 - accuracy: 0.5660 - val_loss: 0.6590 - val_accuracy: 0.6000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6639 - accuracy: 0.5660 - val_loss: 0.6583 - val_accuracy: 0.6000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6632 - accuracy: 0.5660 - val_loss: 0.6574 - val_accuracy: 0.6000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6624 - accuracy: 0.5660 - val_loss: 0.6567 - val_accuracy: 0.6000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6615 - accuracy: 0.5660 - val_loss: 0.6559 - val_accuracy: 0.6000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6607 - accuracy: 0.5660 - val_loss: 0.6550 - val_accuracy: 0.6000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6598 - accuracy: 0.5660 - val_loss: 0.6541 - val_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6590 - accuracy: 0.5660 - val_loss: 0.6532 - val_accuracy: 0.6000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6581 - accuracy: 0.5660 - val_loss: 0.6523 - val_accuracy: 0.6000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6571 - accuracy: 0.5660 - val_loss: 0.6514 - val_accuracy: 0.6000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6562 - accuracy: 0.5660 - val_loss: 0.6505 - val_accuracy: 0.6000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6551 - accuracy: 0.5660 - val_loss: 0.6495 - val_accuracy: 0.6000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6541 - accuracy: 0.5660 - val_loss: 0.6485 - val_accuracy: 0.6000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6530 - accuracy: 0.5660 - val_loss: 0.6474 - val_accuracy: 0.6000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6519 - accuracy: 0.5660 - val_loss: 0.6464 - val_accuracy: 0.6000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6508 - accuracy: 0.5660 - val_loss: 0.6453 - val_accuracy: 0.6000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6496 - accuracy: 0.5660 - val_loss: 0.6442 - val_accuracy: 0.6000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6484 - accuracy: 0.5660 - val_loss: 0.6430 - val_accuracy: 0.6000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6471 - accuracy: 0.5660 - val_loss: 0.6417 - val_accuracy: 0.6000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6459 - accuracy: 0.5660 - val_loss: 0.6405 - val_accuracy: 0.6000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6445 - accuracy: 0.5660 - val_loss: 0.6392 - val_accuracy: 0.6000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6432 - accuracy: 0.5660 - val_loss: 0.6379 - val_accuracy: 0.6000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6417 - accuracy: 0.5660 - val_loss: 0.6365 - val_accuracy: 0.6000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6403 - accuracy: 0.5660 - val_loss: 0.6350 - val_accuracy: 0.6000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6388 - accuracy: 0.5660 - val_loss: 0.6335 - val_accuracy: 0.6000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6372 - accuracy: 0.5660 - val_loss: 0.6320 - val_accuracy: 0.6000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6357 - accuracy: 0.5660 - val_loss: 0.6304 - val_accuracy: 0.6000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6340 - accuracy: 0.5660 - val_loss: 0.6288 - val_accuracy: 0.6000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6323 - accuracy: 0.5660 - val_loss: 0.6271 - val_accuracy: 0.6000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6306 - accuracy: 0.5660 - val_loss: 0.6254 - val_accuracy: 0.6000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6288 - accuracy: 0.5660 - val_loss: 0.6236 - val_accuracy: 0.6000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6269 - accuracy: 0.5660 - val_loss: 0.6218 - val_accuracy: 0.6000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6250 - accuracy: 0.5660 - val_loss: 0.6199 - val_accuracy: 0.6000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6231 - accuracy: 0.5660 - val_loss: 0.6181 - val_accuracy: 0.6000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6211 - accuracy: 0.5660 - val_loss: 0.6161 - val_accuracy: 0.6000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6189 - accuracy: 0.5660 - val_loss: 0.6141 - val_accuracy: 0.6000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6168 - accuracy: 0.5660 - val_loss: 0.6120 - val_accuracy: 0.6000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6146 - accuracy: 0.5660 - val_loss: 0.6099 - val_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6627 - accuracy: 0.2963\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 250ms/step - loss: 0.7308 - accuracy: 0.4259 - val_loss: 0.6804 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.7254 - accuracy: 0.4259 - val_loss: 0.6812 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7193 - accuracy: 0.4259 - val_loss: 0.6822 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7144 - accuracy: 0.4259 - val_loss: 0.6833 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7108 - accuracy: 0.4259 - val_loss: 0.6849 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.7060 - accuracy: 0.4259 - val_loss: 0.6866 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7024 - accuracy: 0.4259 - val_loss: 0.6885 - val_accuracy: 0.6000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6990 - accuracy: 0.4259 - val_loss: 0.6906 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6957 - accuracy: 0.4444 - val_loss: 0.6927 - val_accuracy: 0.5500\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6919 - accuracy: 0.5741 - val_loss: 0.6948 - val_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6901 - accuracy: 0.5741 - val_loss: 0.6970 - val_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6873 - accuracy: 0.5741 - val_loss: 0.6991 - val_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6846 - accuracy: 0.5741 - val_loss: 0.7009 - val_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6825 - accuracy: 0.5741 - val_loss: 0.7028 - val_accuracy: 0.4000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6805 - accuracy: 0.5741 - val_loss: 0.7046 - val_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6793 - accuracy: 0.5741 - val_loss: 0.7064 - val_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6770 - accuracy: 0.5741 - val_loss: 0.7078 - val_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6757 - accuracy: 0.5741 - val_loss: 0.7091 - val_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6739 - accuracy: 0.5741 - val_loss: 0.7100 - val_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6723 - accuracy: 0.5741 - val_loss: 0.7108 - val_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6709 - accuracy: 0.5741 - val_loss: 0.7115 - val_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6699 - accuracy: 0.5741 - val_loss: 0.7125 - val_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6682 - accuracy: 0.5741 - val_loss: 0.7128 - val_accuracy: 0.4000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6669 - accuracy: 0.5741 - val_loss: 0.7132 - val_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6662 - accuracy: 0.5741 - val_loss: 0.7138 - val_accuracy: 0.4000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6644 - accuracy: 0.5741 - val_loss: 0.7135 - val_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6630 - accuracy: 0.5741 - val_loss: 0.7131 - val_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6616 - accuracy: 0.5741 - val_loss: 0.7125 - val_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6603 - accuracy: 0.5741 - val_loss: 0.7117 - val_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6589 - accuracy: 0.5741 - val_loss: 0.7110 - val_accuracy: 0.4000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6574 - accuracy: 0.5741 - val_loss: 0.7097 - val_accuracy: 0.4000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6559 - accuracy: 0.5741 - val_loss: 0.7084 - val_accuracy: 0.4000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6545 - accuracy: 0.5741 - val_loss: 0.7072 - val_accuracy: 0.4000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6528 - accuracy: 0.5741 - val_loss: 0.7052 - val_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6512 - accuracy: 0.5741 - val_loss: 0.7036 - val_accuracy: 0.4000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6495 - accuracy: 0.5741 - val_loss: 0.7015 - val_accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6479 - accuracy: 0.5741 - val_loss: 0.6993 - val_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6464 - accuracy: 0.5741 - val_loss: 0.6966 - val_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6446 - accuracy: 0.5741 - val_loss: 0.6944 - val_accuracy: 0.4000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6428 - accuracy: 0.5741 - val_loss: 0.6922 - val_accuracy: 0.4000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6410 - accuracy: 0.5741 - val_loss: 0.6901 - val_accuracy: 0.4000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6393 - accuracy: 0.5741 - val_loss: 0.6880 - val_accuracy: 0.4000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6373 - accuracy: 0.5741 - val_loss: 0.6863 - val_accuracy: 0.4000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6355 - accuracy: 0.5741 - val_loss: 0.6845 - val_accuracy: 0.4000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6336 - accuracy: 0.5741 - val_loss: 0.6827 - val_accuracy: 0.4000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6315 - accuracy: 0.5741 - val_loss: 0.6805 - val_accuracy: 0.4000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6295 - accuracy: 0.5741 - val_loss: 0.6783 - val_accuracy: 0.4000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6274 - accuracy: 0.5741 - val_loss: 0.6759 - val_accuracy: 0.4000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6254 - accuracy: 0.5741 - val_loss: 0.6735 - val_accuracy: 0.4000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6232 - accuracy: 0.5741 - val_loss: 0.6707 - val_accuracy: 0.4000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6210 - accuracy: 0.5741 - val_loss: 0.6678 - val_accuracy: 0.4000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6190 - accuracy: 0.5741 - val_loss: 0.6651 - val_accuracy: 0.4000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6164 - accuracy: 0.5741 - val_loss: 0.6630 - val_accuracy: 0.4000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6141 - accuracy: 0.5741 - val_loss: 0.6606 - val_accuracy: 0.4000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6117 - accuracy: 0.5741 - val_loss: 0.6586 - val_accuracy: 0.4000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6092 - accuracy: 0.5741 - val_loss: 0.6562 - val_accuracy: 0.4000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6067 - accuracy: 0.5741 - val_loss: 0.6541 - val_accuracy: 0.4000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6040 - accuracy: 0.5741 - val_loss: 0.6517 - val_accuracy: 0.4000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6013 - accuracy: 0.5741 - val_loss: 0.6493 - val_accuracy: 0.4000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5986 - accuracy: 0.6111 - val_loss: 0.6468 - val_accuracy: 0.4500\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5958 - accuracy: 0.6111 - val_loss: 0.6442 - val_accuracy: 0.4500\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5929 - accuracy: 0.6111 - val_loss: 0.6418 - val_accuracy: 0.4500\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5899 - accuracy: 0.6111 - val_loss: 0.6393 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5869 - accuracy: 0.6296 - val_loss: 0.6368 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5838 - accuracy: 0.6296 - val_loss: 0.6338 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5806 - accuracy: 0.6296 - val_loss: 0.6308 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5773 - accuracy: 0.6667 - val_loss: 0.6279 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5741 - accuracy: 0.7222 - val_loss: 0.6250 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5706 - accuracy: 0.7593 - val_loss: 0.6223 - val_accuracy: 0.5500\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5671 - accuracy: 0.7593 - val_loss: 0.6195 - val_accuracy: 0.5500\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5637 - accuracy: 0.7593 - val_loss: 0.6167 - val_accuracy: 0.5500\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5600 - accuracy: 0.7778 - val_loss: 0.6135 - val_accuracy: 0.5500\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5563 - accuracy: 0.8148 - val_loss: 0.6100 - val_accuracy: 0.5500\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5524 - accuracy: 0.8704 - val_loss: 0.6063 - val_accuracy: 0.5500\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5486 - accuracy: 0.9074 - val_loss: 0.6022 - val_accuracy: 0.5500\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5446 - accuracy: 0.9444 - val_loss: 0.5981 - val_accuracy: 0.5500\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5405 - accuracy: 0.9630 - val_loss: 0.5936 - val_accuracy: 0.6500\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5364 - accuracy: 0.9630 - val_loss: 0.5891 - val_accuracy: 0.6500\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5321 - accuracy: 0.9630 - val_loss: 0.5845 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5277 - accuracy: 1.0000 - val_loss: 0.5800 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5236 - accuracy: 1.0000 - val_loss: 0.5753 - val_accuracy: 0.8000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5188 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.8000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5143 - accuracy: 1.0000 - val_loss: 0.5669 - val_accuracy: 0.8000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5097 - accuracy: 1.0000 - val_loss: 0.5624 - val_accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5050 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5002 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.8000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4953 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.8500\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4903 - accuracy: 1.0000 - val_loss: 0.5437 - val_accuracy: 0.8500\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4855 - accuracy: 1.0000 - val_loss: 0.5380 - val_accuracy: 0.9000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4802 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4751 - accuracy: 1.0000 - val_loss: 0.5273 - val_accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4698 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4645 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.9000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4594 - accuracy: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.9000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4537 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4484 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.9500\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4430 - accuracy: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.9500\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.4373 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.9500\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4317 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9500\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4261 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4406 - accuracy: 1.0000\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 0.9496 - accuracy: 0.0566 - val_loss: 0.9258 - val_accuracy: 0.1000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.9248 - accuracy: 0.0755 - val_loss: 0.9053 - val_accuracy: 0.1000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.9005 - accuracy: 0.0755 - val_loss: 0.8854 - val_accuracy: 0.1500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8769 - accuracy: 0.0755 - val_loss: 0.8659 - val_accuracy: 0.1500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.8538 - accuracy: 0.1132 - val_loss: 0.8468 - val_accuracy: 0.1500\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8312 - accuracy: 0.2075 - val_loss: 0.8283 - val_accuracy: 0.2000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8092 - accuracy: 0.2642 - val_loss: 0.8102 - val_accuracy: 0.2000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7876 - accuracy: 0.3208 - val_loss: 0.7924 - val_accuracy: 0.2000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7665 - accuracy: 0.3396 - val_loss: 0.7751 - val_accuracy: 0.4500\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7459 - accuracy: 0.3774 - val_loss: 0.7583 - val_accuracy: 0.4500\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7259 - accuracy: 0.4528 - val_loss: 0.7419 - val_accuracy: 0.4500\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7062 - accuracy: 0.5094 - val_loss: 0.7258 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6869 - accuracy: 0.5660 - val_loss: 0.7101 - val_accuracy: 0.5500\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6681 - accuracy: 0.6226 - val_loss: 0.6950 - val_accuracy: 0.5500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6499 - accuracy: 0.6226 - val_loss: 0.6800 - val_accuracy: 0.6000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6319 - accuracy: 0.6792 - val_loss: 0.6656 - val_accuracy: 0.6000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6145 - accuracy: 0.6981 - val_loss: 0.6514 - val_accuracy: 0.7000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5973 - accuracy: 0.8113 - val_loss: 0.6376 - val_accuracy: 0.7000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5806 - accuracy: 0.8302 - val_loss: 0.6240 - val_accuracy: 0.7000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5642 - accuracy: 0.8302 - val_loss: 0.6107 - val_accuracy: 0.7000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5481 - accuracy: 0.8302 - val_loss: 0.5978 - val_accuracy: 0.7500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5325 - accuracy: 0.8868 - val_loss: 0.5851 - val_accuracy: 0.7500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5172 - accuracy: 0.8868 - val_loss: 0.5725 - val_accuracy: 0.7500\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5022 - accuracy: 0.8868 - val_loss: 0.5604 - val_accuracy: 0.7500\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4876 - accuracy: 0.9245 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4731 - accuracy: 0.9434 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4591 - accuracy: 0.9434 - val_loss: 0.5250 - val_accuracy: 0.8000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4455 - accuracy: 0.9434 - val_loss: 0.5136 - val_accuracy: 0.8000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4320 - accuracy: 0.9434 - val_loss: 0.5023 - val_accuracy: 0.8000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4187 - accuracy: 0.9434 - val_loss: 0.4913 - val_accuracy: 0.8000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4060 - accuracy: 0.9434 - val_loss: 0.4805 - val_accuracy: 0.8500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3935 - accuracy: 0.9623 - val_loss: 0.4696 - val_accuracy: 0.8500\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3810 - accuracy: 0.9623 - val_loss: 0.4591 - val_accuracy: 0.8500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3691 - accuracy: 0.9623 - val_loss: 0.4487 - val_accuracy: 0.8500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3574 - accuracy: 0.9623 - val_loss: 0.4384 - val_accuracy: 0.8500\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3459 - accuracy: 0.9623 - val_loss: 0.4283 - val_accuracy: 0.8500\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3347 - accuracy: 0.9623 - val_loss: 0.4184 - val_accuracy: 0.8500\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3238 - accuracy: 0.9811 - val_loss: 0.4086 - val_accuracy: 0.9000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3133 - accuracy: 0.9811 - val_loss: 0.3989 - val_accuracy: 0.9000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3029 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2928 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2830 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.9000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2735 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2641 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2553 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.9000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2466 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2381 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.9000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2299 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 0.9000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9500\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2144 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 0.9500\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2070 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1999 - accuracy: 1.0000 - val_loss: 0.2896 - val_accuracy: 0.9500\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1930 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9500\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1864 - accuracy: 1.0000 - val_loss: 0.2756 - val_accuracy: 0.9500\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1800 - accuracy: 1.0000 - val_loss: 0.2691 - val_accuracy: 0.9500\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1739 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1680 - accuracy: 1.0000 - val_loss: 0.2563 - val_accuracy: 0.9500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1622 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1567 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 0.9500\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1515 - accuracy: 1.0000 - val_loss: 0.2386 - val_accuracy: 0.9500\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1464 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9500\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1415 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9500\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1369 - accuracy: 1.0000 - val_loss: 0.2228 - val_accuracy: 0.9500\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1325 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9500\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1282 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9500\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1241 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9500\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1201 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9500\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1164 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9500\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1127 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9500\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1092 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 0.9500\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1059 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9500\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1027 - accuracy: 1.0000 - val_loss: 0.1842 - val_accuracy: 0.9500\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0997 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9500\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0968 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9500\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9500\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 0.9500\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0887 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9500\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0862 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 0.9500\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.1618 - val_accuracy: 0.9500\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0815 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9500\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0794 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9500\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 0.9500\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 0.9500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 0.9500\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9500\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9500\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9500\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9500\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9500\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0632 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9500\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0617 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9500\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9500\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9500\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9500\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9500\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9500\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9500\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9500\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9500\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9500\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0468 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9500\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9500\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9500\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9500\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9500\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9500\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9500\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9500\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9500\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9500\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9500\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9500\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9500\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9500\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9500\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9500\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9500\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9500\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9500\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9500\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9500\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9500\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9500\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9500\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9500\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9500\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9500\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9500\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9500\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9500\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9500\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9500\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9500\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9500\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9500\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9500\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9500\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9500\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9500\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9500\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9500\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9500\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9500\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9500\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9500\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9500\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 0.9500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9500\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9500\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9500\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9500\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9500\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 0.9500\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9500\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 0.9500\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9500\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9500\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9500\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9500\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9500\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 0.9500\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9500\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0674 - val_accuracy: 0.9500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9500\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 0.9500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 0.9500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 0.9500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9500\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9500\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 0.9500\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9500\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 0.9500\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9500\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9500\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 0.6841 - accuracy: 0.5849 - val_loss: 0.6511 - val_accuracy: 0.6500\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6604 - accuracy: 0.6415 - val_loss: 0.6303 - val_accuracy: 0.8000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6375 - accuracy: 0.7170 - val_loss: 0.6101 - val_accuracy: 0.8000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6153 - accuracy: 0.7547 - val_loss: 0.5906 - val_accuracy: 0.8500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5939 - accuracy: 0.8302 - val_loss: 0.5717 - val_accuracy: 0.9000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5732 - accuracy: 0.8868 - val_loss: 0.5534 - val_accuracy: 0.9000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5532 - accuracy: 0.9434 - val_loss: 0.5359 - val_accuracy: 0.9000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5341 - accuracy: 0.9434 - val_loss: 0.5190 - val_accuracy: 0.9000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5157 - accuracy: 0.9623 - val_loss: 0.5028 - val_accuracy: 0.9000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4981 - accuracy: 0.9811 - val_loss: 0.4870 - val_accuracy: 0.9000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4810 - accuracy: 0.9811 - val_loss: 0.4719 - val_accuracy: 0.9000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4647 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9500\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4489 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9500\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4337 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4191 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4052 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3917 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3787 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3663 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3542 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3427 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3315 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3208 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3104 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3005 - accuracy: 1.0000 - val_loss: 0.3116 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2910 - accuracy: 1.0000 - val_loss: 0.3030 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.2949 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2727 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2641 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2558 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2478 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2401 - accuracy: 1.0000 - val_loss: 0.2584 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2326 - accuracy: 1.0000 - val_loss: 0.2519 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2254 - accuracy: 1.0000 - val_loss: 0.2456 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2185 - accuracy: 1.0000 - val_loss: 0.2395 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2119 - accuracy: 1.0000 - val_loss: 0.2338 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2055 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1993 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1933 - accuracy: 1.0000 - val_loss: 0.2174 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1875 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1820 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1767 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1715 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1665 - accuracy: 1.0000 - val_loss: 0.1938 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1617 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.1855 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1528 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1485 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1444 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1404 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1367 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1330 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1294 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1260 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1227 - accuracy: 1.0000 - val_loss: 0.1542 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.1513 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1165 - accuracy: 1.0000 - val_loss: 0.1485 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1136 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1107 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1080 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1003 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0817 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0767 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0707 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0693 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0654 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0546 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0537 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0503 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0359 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0665 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9500\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9500\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9500\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0627 - val_accuracy: 0.9500\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9500\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9500\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9500\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9500\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 0.9500\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9500\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9500\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0614 - val_accuracy: 0.9500\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9500\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 0.9500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9500\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9500\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9500\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 0.9500\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0600 - val_accuracy: 0.9500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9500\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 0.9500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9500\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9500\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9500\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9500\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9500\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9500\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9500\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 0.9500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 0.9500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0581 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 872ms/step - loss: 0.6166 - accuracy: 0.8519 - val_loss: 0.6076 - val_accuracy: 0.8500\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5970 - accuracy: 0.9444 - val_loss: 0.5918 - val_accuracy: 0.9000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5778 - accuracy: 0.9444 - val_loss: 0.5764 - val_accuracy: 0.9000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5592 - accuracy: 0.9815 - val_loss: 0.5614 - val_accuracy: 0.9000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5411 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.9000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5235 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.9500\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5063 - accuracy: 1.0000 - val_loss: 0.5186 - val_accuracy: 0.9500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4897 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9500\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4736 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9500\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4579 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9500\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4428 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9500\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4282 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9500\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4140 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9500\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4003 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3870 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3743 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3619 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9500\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3500 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9500\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3384 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9500\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3274 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3166 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3062 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2962 - accuracy: 1.0000 - val_loss: 0.3437 - val_accuracy: 0.9500\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2866 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9500\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2773 - accuracy: 1.0000 - val_loss: 0.3271 - val_accuracy: 0.9500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2684 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9500\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2598 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.9500\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2514 - accuracy: 1.0000 - val_loss: 0.3038 - val_accuracy: 0.9500\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2434 - accuracy: 1.0000 - val_loss: 0.2965 - val_accuracy: 0.9500\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2357 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9500\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2282 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2211 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9500\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2142 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2076 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2012 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9500\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1950 - accuracy: 1.0000 - val_loss: 0.2506 - val_accuracy: 0.9500\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1890 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9500\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1834 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9500\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1779 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9500\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1726 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9500\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1674 - accuracy: 1.0000 - val_loss: 0.2232 - val_accuracy: 0.9500\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1626 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9500\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1579 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9500\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1532 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1489 - accuracy: 1.0000 - val_loss: 0.2040 - val_accuracy: 0.9500\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1446 - accuracy: 1.0000 - val_loss: 0.1996 - val_accuracy: 0.9500\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1406 - accuracy: 1.0000 - val_loss: 0.1953 - val_accuracy: 0.9500\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1367 - accuracy: 1.0000 - val_loss: 0.1911 - val_accuracy: 0.9500\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1329 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9500\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1293 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 0.9500\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1258 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 0.9500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1224 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9500\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1192 - accuracy: 1.0000 - val_loss: 0.1722 - val_accuracy: 0.9500\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1160 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9500\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1130 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9500\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1101 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1021 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 0.9500\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0996 - accuracy: 1.0000 - val_loss: 0.1505 - val_accuracy: 0.9500\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9500\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0949 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9500\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0926 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9500\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0905 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9500\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0884 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9500\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0864 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9500\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 0.9500\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9500\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9500\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0774 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9500\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9500\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9500\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9500\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0712 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9500\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9500\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0684 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9500\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0671 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9500\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9500\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9500\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0634 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9500\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9500\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0611 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9500\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9500\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9500\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9500\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9500\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9500\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9500\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9500\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9500\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9500\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9500\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9500\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9500\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9500\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9500\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9500\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9500\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9500\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9500\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9500\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0550 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 0.6765 - accuracy: 0.6038 - val_loss: 0.6708 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6727 - accuracy: 0.6038 - val_loss: 0.6675 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6690 - accuracy: 0.6226 - val_loss: 0.6642 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6653 - accuracy: 0.6604 - val_loss: 0.6610 - val_accuracy: 0.5500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6618 - accuracy: 0.6792 - val_loss: 0.6579 - val_accuracy: 0.5500\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6584 - accuracy: 0.6792 - val_loss: 0.6548 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6549 - accuracy: 0.6792 - val_loss: 0.6517 - val_accuracy: 0.5500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6516 - accuracy: 0.6792 - val_loss: 0.6488 - val_accuracy: 0.5500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6484 - accuracy: 0.6792 - val_loss: 0.6459 - val_accuracy: 0.5500\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6451 - accuracy: 0.6792 - val_loss: 0.6430 - val_accuracy: 0.5500\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6420 - accuracy: 0.6792 - val_loss: 0.6402 - val_accuracy: 0.5500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6388 - accuracy: 0.6792 - val_loss: 0.6375 - val_accuracy: 0.5500\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6356 - accuracy: 0.6792 - val_loss: 0.6348 - val_accuracy: 0.5500\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6325 - accuracy: 0.6981 - val_loss: 0.6321 - val_accuracy: 0.6500\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6293 - accuracy: 0.6981 - val_loss: 0.6294 - val_accuracy: 0.6500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6262 - accuracy: 0.6981 - val_loss: 0.6268 - val_accuracy: 0.6500\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6232 - accuracy: 0.6981 - val_loss: 0.6242 - val_accuracy: 0.6500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6201 - accuracy: 0.6981 - val_loss: 0.6216 - val_accuracy: 0.6500\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6170 - accuracy: 0.7170 - val_loss: 0.6190 - val_accuracy: 0.6500\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6139 - accuracy: 0.7358 - val_loss: 0.6163 - val_accuracy: 0.6500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6106 - accuracy: 0.7358 - val_loss: 0.6138 - val_accuracy: 0.6500\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6075 - accuracy: 0.7358 - val_loss: 0.6111 - val_accuracy: 0.6500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6043 - accuracy: 0.7358 - val_loss: 0.6085 - val_accuracy: 0.6500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6010 - accuracy: 0.7358 - val_loss: 0.6057 - val_accuracy: 0.6500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5978 - accuracy: 0.7358 - val_loss: 0.6030 - val_accuracy: 0.6500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5945 - accuracy: 0.7358 - val_loss: 0.6001 - val_accuracy: 0.6500\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5911 - accuracy: 0.7358 - val_loss: 0.5972 - val_accuracy: 0.6500\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5878 - accuracy: 0.7547 - val_loss: 0.5943 - val_accuracy: 0.6500\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5843 - accuracy: 0.7547 - val_loss: 0.5914 - val_accuracy: 0.7500\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5808 - accuracy: 0.7736 - val_loss: 0.5884 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5773 - accuracy: 0.8113 - val_loss: 0.5854 - val_accuracy: 0.8500\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5737 - accuracy: 0.8113 - val_loss: 0.5823 - val_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5700 - accuracy: 0.8302 - val_loss: 0.5791 - val_accuracy: 0.8500\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5663 - accuracy: 0.8302 - val_loss: 0.5759 - val_accuracy: 0.8500\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5625 - accuracy: 0.8302 - val_loss: 0.5726 - val_accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5586 - accuracy: 0.8302 - val_loss: 0.5691 - val_accuracy: 0.8500\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5546 - accuracy: 0.8491 - val_loss: 0.5654 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5504 - accuracy: 0.8679 - val_loss: 0.5615 - val_accuracy: 0.8500\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5460 - accuracy: 0.8868 - val_loss: 0.5575 - val_accuracy: 0.8500\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5416 - accuracy: 0.8868 - val_loss: 0.5535 - val_accuracy: 0.8500\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5371 - accuracy: 0.9057 - val_loss: 0.5493 - val_accuracy: 0.8500\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5326 - accuracy: 0.9245 - val_loss: 0.5449 - val_accuracy: 0.9000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5279 - accuracy: 0.9245 - val_loss: 0.5403 - val_accuracy: 0.9000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5233 - accuracy: 0.9434 - val_loss: 0.5357 - val_accuracy: 0.9000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5185 - accuracy: 0.9434 - val_loss: 0.5310 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5136 - accuracy: 0.9434 - val_loss: 0.5263 - val_accuracy: 0.9000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5087 - accuracy: 0.9434 - val_loss: 0.5216 - val_accuracy: 0.9000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5036 - accuracy: 0.9434 - val_loss: 0.5168 - val_accuracy: 0.9000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4986 - accuracy: 0.9434 - val_loss: 0.5120 - val_accuracy: 0.9000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4934 - accuracy: 0.9434 - val_loss: 0.5070 - val_accuracy: 0.9000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4881 - accuracy: 0.9434 - val_loss: 0.5020 - val_accuracy: 0.9000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4827 - accuracy: 0.9434 - val_loss: 0.4969 - val_accuracy: 0.9000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4773 - accuracy: 0.9811 - val_loss: 0.4918 - val_accuracy: 0.9000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4719 - accuracy: 0.9811 - val_loss: 0.4864 - val_accuracy: 0.9000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4663 - accuracy: 0.9811 - val_loss: 0.4809 - val_accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4607 - accuracy: 0.9811 - val_loss: 0.4753 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4550 - accuracy: 0.9811 - val_loss: 0.4696 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4492 - accuracy: 0.9811 - val_loss: 0.4637 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4433 - accuracy: 0.9811 - val_loss: 0.4575 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4373 - accuracy: 0.9811 - val_loss: 0.4513 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4311 - accuracy: 0.9811 - val_loss: 0.4448 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4247 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4183 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4118 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4050 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3982 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3912 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3841 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3768 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3693 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3616 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3538 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3460 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3381 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3303 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3225 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3148 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3071 - accuracy: 1.0000 - val_loss: 0.3157 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2995 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2920 - accuracy: 1.0000 - val_loss: 0.2999 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2847 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2773 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2701 - accuracy: 1.0000 - val_loss: 0.2769 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2631 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2561 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2493 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2426 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2359 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2295 - accuracy: 1.0000 - val_loss: 0.2345 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2232 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2050 - accuracy: 1.0000 - val_loss: 0.2092 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1992 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1935 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1880 - accuracy: 1.0000 - val_loss: 0.1917 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1826 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1774 - accuracy: 1.0000 - val_loss: 0.1809 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1722 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1673 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1479 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 884ms/step - loss: 0.7084 - accuracy: 0.4717 - val_loss: 0.7036 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7040 - accuracy: 0.4906 - val_loss: 0.6996 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6997 - accuracy: 0.5094 - val_loss: 0.6956 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6954 - accuracy: 0.5472 - val_loss: 0.6917 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6913 - accuracy: 0.5660 - val_loss: 0.6877 - val_accuracy: 0.6500\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6872 - accuracy: 0.5849 - val_loss: 0.6839 - val_accuracy: 0.6500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6832 - accuracy: 0.6226 - val_loss: 0.6801 - val_accuracy: 0.6500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6794 - accuracy: 0.6415 - val_loss: 0.6762 - val_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6755 - accuracy: 0.6604 - val_loss: 0.6724 - val_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6718 - accuracy: 0.6792 - val_loss: 0.6685 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6680 - accuracy: 0.7170 - val_loss: 0.6645 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6642 - accuracy: 0.7547 - val_loss: 0.6606 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6603 - accuracy: 0.7925 - val_loss: 0.6568 - val_accuracy: 0.8000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6565 - accuracy: 0.8679 - val_loss: 0.6529 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6526 - accuracy: 0.8679 - val_loss: 0.6490 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6487 - accuracy: 0.9057 - val_loss: 0.6452 - val_accuracy: 0.9500\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6448 - accuracy: 0.9057 - val_loss: 0.6414 - val_accuracy: 0.9500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6408 - accuracy: 0.9057 - val_loss: 0.6375 - val_accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6368 - accuracy: 0.9434 - val_loss: 0.6335 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6327 - accuracy: 0.9623 - val_loss: 0.6296 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6287 - accuracy: 0.9623 - val_loss: 0.6258 - val_accuracy: 0.9500\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6246 - accuracy: 0.9623 - val_loss: 0.6220 - val_accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6205 - accuracy: 0.9623 - val_loss: 0.6183 - val_accuracy: 0.9500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6163 - accuracy: 0.9623 - val_loss: 0.6145 - val_accuracy: 0.9500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6120 - accuracy: 0.9811 - val_loss: 0.6107 - val_accuracy: 0.9500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6077 - accuracy: 0.9811 - val_loss: 0.6069 - val_accuracy: 0.9500\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6034 - accuracy: 0.9811 - val_loss: 0.6030 - val_accuracy: 0.9500\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5989 - accuracy: 0.9811 - val_loss: 0.5991 - val_accuracy: 0.9500\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5944 - accuracy: 0.9811 - val_loss: 0.5951 - val_accuracy: 0.9500\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5898 - accuracy: 0.9811 - val_loss: 0.5912 - val_accuracy: 0.9500\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5851 - accuracy: 0.9811 - val_loss: 0.5871 - val_accuracy: 0.9500\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5804 - accuracy: 0.9811 - val_loss: 0.5830 - val_accuracy: 0.9500\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5757 - accuracy: 0.9811 - val_loss: 0.5788 - val_accuracy: 0.9500\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5709 - accuracy: 0.9811 - val_loss: 0.5744 - val_accuracy: 0.9500\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5660 - accuracy: 0.9811 - val_loss: 0.5700 - val_accuracy: 0.9500\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5612 - accuracy: 0.9811 - val_loss: 0.5656 - val_accuracy: 0.9500\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5563 - accuracy: 0.9811 - val_loss: 0.5611 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5513 - accuracy: 0.9811 - val_loss: 0.5566 - val_accuracy: 0.9500\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5463 - accuracy: 0.9811 - val_loss: 0.5519 - val_accuracy: 0.9500\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5412 - accuracy: 0.9811 - val_loss: 0.5471 - val_accuracy: 0.9500\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5360 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.9500\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5308 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.9500\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5256 - accuracy: 1.0000 - val_loss: 0.5322 - val_accuracy: 0.9500\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5203 - accuracy: 1.0000 - val_loss: 0.5270 - val_accuracy: 0.9500\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5149 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.9500\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5095 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.9500\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5040 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.9500\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4986 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4930 - accuracy: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4873 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9500\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4817 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.9500\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4759 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9500\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4700 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9500\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4641 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9500\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4582 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4521 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9500\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4460 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.9500\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4398 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9500\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4336 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4272 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.9500\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4208 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9500\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4144 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9500\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4079 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.9500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4014 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9500\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3949 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3884 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.9500\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3818 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3752 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 0.9500\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3685 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9500\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3620 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.9500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3554 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.9500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3488 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9500\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3423 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.9500\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3357 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9500\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3292 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9500\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3228 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9500\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3163 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9500\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3099 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3036 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9500\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2973 - accuracy: 1.0000 - val_loss: 0.3193 - val_accuracy: 0.9500\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2911 - accuracy: 1.0000 - val_loss: 0.3140 - val_accuracy: 0.9500\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2850 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.9500\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2789 - accuracy: 1.0000 - val_loss: 0.3034 - val_accuracy: 0.9500\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2729 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9500\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2669 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9500\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2610 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2551 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9500\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2494 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 0.9500\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2437 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 0.9500\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9500\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2325 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9500\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.2270 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9500\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2216 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9500\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.2503 - val_accuracy: 0.9500\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9500\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2058 - accuracy: 1.0000 - val_loss: 0.2416 - val_accuracy: 0.9500\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2007 - accuracy: 1.0000 - val_loss: 0.2372 - val_accuracy: 0.9500\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1956 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9500\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1908 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9500\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1859 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1479 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 861ms/step - loss: 0.8604 - accuracy: 0.5000 - val_loss: 0.8494 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8461 - accuracy: 0.5185 - val_loss: 0.8369 - val_accuracy: 0.4000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.8320 - accuracy: 0.5185 - val_loss: 0.8244 - val_accuracy: 0.4000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8182 - accuracy: 0.5741 - val_loss: 0.8119 - val_accuracy: 0.4000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.8046 - accuracy: 0.5926 - val_loss: 0.7997 - val_accuracy: 0.4500\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7912 - accuracy: 0.6111 - val_loss: 0.7876 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7781 - accuracy: 0.6111 - val_loss: 0.7758 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7655 - accuracy: 0.6296 - val_loss: 0.7644 - val_accuracy: 0.5500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7534 - accuracy: 0.6296 - val_loss: 0.7531 - val_accuracy: 0.5500\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7415 - accuracy: 0.6481 - val_loss: 0.7422 - val_accuracy: 0.5500\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7300 - accuracy: 0.6481 - val_loss: 0.7315 - val_accuracy: 0.5500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7188 - accuracy: 0.6481 - val_loss: 0.7209 - val_accuracy: 0.5500\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7078 - accuracy: 0.6481 - val_loss: 0.7106 - val_accuracy: 0.5500\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6971 - accuracy: 0.6481 - val_loss: 0.7005 - val_accuracy: 0.5500\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6866 - accuracy: 0.6481 - val_loss: 0.6908 - val_accuracy: 0.6000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6761 - accuracy: 0.6481 - val_loss: 0.6814 - val_accuracy: 0.6000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6660 - accuracy: 0.6481 - val_loss: 0.6720 - val_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6562 - accuracy: 0.6481 - val_loss: 0.6628 - val_accuracy: 0.6000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6465 - accuracy: 0.6667 - val_loss: 0.6541 - val_accuracy: 0.6000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6370 - accuracy: 0.6852 - val_loss: 0.6456 - val_accuracy: 0.6500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6278 - accuracy: 0.6852 - val_loss: 0.6374 - val_accuracy: 0.6500\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6185 - accuracy: 0.6852 - val_loss: 0.6294 - val_accuracy: 0.6500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6095 - accuracy: 0.7037 - val_loss: 0.6213 - val_accuracy: 0.6500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6005 - accuracy: 0.7037 - val_loss: 0.6136 - val_accuracy: 0.6500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5919 - accuracy: 0.7037 - val_loss: 0.6057 - val_accuracy: 0.6500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5832 - accuracy: 0.7037 - val_loss: 0.5979 - val_accuracy: 0.6500\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5747 - accuracy: 0.7778 - val_loss: 0.5902 - val_accuracy: 0.6500\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5662 - accuracy: 0.7963 - val_loss: 0.5824 - val_accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5577 - accuracy: 0.7963 - val_loss: 0.5746 - val_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5493 - accuracy: 0.8148 - val_loss: 0.5670 - val_accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5409 - accuracy: 0.8148 - val_loss: 0.5593 - val_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5325 - accuracy: 0.8148 - val_loss: 0.5520 - val_accuracy: 0.7000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5242 - accuracy: 0.8333 - val_loss: 0.5446 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5158 - accuracy: 0.8704 - val_loss: 0.5374 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5075 - accuracy: 0.8704 - val_loss: 0.5301 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4992 - accuracy: 0.8704 - val_loss: 0.5228 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4909 - accuracy: 0.8704 - val_loss: 0.5154 - val_accuracy: 0.8500\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4826 - accuracy: 0.8889 - val_loss: 0.5080 - val_accuracy: 0.8500\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4743 - accuracy: 0.8889 - val_loss: 0.5006 - val_accuracy: 0.9000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4661 - accuracy: 0.9074 - val_loss: 0.4932 - val_accuracy: 0.9000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4578 - accuracy: 0.9259 - val_loss: 0.4858 - val_accuracy: 0.9000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4496 - accuracy: 0.9259 - val_loss: 0.4785 - val_accuracy: 0.9500\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4414 - accuracy: 0.9444 - val_loss: 0.4710 - val_accuracy: 0.9500\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4332 - accuracy: 0.9630 - val_loss: 0.4637 - val_accuracy: 0.9500\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4251 - accuracy: 0.9630 - val_loss: 0.4562 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4169 - accuracy: 0.9815 - val_loss: 0.4488 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4088 - accuracy: 0.9815 - val_loss: 0.4415 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4007 - accuracy: 0.9815 - val_loss: 0.4342 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3928 - accuracy: 0.9815 - val_loss: 0.4269 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3848 - accuracy: 0.9815 - val_loss: 0.4198 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3769 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3690 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3612 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3533 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3455 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3378 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3301 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3227 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3154 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3083 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3012 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2942 - accuracy: 1.0000 - val_loss: 0.3402 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2875 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2808 - accuracy: 1.0000 - val_loss: 0.3281 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2743 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2680 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2617 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2555 - accuracy: 1.0000 - val_loss: 0.3050 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2495 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 0.2941 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2378 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2322 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2215 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2111 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2061 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2012 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1965 - accuracy: 1.0000 - val_loss: 0.2498 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1918 - accuracy: 1.0000 - val_loss: 0.2454 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1873 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1829 - accuracy: 1.0000 - val_loss: 0.2365 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1786 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1744 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1703 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1664 - accuracy: 1.0000 - val_loss: 0.2201 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1624 - accuracy: 1.0000 - val_loss: 0.2162 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1586 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1549 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1512 - accuracy: 1.0000 - val_loss: 0.2049 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1477 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1442 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1408 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1375 - accuracy: 1.0000 - val_loss: 0.1907 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1343 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 0.1807 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1252 - accuracy: 1.0000 - val_loss: 0.1775 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1195 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1347 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.7038 - accuracy: 0.3396 - val_loss: 0.6981 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6980 - accuracy: 0.4340 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6921 - accuracy: 0.5094 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6864 - accuracy: 0.5660 - val_loss: 0.6842 - val_accuracy: 0.4500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6806 - accuracy: 0.5660 - val_loss: 0.6797 - val_accuracy: 0.4500\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6750 - accuracy: 0.5660 - val_loss: 0.6754 - val_accuracy: 0.4500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6694 - accuracy: 0.5660 - val_loss: 0.6711 - val_accuracy: 0.4500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6639 - accuracy: 0.5660 - val_loss: 0.6668 - val_accuracy: 0.4500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6584 - accuracy: 0.5660 - val_loss: 0.6625 - val_accuracy: 0.4000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6530 - accuracy: 0.5660 - val_loss: 0.6583 - val_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6477 - accuracy: 0.5660 - val_loss: 0.6542 - val_accuracy: 0.4000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6424 - accuracy: 0.5660 - val_loss: 0.6502 - val_accuracy: 0.4000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6371 - accuracy: 0.5660 - val_loss: 0.6463 - val_accuracy: 0.4000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6319 - accuracy: 0.5660 - val_loss: 0.6423 - val_accuracy: 0.4000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6268 - accuracy: 0.5660 - val_loss: 0.6384 - val_accuracy: 0.4000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6216 - accuracy: 0.5660 - val_loss: 0.6347 - val_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6166 - accuracy: 0.5660 - val_loss: 0.6310 - val_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6116 - accuracy: 0.5660 - val_loss: 0.6273 - val_accuracy: 0.4000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6067 - accuracy: 0.5660 - val_loss: 0.6236 - val_accuracy: 0.4000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6018 - accuracy: 0.5660 - val_loss: 0.6200 - val_accuracy: 0.4000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5970 - accuracy: 0.5660 - val_loss: 0.6164 - val_accuracy: 0.4000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5922 - accuracy: 0.5660 - val_loss: 0.6129 - val_accuracy: 0.4000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5874 - accuracy: 0.5660 - val_loss: 0.6095 - val_accuracy: 0.4000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5827 - accuracy: 0.5660 - val_loss: 0.6062 - val_accuracy: 0.4000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5780 - accuracy: 0.5660 - val_loss: 0.6029 - val_accuracy: 0.4000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5733 - accuracy: 0.5660 - val_loss: 0.5997 - val_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5687 - accuracy: 0.5660 - val_loss: 0.5966 - val_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5642 - accuracy: 0.5660 - val_loss: 0.5936 - val_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5597 - accuracy: 0.5660 - val_loss: 0.5907 - val_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5552 - accuracy: 0.5660 - val_loss: 0.5878 - val_accuracy: 0.4000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5507 - accuracy: 0.5660 - val_loss: 0.5850 - val_accuracy: 0.4000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5463 - accuracy: 0.5849 - val_loss: 0.5822 - val_accuracy: 0.4000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5419 - accuracy: 0.5849 - val_loss: 0.5793 - val_accuracy: 0.4000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5375 - accuracy: 0.6038 - val_loss: 0.5764 - val_accuracy: 0.4000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5331 - accuracy: 0.6038 - val_loss: 0.5736 - val_accuracy: 0.4000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5288 - accuracy: 0.6038 - val_loss: 0.5706 - val_accuracy: 0.4000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5244 - accuracy: 0.6038 - val_loss: 0.5678 - val_accuracy: 0.4000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5201 - accuracy: 0.6038 - val_loss: 0.5649 - val_accuracy: 0.4000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5157 - accuracy: 0.6038 - val_loss: 0.5619 - val_accuracy: 0.5500\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5114 - accuracy: 0.6792 - val_loss: 0.5589 - val_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5069 - accuracy: 0.7925 - val_loss: 0.5558 - val_accuracy: 0.6000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5023 - accuracy: 0.8113 - val_loss: 0.5527 - val_accuracy: 0.6000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4978 - accuracy: 0.8302 - val_loss: 0.5496 - val_accuracy: 0.6000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4933 - accuracy: 0.8302 - val_loss: 0.5465 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4887 - accuracy: 0.8491 - val_loss: 0.5434 - val_accuracy: 0.6500\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4841 - accuracy: 0.8679 - val_loss: 0.5402 - val_accuracy: 0.6500\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4796 - accuracy: 0.9057 - val_loss: 0.5370 - val_accuracy: 0.6500\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4750 - accuracy: 0.9057 - val_loss: 0.5338 - val_accuracy: 0.7000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4705 - accuracy: 0.9057 - val_loss: 0.5306 - val_accuracy: 0.7000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4658 - accuracy: 0.9245 - val_loss: 0.5274 - val_accuracy: 0.7000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4613 - accuracy: 0.9245 - val_loss: 0.5241 - val_accuracy: 0.7000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4567 - accuracy: 0.9245 - val_loss: 0.5209 - val_accuracy: 0.7000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4522 - accuracy: 0.9245 - val_loss: 0.5176 - val_accuracy: 0.7000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4476 - accuracy: 0.9245 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4429 - accuracy: 0.9434 - val_loss: 0.5111 - val_accuracy: 0.8500\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4384 - accuracy: 0.9623 - val_loss: 0.5079 - val_accuracy: 0.8500\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4338 - accuracy: 0.9623 - val_loss: 0.5046 - val_accuracy: 0.8500\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4292 - accuracy: 0.9623 - val_loss: 0.5014 - val_accuracy: 0.9000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4247 - accuracy: 0.9623 - val_loss: 0.4982 - val_accuracy: 0.9000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4201 - accuracy: 0.9623 - val_loss: 0.4949 - val_accuracy: 0.9000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4155 - accuracy: 0.9623 - val_loss: 0.4917 - val_accuracy: 0.9000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4109 - accuracy: 0.9623 - val_loss: 0.4885 - val_accuracy: 0.9000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4064 - accuracy: 0.9623 - val_loss: 0.4852 - val_accuracy: 0.9000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4019 - accuracy: 0.9623 - val_loss: 0.4820 - val_accuracy: 0.9000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3973 - accuracy: 0.9623 - val_loss: 0.4788 - val_accuracy: 0.9000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3927 - accuracy: 0.9811 - val_loss: 0.4755 - val_accuracy: 0.9000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3881 - accuracy: 0.9811 - val_loss: 0.4723 - val_accuracy: 0.9000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3836 - accuracy: 0.9811 - val_loss: 0.4691 - val_accuracy: 0.9000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3790 - accuracy: 0.9811 - val_loss: 0.4658 - val_accuracy: 0.9000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3744 - accuracy: 0.9811 - val_loss: 0.4624 - val_accuracy: 0.9000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3698 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3652 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3606 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.9000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3561 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3515 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3469 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.9000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3424 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3379 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3335 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3291 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3246 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3202 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3159 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3116 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3073 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3031 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2988 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.9000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2947 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2905 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2865 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2823 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2783 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2743 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2703 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2663 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2624 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2585 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2546 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2508 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2470 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2757 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 878ms/step - loss: 0.6795 - accuracy: 0.4906 - val_loss: 0.6709 - val_accuracy: 0.6500\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6727 - accuracy: 0.5094 - val_loss: 0.6645 - val_accuracy: 0.6500\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6660 - accuracy: 0.5094 - val_loss: 0.6582 - val_accuracy: 0.6500\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6593 - accuracy: 0.5472 - val_loss: 0.6518 - val_accuracy: 0.6500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6526 - accuracy: 0.5660 - val_loss: 0.6455 - val_accuracy: 0.6500\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6461 - accuracy: 0.5849 - val_loss: 0.6392 - val_accuracy: 0.6500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6396 - accuracy: 0.6038 - val_loss: 0.6330 - val_accuracy: 0.6500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6332 - accuracy: 0.6226 - val_loss: 0.6269 - val_accuracy: 0.6500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6269 - accuracy: 0.6226 - val_loss: 0.6211 - val_accuracy: 0.6500\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6206 - accuracy: 0.6604 - val_loss: 0.6155 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6145 - accuracy: 0.6981 - val_loss: 0.6098 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6084 - accuracy: 0.7547 - val_loss: 0.6040 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6024 - accuracy: 0.8113 - val_loss: 0.5981 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5963 - accuracy: 0.8679 - val_loss: 0.5922 - val_accuracy: 0.8500\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5903 - accuracy: 0.9245 - val_loss: 0.5862 - val_accuracy: 0.9500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5843 - accuracy: 0.9245 - val_loss: 0.5804 - val_accuracy: 0.9500\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5783 - accuracy: 0.9434 - val_loss: 0.5746 - val_accuracy: 0.9500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5724 - accuracy: 0.9623 - val_loss: 0.5689 - val_accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5666 - accuracy: 0.9811 - val_loss: 0.5631 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5608 - accuracy: 1.0000 - val_loss: 0.5573 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5550 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5494 - accuracy: 1.0000 - val_loss: 0.5460 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5438 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5383 - accuracy: 1.0000 - val_loss: 0.5349 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5328 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5273 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5219 - accuracy: 1.0000 - val_loss: 0.5186 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5165 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5111 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5057 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5002 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4948 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4892 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4836 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4780 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4723 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4665 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4608 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4549 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4489 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4429 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4368 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4305 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4243 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4179 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4116 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4052 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3988 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3924 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3858 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3792 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3727 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3661 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3594 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3528 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3462 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3396 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3329 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3264 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3197 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3130 - accuracy: 1.0000 - val_loss: 0.3205 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3064 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2997 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2930 - accuracy: 1.0000 - val_loss: 0.3025 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2864 - accuracy: 1.0000 - val_loss: 0.2966 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2799 - accuracy: 1.0000 - val_loss: 0.2906 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2734 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2670 - accuracy: 1.0000 - val_loss: 0.2791 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2606 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2542 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2479 - accuracy: 1.0000 - val_loss: 0.2620 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2416 - accuracy: 1.0000 - val_loss: 0.2564 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2355 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2294 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2234 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2174 - accuracy: 1.0000 - val_loss: 0.2347 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2117 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2059 - accuracy: 1.0000 - val_loss: 0.2243 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2004 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1949 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1895 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1843 - accuracy: 1.0000 - val_loss: 0.2050 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1791 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1742 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1693 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1645 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1598 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1552 - accuracy: 1.0000 - val_loss: 0.1794 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1508 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1464 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1422 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1380 - accuracy: 1.0000 - val_loss: 0.1643 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1339 - accuracy: 1.0000 - val_loss: 0.1606 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1299 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1260 - accuracy: 1.0000 - val_loss: 0.1538 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1186 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1150 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1115 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1133 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.7590 - accuracy: 0.3333 - val_loss: 0.7623 - val_accuracy: 0.2000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.7491 - accuracy: 0.3704 - val_loss: 0.7523 - val_accuracy: 0.2500\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7392 - accuracy: 0.4074 - val_loss: 0.7425 - val_accuracy: 0.3000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7297 - accuracy: 0.4259 - val_loss: 0.7331 - val_accuracy: 0.3000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7205 - accuracy: 0.5185 - val_loss: 0.7239 - val_accuracy: 0.4500\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7117 - accuracy: 0.5370 - val_loss: 0.7151 - val_accuracy: 0.5500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7031 - accuracy: 0.5926 - val_loss: 0.7064 - val_accuracy: 0.5500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6947 - accuracy: 0.6481 - val_loss: 0.6980 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6866 - accuracy: 0.6852 - val_loss: 0.6901 - val_accuracy: 0.6500\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6787 - accuracy: 0.7778 - val_loss: 0.6826 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6708 - accuracy: 0.8333 - val_loss: 0.6753 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6632 - accuracy: 0.8704 - val_loss: 0.6683 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6558 - accuracy: 0.9074 - val_loss: 0.6616 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6488 - accuracy: 0.9074 - val_loss: 0.6549 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6421 - accuracy: 0.9259 - val_loss: 0.6484 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6357 - accuracy: 0.9444 - val_loss: 0.6420 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6295 - accuracy: 0.9259 - val_loss: 0.6358 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6235 - accuracy: 0.9259 - val_loss: 0.6297 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6175 - accuracy: 0.9630 - val_loss: 0.6237 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6117 - accuracy: 0.9630 - val_loss: 0.6178 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6060 - accuracy: 0.9630 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6005 - accuracy: 0.9815 - val_loss: 0.6060 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5950 - accuracy: 0.9815 - val_loss: 0.6003 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5895 - accuracy: 0.9815 - val_loss: 0.5947 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5841 - accuracy: 0.9815 - val_loss: 0.5891 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5787 - accuracy: 0.9815 - val_loss: 0.5837 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5734 - accuracy: 0.9815 - val_loss: 0.5783 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5680 - accuracy: 0.9815 - val_loss: 0.5731 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5627 - accuracy: 0.9815 - val_loss: 0.5678 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5574 - accuracy: 0.9815 - val_loss: 0.5626 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5520 - accuracy: 0.9815 - val_loss: 0.5573 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5464 - accuracy: 0.9815 - val_loss: 0.5519 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5408 - accuracy: 0.9815 - val_loss: 0.5465 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5350 - accuracy: 0.9815 - val_loss: 0.5410 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5292 - accuracy: 0.9815 - val_loss: 0.5355 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5233 - accuracy: 0.9815 - val_loss: 0.5301 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5173 - accuracy: 0.9815 - val_loss: 0.5247 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5111 - accuracy: 0.9815 - val_loss: 0.5191 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5049 - accuracy: 0.9815 - val_loss: 0.5136 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4986 - accuracy: 1.0000 - val_loss: 0.5079 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4922 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4859 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4796 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4733 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4669 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4606 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4543 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4479 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4415 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4353 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4289 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4226 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4164 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4102 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4040 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3979 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3917 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3857 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3796 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3736 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3676 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3617 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3558 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3498 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3439 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3380 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3321 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3263 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3205 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3146 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3088 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3030 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2973 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2915 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2859 - accuracy: 1.0000 - val_loss: 0.3106 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2802 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2746 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2691 - accuracy: 1.0000 - val_loss: 0.2950 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2636 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2529 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2476 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2424 - accuracy: 1.0000 - val_loss: 0.2700 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2372 - accuracy: 1.0000 - val_loss: 0.2652 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2321 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2271 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2222 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2172 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2076 - accuracy: 1.0000 - val_loss: 0.2377 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2028 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1982 - accuracy: 1.0000 - val_loss: 0.2290 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1935 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1890 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1845 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1801 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1758 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1716 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1674 - accuracy: 1.0000 - val_loss: 0.2004 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1632 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1431 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 858ms/step - loss: 0.6374 - accuracy: 0.7547 - val_loss: 0.6020 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6109 - accuracy: 0.8491 - val_loss: 0.5809 - val_accuracy: 0.9500\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5852 - accuracy: 0.9057 - val_loss: 0.5605 - val_accuracy: 0.9500\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5604 - accuracy: 0.9245 - val_loss: 0.5409 - val_accuracy: 0.9500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5364 - accuracy: 0.9623 - val_loss: 0.5219 - val_accuracy: 0.9500\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5133 - accuracy: 0.9811 - val_loss: 0.5037 - val_accuracy: 0.9500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4911 - accuracy: 0.9811 - val_loss: 0.4862 - val_accuracy: 0.9500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4698 - accuracy: 0.9811 - val_loss: 0.4694 - val_accuracy: 0.9500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4494 - accuracy: 0.9811 - val_loss: 0.4532 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4298 - accuracy: 0.9811 - val_loss: 0.4376 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4110 - accuracy: 0.9811 - val_loss: 0.4226 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3931 - accuracy: 0.9811 - val_loss: 0.4081 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3759 - accuracy: 0.9811 - val_loss: 0.3942 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3595 - accuracy: 0.9811 - val_loss: 0.3808 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3439 - accuracy: 0.9811 - val_loss: 0.3680 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3290 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3147 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3012 - accuracy: 1.0000 - val_loss: 0.3318 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2881 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2759 - accuracy: 1.0000 - val_loss: 0.3096 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2640 - accuracy: 1.0000 - val_loss: 0.2991 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2528 - accuracy: 1.0000 - val_loss: 0.2890 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2421 - accuracy: 1.0000 - val_loss: 0.2793 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2321 - accuracy: 1.0000 - val_loss: 0.2698 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2224 - accuracy: 1.0000 - val_loss: 0.2606 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2131 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2043 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1961 - accuracy: 1.0000 - val_loss: 0.2352 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1882 - accuracy: 1.0000 - val_loss: 0.2273 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1805 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1735 - accuracy: 1.0000 - val_loss: 0.2125 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1666 - accuracy: 1.0000 - val_loss: 0.2056 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1601 - accuracy: 1.0000 - val_loss: 0.1989 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1540 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1482 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1426 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1373 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1276 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1231 - accuracy: 1.0000 - val_loss: 0.1597 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1188 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1147 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1109 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1071 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1036 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1003 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0912 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0858 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0787 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0687 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0670 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0554 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0427 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0391 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9318 - accuracy: 0.0755 - val_loss: 0.8515 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9080 - accuracy: 0.0755 - val_loss: 0.8295 - val_accuracy: 0.1500\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.8847 - accuracy: 0.0755 - val_loss: 0.8079 - val_accuracy: 0.1500\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.8616 - accuracy: 0.0755 - val_loss: 0.7863 - val_accuracy: 0.2000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.8386 - accuracy: 0.1132 - val_loss: 0.7654 - val_accuracy: 0.3000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8161 - accuracy: 0.1698 - val_loss: 0.7447 - val_accuracy: 0.4500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7939 - accuracy: 0.2075 - val_loss: 0.7245 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7722 - accuracy: 0.2453 - val_loss: 0.7045 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7506 - accuracy: 0.3019 - val_loss: 0.6851 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7296 - accuracy: 0.3962 - val_loss: 0.6659 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7089 - accuracy: 0.4906 - val_loss: 0.6474 - val_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6886 - accuracy: 0.5283 - val_loss: 0.6292 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6690 - accuracy: 0.5660 - val_loss: 0.6117 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6498 - accuracy: 0.6604 - val_loss: 0.5945 - val_accuracy: 0.9500\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6310 - accuracy: 0.7358 - val_loss: 0.5777 - val_accuracy: 0.9500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6127 - accuracy: 0.8491 - val_loss: 0.5616 - val_accuracy: 0.9500\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5951 - accuracy: 0.8868 - val_loss: 0.5458 - val_accuracy: 0.9500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5779 - accuracy: 0.8868 - val_loss: 0.5306 - val_accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5611 - accuracy: 0.9057 - val_loss: 0.5159 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5450 - accuracy: 0.9245 - val_loss: 0.5016 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5292 - accuracy: 0.9623 - val_loss: 0.4878 - val_accuracy: 0.9500\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5139 - accuracy: 0.9623 - val_loss: 0.4744 - val_accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4992 - accuracy: 0.9811 - val_loss: 0.4617 - val_accuracy: 0.9500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4850 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4712 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4578 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4448 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4323 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4202 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4086 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3973 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3863 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3758 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3656 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3556 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3462 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3370 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3282 - accuracy: 1.0000 - val_loss: 0.3144 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3195 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3112 - accuracy: 1.0000 - val_loss: 0.3001 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3033 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2955 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2881 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2808 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2738 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2671 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2606 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2544 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2483 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2425 - accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2367 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2313 - accuracy: 1.0000 - val_loss: 0.2314 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2260 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2208 - accuracy: 1.0000 - val_loss: 0.2222 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2158 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2110 - accuracy: 1.0000 - val_loss: 0.2137 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2064 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2019 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1975 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1933 - accuracy: 1.0000 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1892 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1852 - accuracy: 1.0000 - val_loss: 0.1905 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1813 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1776 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1740 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1705 - accuracy: 1.0000 - val_loss: 0.1770 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1670 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1637 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1605 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1573 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1543 - accuracy: 1.0000 - val_loss: 0.1621 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1514 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1485 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1457 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1430 - accuracy: 1.0000 - val_loss: 0.1514 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1404 - accuracy: 1.0000 - val_loss: 0.1489 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1378 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1353 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1328 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1282 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1260 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1238 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1176 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1156 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1119 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1100 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1083 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1065 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1048 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1032 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0970 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0968 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.7099 - accuracy: 0.5000 - val_loss: 0.6518 - val_accuracy: 0.5500\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6914 - accuracy: 0.5370 - val_loss: 0.6382 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6736 - accuracy: 0.5926 - val_loss: 0.6249 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6561 - accuracy: 0.6111 - val_loss: 0.6121 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6392 - accuracy: 0.6481 - val_loss: 0.5997 - val_accuracy: 0.6000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6227 - accuracy: 0.6852 - val_loss: 0.5875 - val_accuracy: 0.6500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6067 - accuracy: 0.7222 - val_loss: 0.5755 - val_accuracy: 0.7000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5909 - accuracy: 0.7407 - val_loss: 0.5640 - val_accuracy: 0.7500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5757 - accuracy: 0.7778 - val_loss: 0.5527 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5609 - accuracy: 0.7963 - val_loss: 0.5416 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5463 - accuracy: 0.8148 - val_loss: 0.5310 - val_accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5323 - accuracy: 0.8889 - val_loss: 0.5204 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5186 - accuracy: 0.8889 - val_loss: 0.5101 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5053 - accuracy: 0.8889 - val_loss: 0.5000 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4922 - accuracy: 0.9074 - val_loss: 0.4900 - val_accuracy: 0.9500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4795 - accuracy: 0.9259 - val_loss: 0.4802 - val_accuracy: 0.9500\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4671 - accuracy: 0.9259 - val_loss: 0.4707 - val_accuracy: 0.9500\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4550 - accuracy: 0.9259 - val_loss: 0.4612 - val_accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4431 - accuracy: 0.9444 - val_loss: 0.4519 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4316 - accuracy: 0.9630 - val_loss: 0.4426 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4202 - accuracy: 0.9630 - val_loss: 0.4335 - val_accuracy: 0.9500\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4092 - accuracy: 0.9630 - val_loss: 0.4245 - val_accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3984 - accuracy: 0.9630 - val_loss: 0.4156 - val_accuracy: 0.9500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3878 - accuracy: 0.9630 - val_loss: 0.4067 - val_accuracy: 0.9500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3775 - accuracy: 0.9630 - val_loss: 0.3980 - val_accuracy: 0.9500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3674 - accuracy: 0.9630 - val_loss: 0.3894 - val_accuracy: 0.9500\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3576 - accuracy: 0.9630 - val_loss: 0.3808 - val_accuracy: 0.9500\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3479 - accuracy: 0.9630 - val_loss: 0.3722 - val_accuracy: 0.9500\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3383 - accuracy: 0.9815 - val_loss: 0.3639 - val_accuracy: 0.9500\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3292 - accuracy: 0.9815 - val_loss: 0.3556 - val_accuracy: 0.9500\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3201 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9500\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3112 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9500\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3026 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.9500\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2942 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9500\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2860 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9500\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2779 - accuracy: 1.0000 - val_loss: 0.3078 - val_accuracy: 0.9500\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2701 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2624 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2550 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2477 - accuracy: 1.0000 - val_loss: 0.2783 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2406 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2338 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.2578 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2207 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2143 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2082 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2023 - accuracy: 1.0000 - val_loss: 0.2324 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1965 - accuracy: 1.0000 - val_loss: 0.2265 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1909 - accuracy: 1.0000 - val_loss: 0.2208 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1856 - accuracy: 1.0000 - val_loss: 0.2151 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1803 - accuracy: 1.0000 - val_loss: 0.2097 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1752 - accuracy: 1.0000 - val_loss: 0.2045 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1703 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1655 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1609 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1522 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1480 - accuracy: 1.0000 - val_loss: 0.1761 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1440 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1401 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1363 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1327 - accuracy: 1.0000 - val_loss: 0.1601 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1292 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1258 - accuracy: 1.0000 - val_loss: 0.1528 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1226 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1194 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1164 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1106 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1052 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0978 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0911 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0890 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0833 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0703 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0627 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0489 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 867ms/step - loss: 0.7662 - accuracy: 0.0375 - val_loss: 0.7372 - val_accuracy: 0.0500\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7498 - accuracy: 0.0625 - val_loss: 0.7246 - val_accuracy: 0.1500\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.7338 - accuracy: 0.0625 - val_loss: 0.7123 - val_accuracy: 0.3000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7181 - accuracy: 0.1500 - val_loss: 0.7001 - val_accuracy: 0.4500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7027 - accuracy: 0.4000 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6876 - accuracy: 0.6000 - val_loss: 0.6763 - val_accuracy: 0.6000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6728 - accuracy: 0.7250 - val_loss: 0.6648 - val_accuracy: 0.8500\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6582 - accuracy: 0.9125 - val_loss: 0.6535 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6439 - accuracy: 0.9625 - val_loss: 0.6423 - val_accuracy: 0.9000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6300 - accuracy: 0.9625 - val_loss: 0.6313 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6162 - accuracy: 0.9625 - val_loss: 0.6205 - val_accuracy: 0.9000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6028 - accuracy: 0.9625 - val_loss: 0.6097 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5895 - accuracy: 0.9625 - val_loss: 0.5992 - val_accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5765 - accuracy: 0.9625 - val_loss: 0.5886 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5636 - accuracy: 0.9625 - val_loss: 0.5783 - val_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5511 - accuracy: 0.9625 - val_loss: 0.5679 - val_accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5388 - accuracy: 0.9625 - val_loss: 0.5577 - val_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5266 - accuracy: 0.9625 - val_loss: 0.5474 - val_accuracy: 0.9000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5145 - accuracy: 0.9750 - val_loss: 0.5372 - val_accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5027 - accuracy: 0.9750 - val_loss: 0.5270 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4910 - accuracy: 0.9750 - val_loss: 0.5169 - val_accuracy: 0.9500\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4796 - accuracy: 0.9750 - val_loss: 0.5069 - val_accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4683 - accuracy: 0.9750 - val_loss: 0.4967 - val_accuracy: 0.9500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4571 - accuracy: 0.9750 - val_loss: 0.4868 - val_accuracy: 0.9500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4461 - accuracy: 0.9750 - val_loss: 0.4768 - val_accuracy: 0.9500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4352 - accuracy: 0.9750 - val_loss: 0.4669 - val_accuracy: 0.9500\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4245 - accuracy: 0.9750 - val_loss: 0.4570 - val_accuracy: 0.9500\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4139 - accuracy: 0.9750 - val_loss: 0.4473 - val_accuracy: 0.9500\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4035 - accuracy: 0.9750 - val_loss: 0.4375 - val_accuracy: 0.9500\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3932 - accuracy: 0.9750 - val_loss: 0.4280 - val_accuracy: 0.9500\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3831 - accuracy: 0.9750 - val_loss: 0.4184 - val_accuracy: 0.9500\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3731 - accuracy: 0.9750 - val_loss: 0.4090 - val_accuracy: 0.9500\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3633 - accuracy: 0.9750 - val_loss: 0.3998 - val_accuracy: 0.9500\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3537 - accuracy: 0.9750 - val_loss: 0.3906 - val_accuracy: 0.9500\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3442 - accuracy: 0.9750 - val_loss: 0.3816 - val_accuracy: 0.9500\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3349 - accuracy: 0.9750 - val_loss: 0.3728 - val_accuracy: 0.9500\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3257 - accuracy: 0.9750 - val_loss: 0.3641 - val_accuracy: 0.9500\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3168 - accuracy: 0.9750 - val_loss: 0.3557 - val_accuracy: 0.9500\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3080 - accuracy: 0.9875 - val_loss: 0.3473 - val_accuracy: 0.9500\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2994 - accuracy: 0.9875 - val_loss: 0.3391 - val_accuracy: 0.9500\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2909 - accuracy: 0.9875 - val_loss: 0.3312 - val_accuracy: 0.9500\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2827 - accuracy: 0.9875 - val_loss: 0.3234 - val_accuracy: 0.9500\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2747 - accuracy: 0.9875 - val_loss: 0.3158 - val_accuracy: 0.9500\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2668 - accuracy: 0.9875 - val_loss: 0.3084 - val_accuracy: 0.9500\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2591 - accuracy: 0.9875 - val_loss: 0.3011 - val_accuracy: 0.9500\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2516 - accuracy: 0.9875 - val_loss: 0.2941 - val_accuracy: 0.9500\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2443 - accuracy: 0.9875 - val_loss: 0.2872 - val_accuracy: 0.9500\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2372 - accuracy: 0.9875 - val_loss: 0.2806 - val_accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2304 - accuracy: 0.9875 - val_loss: 0.2741 - val_accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2237 - accuracy: 0.9875 - val_loss: 0.2677 - val_accuracy: 0.9500\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2172 - accuracy: 0.9875 - val_loss: 0.2616 - val_accuracy: 0.9500\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2109 - accuracy: 0.9875 - val_loss: 0.2556 - val_accuracy: 0.9500\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2047 - accuracy: 0.9875 - val_loss: 0.2498 - val_accuracy: 0.9500\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1988 - accuracy: 0.9875 - val_loss: 0.2441 - val_accuracy: 0.9500\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1931 - accuracy: 0.9875 - val_loss: 0.2386 - val_accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1875 - accuracy: 0.9875 - val_loss: 0.2332 - val_accuracy: 0.9500\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1822 - accuracy: 0.9875 - val_loss: 0.2280 - val_accuracy: 0.9500\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1770 - accuracy: 0.9875 - val_loss: 0.2229 - val_accuracy: 0.9500\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1720 - accuracy: 0.9875 - val_loss: 0.2180 - val_accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1671 - accuracy: 0.9875 - val_loss: 0.2132 - val_accuracy: 0.9500\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1625 - accuracy: 0.9875 - val_loss: 0.2084 - val_accuracy: 0.9500\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1579 - accuracy: 0.9875 - val_loss: 0.2039 - val_accuracy: 0.9500\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1536 - accuracy: 0.9875 - val_loss: 0.1995 - val_accuracy: 0.9500\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1494 - accuracy: 0.9875 - val_loss: 0.1952 - val_accuracy: 0.9500\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1453 - accuracy: 0.9875 - val_loss: 0.1910 - val_accuracy: 0.9500\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1414 - accuracy: 0.9875 - val_loss: 0.1869 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1377 - accuracy: 0.9875 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1340 - accuracy: 0.9875 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1305 - accuracy: 0.9875 - val_loss: 0.1754 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1271 - accuracy: 0.9875 - val_loss: 0.1718 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1239 - accuracy: 0.9875 - val_loss: 0.1683 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1208 - accuracy: 0.9875 - val_loss: 0.1649 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1177 - accuracy: 0.9875 - val_loss: 0.1616 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1148 - accuracy: 0.9875 - val_loss: 0.1584 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1120 - accuracy: 0.9875 - val_loss: 0.1554 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1093 - accuracy: 0.9875 - val_loss: 0.1523 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1067 - accuracy: 0.9875 - val_loss: 0.1494 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1042 - accuracy: 0.9875 - val_loss: 0.1467 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1018 - accuracy: 0.9875 - val_loss: 0.1439 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0994 - accuracy: 0.9875 - val_loss: 0.1414 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0972 - accuracy: 0.9875 - val_loss: 0.1388 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0950 - accuracy: 0.9875 - val_loss: 0.1364 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0929 - accuracy: 0.9875 - val_loss: 0.1340 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0909 - accuracy: 0.9875 - val_loss: 0.1317 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0889 - accuracy: 0.9875 - val_loss: 0.1295 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0870 - accuracy: 0.9875 - val_loss: 0.1274 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0852 - accuracy: 0.9875 - val_loss: 0.1253 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0834 - accuracy: 0.9875 - val_loss: 0.1233 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0817 - accuracy: 0.9875 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0800 - accuracy: 0.9875 - val_loss: 0.1195 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0784 - accuracy: 0.9875 - val_loss: 0.1177 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0768 - accuracy: 0.9875 - val_loss: 0.1159 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0753 - accuracy: 0.9875 - val_loss: 0.1142 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0739 - accuracy: 0.9875 - val_loss: 0.1125 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0725 - accuracy: 0.9875 - val_loss: 0.1109 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0711 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 0.7503 - accuracy: 0.3846\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7381 - accuracy: 0.4286\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 0.6690 - accuracy: 0.4615\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.6511 - accuracy: 0.2857\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 0.7718 - accuracy: 0.3571\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.7967 - accuracy: 0.5000\n",
      "Best: 1.000000 using {'learning_rate': 0.1, 'epochs': 100, 'batch_size': 256, 'activation': 'tanh'}\n",
      "0.962963 (0.052378) with: {'learning_rate': 0.001, 'epochs': 20, 'batch_size': 32, 'activation': 'relu'}\n",
      "1.000000 (0.000000) with: {'learning_rate': 0.1, 'epochs': 100, 'batch_size': 256, 'activation': 'tanh'}\n",
      "0.387939 (0.065386) with: {'learning_rate': 0.001, 'epochs': 40, 'batch_size': 32, 'activation': 'sigmoid'}\n",
      "0.439221 (0.114625) with: {'learning_rate': 0.001, 'epochs': 20, 'batch_size': 256, 'activation': 'sigmoid'}\n",
      "0.875594 (0.125536) with: {'learning_rate': 0.1, 'epochs': 30, 'batch_size': 128, 'activation': 'relu'}\n",
      "0.765432 (0.331729) with: {'learning_rate': 0.001, 'epochs': 100, 'batch_size': 32, 'activation': 'sigmoid'}\n",
      "1.000000 (0.000000) with: {'learning_rate': 0.01, 'epochs': 200, 'batch_size': 128, 'activation': 'tanh'}\n",
      "1.000000 (0.000000) with: {'learning_rate': 0.1, 'epochs': 100, 'batch_size': 128, 'activation': 'relu'}\n",
      "1.000000 (0.000000) with: {'learning_rate': 0.001, 'epochs': 100, 'batch_size': 256, 'activation': 'relu'}\n",
      "1.000000 (0.000000) with: {'learning_rate': 0.001, 'epochs': 100, 'batch_size': 128, 'activation': 'tanh'}\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:5 out of the last 104 calls to <function Model.make_train_function.<locals>.train_function at 0x000001E807F56670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8826 - accuracy: 0.0750WARNING:tensorflow:5 out of the last 104 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E7EB1221F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 876ms/step - loss: 0.8826 - accuracy: 0.0750 - val_loss: 0.8658 - val_accuracy: 0.0500\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.8552 - accuracy: 0.1000 - val_loss: 0.8438 - val_accuracy: 0.1000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.8286 - accuracy: 0.1250 - val_loss: 0.8221 - val_accuracy: 0.1000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.8025 - accuracy: 0.1625 - val_loss: 0.8009 - val_accuracy: 0.1500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.7772 - accuracy: 0.2125 - val_loss: 0.7803 - val_accuracy: 0.1500\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7524 - accuracy: 0.3375 - val_loss: 0.7602 - val_accuracy: 0.2000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7284 - accuracy: 0.4000 - val_loss: 0.7405 - val_accuracy: 0.3000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7051 - accuracy: 0.4750 - val_loss: 0.7213 - val_accuracy: 0.4500\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6824 - accuracy: 0.5750 - val_loss: 0.7026 - val_accuracy: 0.4500\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6605 - accuracy: 0.6375 - val_loss: 0.6845 - val_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6394 - accuracy: 0.7125 - val_loss: 0.6668 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6188 - accuracy: 0.7750 - val_loss: 0.6494 - val_accuracy: 0.7500\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5990 - accuracy: 0.8500 - val_loss: 0.6325 - val_accuracy: 0.7500\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5798 - accuracy: 0.8500 - val_loss: 0.6160 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5613 - accuracy: 0.8875 - val_loss: 0.5998 - val_accuracy: 0.8000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5433 - accuracy: 0.9000 - val_loss: 0.5840 - val_accuracy: 0.8000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5259 - accuracy: 0.9000 - val_loss: 0.5686 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5092 - accuracy: 0.9125 - val_loss: 0.5534 - val_accuracy: 0.8000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4930 - accuracy: 0.9500 - val_loss: 0.5387 - val_accuracy: 0.8000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4774 - accuracy: 0.9500 - val_loss: 0.5244 - val_accuracy: 0.8000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4623 - accuracy: 0.9750 - val_loss: 0.5104 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4478 - accuracy: 0.9750 - val_loss: 0.4969 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4340 - accuracy: 0.9750 - val_loss: 0.4836 - val_accuracy: 0.9000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4204 - accuracy: 0.9750 - val_loss: 0.4708 - val_accuracy: 0.9000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4076 - accuracy: 0.9750 - val_loss: 0.4583 - val_accuracy: 0.9500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3952 - accuracy: 0.9875 - val_loss: 0.4463 - val_accuracy: 0.9500\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3833 - accuracy: 0.9875 - val_loss: 0.4346 - val_accuracy: 0.9500\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3718 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9500\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3607 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9500\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3502 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3400 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3303 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3210 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3119 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3033 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2950 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2869 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2793 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2720 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2649 - accuracy: 1.0000 - val_loss: 0.3149 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2580 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2515 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2451 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2391 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2332 - accuracy: 1.0000 - val_loss: 0.2826 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2276 - accuracy: 1.0000 - val_loss: 0.2767 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2220 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2169 - accuracy: 1.0000 - val_loss: 0.2659 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2118 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2069 - accuracy: 1.0000 - val_loss: 0.2558 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2022 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1976 - accuracy: 1.0000 - val_loss: 0.2463 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1932 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1890 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1848 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1809 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1771 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1734 - accuracy: 1.0000 - val_loss: 0.2215 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1697 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1663 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1629 - accuracy: 1.0000 - val_loss: 0.2108 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1597 - accuracy: 1.0000 - val_loss: 0.2073 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1565 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1535 - accuracy: 1.0000 - val_loss: 0.2009 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1505 - accuracy: 1.0000 - val_loss: 0.1977 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1477 - accuracy: 1.0000 - val_loss: 0.1947 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1449 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1422 - accuracy: 1.0000 - val_loss: 0.1889 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1396 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1371 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1346 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1322 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1298 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1276 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.1707 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1233 - accuracy: 1.0000 - val_loss: 0.1682 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1212 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1191 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1172 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1153 - accuracy: 1.0000 - val_loss: 0.1595 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1134 - accuracy: 1.0000 - val_loss: 0.1574 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1116 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1098 - accuracy: 1.0000 - val_loss: 0.1533 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 0.1514 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.1495 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1047 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1032 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1016 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1001 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0971 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0957 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0943 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0866 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Import KerasClassifier from tensorflow.keras scikit learn wrappers\n",
    "from tensorflow.keras.wrappers.scikit_learn  import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Creates a model given an activation and learning rate\n",
    "def create_model(learning_rate = 0.1, activation = 'relu', optomizer = 'Adam'):\n",
    "    # Create an Adam optimizer with the given learning rate\n",
    "    # opt = optomizer(lr = learning_rate)\n",
    "  \t# Create model  \n",
    "    model = Sequential() \n",
    "    model.add(Dense(10, input_dim=4, activation=activation)) \n",
    "    model.add(Dense(20, activation=activation)) \n",
    "    model.add(Dense(10, activation=activation)) \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "  \t\n",
    "  \t# Compile your model with your optimizer, loss, and metrics\n",
    "    model.compile(optimizer = optomizer, loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a KerasClassifier\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "# Define the parameters to try out\n",
    "params = {\n",
    "    'activation': ['relu', 'tanh','sigmoid'], \n",
    "    'batch_size': [32, 128, 256], \n",
    "    'epochs': [20,30,40,50, 100, 200], \n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Create a randomize search cv object passing in the parameters to try\n",
    "random_search = RandomizedSearchCV(model, param_distributions = params, cv = KFold(3))\n",
    "h_callback = random_search.fit(x_train, y_train,validation_data=(x_test, y_test))\n",
    "# h_callback = random_search.fit(x_train, y_train)\n",
    "\n",
    "# Calculate the accuracy score for each fold\n",
    "kfolds = cross_val_score(model, x_test, y_test, cv = 3)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (h_callback.best_score_, h_callback.best_params_))\n",
    "\n",
    "means = h_callback.cv_results_['mean_test_score']\n",
    "stds = h_callback.cv_results_['std_test_score']\n",
    "params = h_callback.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Extract best model\n",
    "best_model = random_search.best_estimator_\n",
    "history = best_model.fit(x_train, y_train, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "# Plot test loss during training\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "# Plot test accuracy during training\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "\n",
    "plt.title('Model performance')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['val_loss', 'val_acc'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with keras without hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 1s 124ms/step - loss: 0.5308 - accuracy: 0.5500 - val_loss: 0.5468 - val_accuracy: 0.5500\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5105 - accuracy: 0.5750 - val_loss: 0.5302 - val_accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.4915 - accuracy: 0.6125 - val_loss: 0.5151 - val_accuracy: 0.6500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4726 - accuracy: 0.7000 - val_loss: 0.5012 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4551 - accuracy: 0.8000 - val_loss: 0.4885 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4381 - accuracy: 0.9000 - val_loss: 0.4769 - val_accuracy: 0.8500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4226 - accuracy: 0.9000 - val_loss: 0.4663 - val_accuracy: 0.8500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4075 - accuracy: 0.9250 - val_loss: 0.4563 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3937 - accuracy: 0.9500 - val_loss: 0.4471 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3801 - accuracy: 0.9625 - val_loss: 0.4381 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3675 - accuracy: 0.9625 - val_loss: 0.4295 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3554 - accuracy: 0.9625 - val_loss: 0.4212 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3440 - accuracy: 0.9750 - val_loss: 0.4131 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3331 - accuracy: 0.9875 - val_loss: 0.4052 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3225 - accuracy: 0.9875 - val_loss: 0.3971 - val_accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3119 - accuracy: 0.9875 - val_loss: 0.3891 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3020 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.2918 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9500\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2816 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2718 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3540 - accuracy: 0.9500\n",
      "\n",
      "accuracy: 95.00%\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "[0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_297 (Dense)           (None, 10)                50        \n",
      "                                                                 \n",
      " dense_298 (Dense)           (None, 20)                220       \n",
      "                                                                 \n",
      " dense_299 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " dense_300 (Dense)           (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create model \n",
    "model = Sequential() \n",
    "model.add(Dense(10, input_dim=4, activation='relu')) \n",
    "model.add(Dense(20, activation='relu')) \n",
    "model.add(Dense(10, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compile model \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# Train your model and save its history\n",
    "h_callback = model.fit(x_train, y_train, epochs = 20,\n",
    "               validation_data=(x_test, y_test))\n",
    "\n",
    "# Plot train vs test loss during training\n",
    "plt.plot(h_callback.history['val_loss'])\n",
    "\n",
    "# Plot train vs test accuracy during training\n",
    "plt.plot(h_callback.history['val_accuracy'])\n",
    "\n",
    "plt.title('Model performance')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['val_loss', 'val_acc'], loc='upper left')\n",
    "\n",
    "# eval model \n",
    "scores = model.evaluate(x_test, y_test) \n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions \n",
    "predictions = model.predict(x_test) \n",
    "\n",
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions] \n",
    "print(rounded) \n",
    "\n",
    "# Display a summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model using keras functional api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 10ms/step - loss: 0.5531 - accuracy: 0.8875\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3344 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2144 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1369 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0874 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0232 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0095 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7bb489460>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense \n",
    "from tensorflow.keras.models import Model \n",
    "\n",
    "# This returns a tensor \n",
    "inputs = Input(shape=(4,)) \n",
    "print(inputs)\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor \n",
    "x = Dense(64, activation='relu')(inputs) \n",
    "x = Dense(64, activation='relu')(x) \n",
    "predictions = Dense(1, activation='sigmoid')(x) \n",
    "\n",
    "# This creates a model that includes \n",
    "# the Input layer and three Dense layers \n",
    "model = Model(inputs=inputs, outputs=predictions) \n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "model.fit(x_train, y_train,epochs=10, batch_size=10)  # starts training "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
