{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Hello World \n",
    "import tensorflow as tf \n",
    "#sess = tf.Session() \n",
    "# This is only needed for TF 1.X \n",
    "# Computational Graph to be compiled and then run using the session \n",
    "a = tf.constant(10) \n",
    "b = tf.constant(32) \n",
    "# print(sess.run(a+b))  # Not session.run not needed in TF2.X\n",
    "# In TF2.X eager execution compiles the computation graph in the background print(a+b) \n",
    "# TF 2.X is more direct. Just write a+b \n",
    "print(a)\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Keras Hello World \n",
    "from keras.models  import Sequential \n",
    "from keras.layers import Dense \n",
    "# create model \n",
    "model = Sequential() \n",
    "model.add(Dense(12, input_dim=8, activation='relu')) # first layer has 12 neurons and expects 8 input variables\n",
    "model.add(Dense(8, activation='relu')) # second hidden layer has 8 neurons\n",
    "# Compile model \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212\n",
      "Trainable params: 212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([-0.41722417], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n",
      "W: [-0.0697065], b: [0.5747752]\n",
      "W: [0.03248136], b: [0.33826715]\n",
      "W: [0.08149227], b: [0.31048954]\n",
      "W: [0.09492681], b: [0.3028753]\n",
      "W: [0.09860939], b: [0.30078816]\n",
      "W: [0.09961881], b: [0.30021605]\n",
      "W: [0.09989551], b: [0.30005923]\n",
      "W: [0.09997136], b: [0.30001625]\n",
      "W: [0.09999216], b: [0.30000445]\n",
      "W: [0.09999788], b: [0.30000123]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np   \n",
    "# Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3 \n",
    "x_data = np.random.rand(100).astype(np.float32) \n",
    "y_data = x_data * 0.1 + 0.3   \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x_data, y_data)\n",
    "plt.show()\n",
    "\n",
    "# Try to find values for W and b that compute y_data = W * x_data + b \n",
    "# (We know that W should be 0.1 and b 0.3, but Tensorflow will figure that out for us.) \n",
    "W = tf.Variable(tf.random.uniform(shape=(1,), minval=-1.0, maxval=1.0)) \n",
    "b = tf.Variable(tf.zeros(shape=(1,))) \n",
    "\n",
    "print(W)\n",
    "print(b)\n",
    "\n",
    "# Minimize the mean squared errors. \n",
    "def cost():     \n",
    "    y = W * x_data + b     \n",
    "    loss = tf.reduce_mean(tf.square(y - y_data))     \n",
    "    return loss \n",
    "\n",
    "# SGD is the equivalent for GradientDescentOptimizer\n",
    "optimizer = tf.optimizers.SGD(0.5)  \n",
    "\n",
    "for e in range(200):     \n",
    "    optimizer.minimize(cost, var_list=[W, b])     \n",
    "    if e % 20 == 0:         \n",
    "        print(f'W: {W.numpy()}, b: {b.numpy()}')  \n",
    "        \n",
    "# Learns best fit is W: [0.1], b: [0.3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "# create model \n",
    "model = Sequential([ \n",
    "        Dense(12, input_dim=8, activation='relu'), \n",
    "        Dense(8, activation='relu'),             \n",
    "        Dense(1, activation='sigmoid') \n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris two class dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Keras version of Iris classifier \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn import model_selection \n",
    "from sklearn import preprocessing \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# loading and pre-processing of the data \n",
    "# We use the 2 class version of iris data set \n",
    "iris = pd.read_csv(\"IrisTwoClass.csv\") \n",
    "x = np.array(iris.drop(\"Class\",axis=1)) \n",
    "y = np.array(iris[\"Class\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "[[6.3 2.9 5.6 1.8]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.  2.2 5.  1.5]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [6.5 3.  5.8 2.2]]\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[1 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 1 0 1 1 1 0 1 0\n",
      " 1 0 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 1 1\n",
      " 1 1 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 4)\n",
      "(20, 4)\n",
      "(80,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train / test \n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=42) \n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# Scale data (training set) to 0 mean and unit standard deviation. \n",
    "scaler = preprocessing.StandardScaler() \n",
    "x_train = scaler.fit_transform(x_train) \n",
    "x_test = scaler.fit_transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72103295 -1.03004748  1.08200425  1.10481261]\n",
      " [ 1.16135842 -0.54245104  1.03321037  1.10481261]\n",
      " [-0.37978071  0.43274184 -0.91854476 -0.76402464]\n",
      " [ 1.27143978 -0.0548546   1.13079813  1.32467581]\n",
      " [-1.04026891 -0.29865282 -0.86975088 -0.98388784]\n",
      " [-1.04026891 -0.54245104 -0.96733864 -0.87395624]\n",
      " [ 2.15209071 -0.54245104  1.32597364  1.32467581]\n",
      " [-0.59994345  2.13932938 -0.91854476 -1.09381945]\n",
      " [ 0.39078885 -1.51764392  1.08200425  0.33529139]\n",
      " [ 0.17062612 -0.54245104  0.83803486  0.7750178 ]\n",
      " [ 0.28070748 -2.4928368   0.78924098  0.44522299]\n",
      " [-0.82010618 -0.54245104 -0.86975088 -0.98388784]\n",
      " [-1.37051301 -2.24903858 -1.01613251 -0.87395624]\n",
      " [ 0.61095158 -1.76144214  0.78924098  0.8849494 ]\n",
      " [ 0.50087022 -1.03004748  0.69165322  0.7750178 ]\n",
      " [-0.93018755  0.92033828 -0.96733864 -1.09381945]\n",
      " [-0.82010618  0.43274184 -0.91854476 -0.98388784]\n",
      " [-0.71002481  0.18894362 -0.820957   -0.65409304]\n",
      " [ 0.50087022  0.43274184  0.98441649  1.32467581]\n",
      " [-0.71002481  1.1641365  -0.91854476 -0.76402464]\n",
      " [ 0.61095158 -1.2738457   0.7404471   0.7750178 ]\n",
      " [-1.04026891  0.43274184 -0.72336924 -0.98388784]\n",
      " [-0.48986208  1.1641365  -0.91854476 -0.98388784]\n",
      " [ 0.83111432 -0.54245104  0.88682874  0.994881  ]\n",
      " [-0.04953661 -1.76144214  0.78924098  0.994881  ]\n",
      " [ 2.04200935 -0.54245104  1.56994303  1.10481261]\n",
      " [ 0.83111432 -0.54245104  1.03321037  0.7750178 ]\n",
      " [ 1.49160252 -0.54245104  1.22838588  1.10481261]\n",
      " [-0.37978071  1.1641365  -0.91854476 -0.98388784]\n",
      " [-0.37978071  1.65173294 -1.01613251 -0.76402464]\n",
      " [-1.59067575 -0.54245104 -1.11372027 -1.09381945]\n",
      " [-0.59994345  0.43274184 -0.96733864 -0.98388784]\n",
      " [-0.71002481  1.40793472 -0.86975088 -0.98388784]\n",
      " [-1.15035028 -0.0548546  -0.86975088 -0.98388784]\n",
      " [ 0.72103295 -0.29865282  1.03321037  0.7750178 ]\n",
      " [-0.04953661  1.40793472 -0.820957   -0.87395624]\n",
      " [-0.26969935  0.67654006 -1.01613251 -0.98388784]\n",
      " [ 0.61095158 -1.03004748  0.83803486  0.44522299]\n",
      " [-0.71002481  0.67654006 -0.96733864 -0.98388784]\n",
      " [-0.37978071  1.65173294 -0.820957   -0.76402464]\n",
      " [ 1.60168388  0.92033828  1.32597364  1.54453902]\n",
      " [ 0.83111432 -0.54245104  1.17959201  1.21474421]\n",
      " [-0.82010618  0.67654006 -0.86975088 -0.54416143]\n",
      " [ 0.06054475  1.89553116 -1.06492639 -0.98388784]\n",
      " [ 0.61095158  0.18894362  1.27717976  1.54453902]\n",
      " [-0.82010618  0.92033828 -0.96733864 -0.98388784]\n",
      " [-1.48059438 -0.0548546  -1.01613251 -0.98388784]\n",
      " [-0.71002481  1.40793472 -0.72336924 -0.76402464]\n",
      " [-1.04026891 -0.54245104 -0.96733864 -1.09381945]\n",
      " [ 1.05127705 -0.54245104  0.88682874  1.32467581]\n",
      " [-0.82010618  0.67654006 -1.01613251 -0.87395624]\n",
      " [ 2.37225345  1.40793472  1.47235527  0.994881  ]\n",
      " [-1.48059438 -0.78624926 -0.96733864 -0.98388784]\n",
      " [-1.26043165  0.92033828 -1.16251415 -0.98388784]\n",
      " [-0.26969935  2.3831276  -0.96733864 -0.98388784]\n",
      " [ 0.06054475 -1.03004748  0.83803486  1.43460741]\n",
      " [ 1.27143978 -0.29865282  0.98441649  1.10481261]\n",
      " [ 0.61095158  0.43274184  1.08200425  1.43460741]\n",
      " [-0.82010618  0.43274184 -0.86975088 -0.76402464]\n",
      " [ 1.27143978 -0.29865282  0.83803486  1.32467581]\n",
      " [-1.15035028 -0.0548546  -1.01613251 -0.98388784]\n",
      " [ 1.05127705 -1.76144214  1.17959201  0.7750178 ]\n",
      " [ 1.82184661 -1.03004748  1.32597364  0.8849494 ]\n",
      " [ 0.39078885 -0.54245104  0.7404471   0.7750178 ]\n",
      " [-1.04026891  0.43274184 -0.86975088 -0.98388784]\n",
      " [-0.15961798 -1.03004748  0.7404471   0.994881  ]\n",
      " [-1.26043165  0.43274184 -0.96733864 -0.87395624]\n",
      " [ 1.60168388 -0.0548546   1.27717976  0.7750178 ]\n",
      " [ 0.72103295 -1.03004748  1.08200425  1.21474421]\n",
      " [ 1.16135842 -0.0548546   1.22838588  1.32467581]\n",
      " [-1.26043165 -0.29865282 -0.91854476 -0.98388784]\n",
      " [ 1.60168388 -0.54245104  1.17959201  0.55515459]\n",
      " [-0.82010618 -0.0548546  -1.06492639 -0.98388784]\n",
      " [-0.71002481  0.67654006 -0.96733864 -0.87395624]\n",
      " [-1.26043165 -0.0548546  -0.96733864 -0.98388784]\n",
      " [ 0.72103295 -0.0548546   0.93562261  1.32467581]\n",
      " [ 1.05127705  0.18894362  1.13079813  1.10481261]\n",
      " [ 0.06054475 -1.2738457   0.83803486  0.8849494 ]\n",
      " [-0.71002481  0.43274184 -0.91854476 -0.98388784]\n",
      " [-0.71002481  1.40793472 -0.91854476 -0.87395624]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model using keras hypertuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adamt\\AppData\\Local\\Temp\\ipykernel_22080\\2502756197.py:24: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn = create_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.6717 - accuracy: 0.5660 - val_loss: 0.6965 - val_accuracy: 0.4000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6659 - accuracy: 0.5660 - val_loss: 0.6917 - val_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6602 - accuracy: 0.5660 - val_loss: 0.6869 - val_accuracy: 0.4000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6546 - accuracy: 0.5660 - val_loss: 0.6822 - val_accuracy: 0.4000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6490 - accuracy: 0.5660 - val_loss: 0.6776 - val_accuracy: 0.4000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6436 - accuracy: 0.5660 - val_loss: 0.6732 - val_accuracy: 0.4000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6383 - accuracy: 0.5660 - val_loss: 0.6688 - val_accuracy: 0.4000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6330 - accuracy: 0.5660 - val_loss: 0.6645 - val_accuracy: 0.4000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6278 - accuracy: 0.5660 - val_loss: 0.6603 - val_accuracy: 0.4000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6225 - accuracy: 0.5660 - val_loss: 0.6562 - val_accuracy: 0.4000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6174 - accuracy: 0.5660 - val_loss: 0.6521 - val_accuracy: 0.4000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6122 - accuracy: 0.5660 - val_loss: 0.6481 - val_accuracy: 0.4000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6071 - accuracy: 0.5660 - val_loss: 0.6441 - val_accuracy: 0.4000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6021 - accuracy: 0.5660 - val_loss: 0.6401 - val_accuracy: 0.4000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5970 - accuracy: 0.5660 - val_loss: 0.6361 - val_accuracy: 0.4000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5920 - accuracy: 0.5660 - val_loss: 0.6321 - val_accuracy: 0.4000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5871 - accuracy: 0.5660 - val_loss: 0.6282 - val_accuracy: 0.4000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5824 - accuracy: 0.5660 - val_loss: 0.6243 - val_accuracy: 0.4000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5777 - accuracy: 0.5660 - val_loss: 0.6206 - val_accuracy: 0.4000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5730 - accuracy: 0.5660 - val_loss: 0.6169 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6284 - accuracy: 0.4444\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.6996 - accuracy: 0.4528 - val_loss: 0.6962 - val_accuracy: 0.4500\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6943 - accuracy: 0.4528 - val_loss: 0.6920 - val_accuracy: 0.6000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6890 - accuracy: 0.5094 - val_loss: 0.6878 - val_accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6838 - accuracy: 0.7358 - val_loss: 0.6837 - val_accuracy: 0.8000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6787 - accuracy: 0.8491 - val_loss: 0.6796 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6735 - accuracy: 0.9057 - val_loss: 0.6757 - val_accuracy: 0.8500\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6685 - accuracy: 0.9245 - val_loss: 0.6717 - val_accuracy: 0.8500\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6634 - accuracy: 0.9623 - val_loss: 0.6678 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6585 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6536 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6486 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6437 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.9500\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6389 - accuracy: 1.0000 - val_loss: 0.6482 - val_accuracy: 0.9500\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6340 - accuracy: 1.0000 - val_loss: 0.6443 - val_accuracy: 0.9500\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6291 - accuracy: 1.0000 - val_loss: 0.6404 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6243 - accuracy: 1.0000 - val_loss: 0.6365 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6195 - accuracy: 1.0000 - val_loss: 0.6326 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6147 - accuracy: 1.0000 - val_loss: 0.6287 - val_accuracy: 0.9500\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6098 - accuracy: 1.0000 - val_loss: 0.6248 - val_accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6048 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6353 - accuracy: 0.9259\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 854ms/step - loss: 0.6603 - accuracy: 0.5741 - val_loss: 0.6643 - val_accuracy: 0.4000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6537 - accuracy: 0.5741 - val_loss: 0.6584 - val_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6470 - accuracy: 0.5741 - val_loss: 0.6526 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6405 - accuracy: 0.6296 - val_loss: 0.6469 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6340 - accuracy: 0.6667 - val_loss: 0.6411 - val_accuracy: 0.5500\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6276 - accuracy: 0.6852 - val_loss: 0.6354 - val_accuracy: 0.5500\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6211 - accuracy: 0.6852 - val_loss: 0.6300 - val_accuracy: 0.6000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6147 - accuracy: 0.6852 - val_loss: 0.6245 - val_accuracy: 0.6500\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6082 - accuracy: 0.7963 - val_loss: 0.6190 - val_accuracy: 0.7000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6017 - accuracy: 0.8704 - val_loss: 0.6135 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5951 - accuracy: 0.9259 - val_loss: 0.6079 - val_accuracy: 0.7500\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5886 - accuracy: 0.9259 - val_loss: 0.6022 - val_accuracy: 0.8000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5821 - accuracy: 0.9444 - val_loss: 0.5966 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5757 - accuracy: 0.9444 - val_loss: 0.5907 - val_accuracy: 0.9500\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5692 - accuracy: 0.9630 - val_loss: 0.5848 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5626 - accuracy: 0.9630 - val_loss: 0.5789 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5561 - accuracy: 0.9630 - val_loss: 0.5729 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5495 - accuracy: 0.9815 - val_loss: 0.5669 - val_accuracy: 0.9500\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5428 - accuracy: 0.9815 - val_loss: 0.5607 - val_accuracy: 0.9500\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5362 - accuracy: 0.9815 - val_loss: 0.5546 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5460 - accuracy: 1.0000\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 0.4017 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3814 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3621 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3436 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3261 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2939 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2790 - accuracy: 1.0000 - val_loss: 0.3168 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2650 - accuracy: 1.0000 - val_loss: 0.3061 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2516 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2391 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2272 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2161 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9500\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2056 - accuracy: 1.0000 - val_loss: 0.2594 - val_accuracy: 0.9500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1957 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 0.9500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1863 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1775 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9500\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1692 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9500\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1615 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9500\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1541 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1471 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1406 - accuracy: 1.0000 - val_loss: 0.2016 - val_accuracy: 0.9500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1344 - accuracy: 1.0000 - val_loss: 0.1956 - val_accuracy: 0.9500\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1286 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9500\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1232 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1180 - accuracy: 1.0000 - val_loss: 0.1790 - val_accuracy: 0.9500\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1132 - accuracy: 1.0000 - val_loss: 0.1739 - val_accuracy: 0.9500\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1086 - accuracy: 1.0000 - val_loss: 0.1690 - val_accuracy: 0.9500\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9500\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1002 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9500\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0964 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 0.9500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9500\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0894 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 0.9500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0749 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0724 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0538 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0444 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0442 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4717 - accuracy: 0.9811 - val_loss: 0.4776 - val_accuracy: 1.0000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4587 - accuracy: 0.9811 - val_loss: 0.4647 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4460 - accuracy: 0.9811 - val_loss: 0.4521 - val_accuracy: 1.0000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4337 - accuracy: 0.9811 - val_loss: 0.4398 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4217 - accuracy: 0.9811 - val_loss: 0.4279 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4101 - accuracy: 0.9811 - val_loss: 0.4163 - val_accuracy: 1.0000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3987 - accuracy: 0.9811 - val_loss: 0.4050 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3877 - accuracy: 0.9811 - val_loss: 0.3940 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3769 - accuracy: 0.9811 - val_loss: 0.3833 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3665 - accuracy: 0.9811 - val_loss: 0.3730 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3563 - accuracy: 0.9811 - val_loss: 0.3629 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3464 - accuracy: 0.9811 - val_loss: 0.3532 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3368 - accuracy: 0.9811 - val_loss: 0.3439 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3276 - accuracy: 0.9811 - val_loss: 0.3348 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3186 - accuracy: 0.9811 - val_loss: 0.3261 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3099 - accuracy: 0.9811 - val_loss: 0.3175 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3013 - accuracy: 0.9811 - val_loss: 0.3093 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2931 - accuracy: 0.9811 - val_loss: 0.3013 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2851 - accuracy: 0.9811 - val_loss: 0.2937 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2774 - accuracy: 0.9811 - val_loss: 0.2863 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2699 - accuracy: 0.9811 - val_loss: 0.2792 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2627 - accuracy: 1.0000 - val_loss: 0.2723 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2557 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2489 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2423 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2359 - accuracy: 1.0000 - val_loss: 0.2470 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2297 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2238 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2180 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2070 - accuracy: 1.0000 - val_loss: 0.2199 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2018 - accuracy: 1.0000 - val_loss: 0.2150 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1967 - accuracy: 1.0000 - val_loss: 0.2104 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1919 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1871 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1826 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1782 - accuracy: 1.0000 - val_loss: 0.1932 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1740 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1698 - accuracy: 1.0000 - val_loss: 0.1853 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1658 - accuracy: 1.0000 - val_loss: 0.1816 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1619 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1582 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1546 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1511 - accuracy: 1.0000 - val_loss: 0.1679 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1478 - accuracy: 1.0000 - val_loss: 0.1647 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1445 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1413 - accuracy: 1.0000 - val_loss: 0.1587 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1383 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1353 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1324 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1297 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1270 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1244 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1219 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1195 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1171 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1149 - accuracy: 1.0000 - val_loss: 0.1334 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1126 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1105 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1084 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1007 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0989 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0892 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0836 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0823 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0811 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0763 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0752 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0741 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0710 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0701 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0664 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0630 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0615 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0547 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 0.0716 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0529 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0491 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0481 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0477 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.0644 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0422 - accuracy: 1.0000 - val_loss: 0.0594 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0331 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0413 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 1.1413 - accuracy: 0.0370 - val_loss: 1.0583 - val_accuracy: 0.0500\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.1151 - accuracy: 0.0370 - val_loss: 1.0373 - val_accuracy: 0.0500\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 1.0895 - accuracy: 0.0370 - val_loss: 1.0169 - val_accuracy: 0.0500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 1.0643 - accuracy: 0.0370 - val_loss: 0.9968 - val_accuracy: 0.0500\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 1.0396 - accuracy: 0.0370 - val_loss: 0.9769 - val_accuracy: 0.0500\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0154 - accuracy: 0.0556 - val_loss: 0.9576 - val_accuracy: 0.0500\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.9917 - accuracy: 0.0741 - val_loss: 0.9387 - val_accuracy: 0.0500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9685 - accuracy: 0.1111 - val_loss: 0.9202 - val_accuracy: 0.0500\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9457 - accuracy: 0.1111 - val_loss: 0.9022 - val_accuracy: 0.0500\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9236 - accuracy: 0.1111 - val_loss: 0.8843 - val_accuracy: 0.0500\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.9017 - accuracy: 0.1481 - val_loss: 0.8670 - val_accuracy: 0.0500\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8805 - accuracy: 0.1481 - val_loss: 0.8502 - val_accuracy: 0.1000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8599 - accuracy: 0.1481 - val_loss: 0.8338 - val_accuracy: 0.1500\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.8398 - accuracy: 0.1296 - val_loss: 0.8177 - val_accuracy: 0.2500\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.8200 - accuracy: 0.1667 - val_loss: 0.8021 - val_accuracy: 0.2500\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.8010 - accuracy: 0.2037 - val_loss: 0.7867 - val_accuracy: 0.2500\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7822 - accuracy: 0.2407 - val_loss: 0.7717 - val_accuracy: 0.3500\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7640 - accuracy: 0.3148 - val_loss: 0.7570 - val_accuracy: 0.3500\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.7464 - accuracy: 0.3519 - val_loss: 0.7427 - val_accuracy: 0.4500\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7292 - accuracy: 0.4259 - val_loss: 0.7286 - val_accuracy: 0.4500\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.7123 - accuracy: 0.4815 - val_loss: 0.7150 - val_accuracy: 0.4500\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6960 - accuracy: 0.5370 - val_loss: 0.7016 - val_accuracy: 0.4500\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6802 - accuracy: 0.6111 - val_loss: 0.6884 - val_accuracy: 0.4500\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6647 - accuracy: 0.6296 - val_loss: 0.6758 - val_accuracy: 0.4500\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6499 - accuracy: 0.6296 - val_loss: 0.6630 - val_accuracy: 0.4500\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6351 - accuracy: 0.6296 - val_loss: 0.6508 - val_accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6210 - accuracy: 0.6667 - val_loss: 0.6387 - val_accuracy: 0.5500\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6072 - accuracy: 0.7037 - val_loss: 0.6267 - val_accuracy: 0.5500\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5936 - accuracy: 0.7778 - val_loss: 0.6153 - val_accuracy: 0.6500\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5807 - accuracy: 0.8148 - val_loss: 0.6038 - val_accuracy: 0.6500\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5679 - accuracy: 0.8148 - val_loss: 0.5926 - val_accuracy: 0.7500\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5554 - accuracy: 0.8519 - val_loss: 0.5815 - val_accuracy: 0.9000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5432 - accuracy: 0.9074 - val_loss: 0.5707 - val_accuracy: 0.9000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5314 - accuracy: 0.9630 - val_loss: 0.5601 - val_accuracy: 0.9000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5200 - accuracy: 0.9630 - val_loss: 0.5497 - val_accuracy: 0.9000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5088 - accuracy: 0.9630 - val_loss: 0.5394 - val_accuracy: 0.9000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4978 - accuracy: 0.9630 - val_loss: 0.5294 - val_accuracy: 0.9000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4872 - accuracy: 0.9630 - val_loss: 0.5194 - val_accuracy: 0.9000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4767 - accuracy: 0.9630 - val_loss: 0.5096 - val_accuracy: 0.9000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4665 - accuracy: 0.9815 - val_loss: 0.5001 - val_accuracy: 0.9000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4566 - accuracy: 0.9815 - val_loss: 0.4907 - val_accuracy: 0.9000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4468 - accuracy: 0.9815 - val_loss: 0.4813 - val_accuracy: 0.9500\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4373 - accuracy: 0.9815 - val_loss: 0.4723 - val_accuracy: 0.9500\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4281 - accuracy: 0.9815 - val_loss: 0.4633 - val_accuracy: 0.9500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4189 - accuracy: 0.9815 - val_loss: 0.4545 - val_accuracy: 0.9500\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4100 - accuracy: 0.9815 - val_loss: 0.4458 - val_accuracy: 0.9500\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4013 - accuracy: 0.9815 - val_loss: 0.4373 - val_accuracy: 0.9500\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3928 - accuracy: 0.9815 - val_loss: 0.4289 - val_accuracy: 0.9500\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3844 - accuracy: 0.9815 - val_loss: 0.4208 - val_accuracy: 0.9500\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3763 - accuracy: 0.9815 - val_loss: 0.4126 - val_accuracy: 0.9500\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3682 - accuracy: 0.9815 - val_loss: 0.4046 - val_accuracy: 0.9500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3603 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.9500\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3528 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3452 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3379 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3306 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3236 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3167 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3100 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3034 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2968 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2905 - accuracy: 1.0000 - val_loss: 0.3268 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2843 - accuracy: 1.0000 - val_loss: 0.3206 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2783 - accuracy: 1.0000 - val_loss: 0.3145 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2723 - accuracy: 1.0000 - val_loss: 0.3085 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2665 - accuracy: 1.0000 - val_loss: 0.3026 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2608 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2553 - accuracy: 1.0000 - val_loss: 0.2914 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2499 - accuracy: 1.0000 - val_loss: 0.2859 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2445 - accuracy: 1.0000 - val_loss: 0.2806 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2394 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2343 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2294 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2246 - accuracy: 1.0000 - val_loss: 0.2604 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2198 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2152 - accuracy: 1.0000 - val_loss: 0.2511 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2108 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2064 - accuracy: 1.0000 - val_loss: 0.2422 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2021 - accuracy: 1.0000 - val_loss: 0.2379 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1980 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1939 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1899 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1860 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1822 - accuracy: 1.0000 - val_loss: 0.2179 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1785 - accuracy: 1.0000 - val_loss: 0.2142 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1750 - accuracy: 1.0000 - val_loss: 0.2106 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1715 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1681 - accuracy: 1.0000 - val_loss: 0.2036 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1647 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1615 - accuracy: 1.0000 - val_loss: 0.1970 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1584 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1523 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1494 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1465 - accuracy: 1.0000 - val_loss: 0.1819 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1437 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1410 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1384 - accuracy: 1.0000 - val_loss: 0.1736 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1358 - accuracy: 1.0000 - val_loss: 0.1710 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1333 - accuracy: 1.0000 - val_loss: 0.1685 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1309 - accuracy: 1.0000 - val_loss: 0.1661 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1262 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1239 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.1567 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1175 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1154 - accuracy: 1.0000 - val_loss: 0.1503 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1135 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1115 - accuracy: 1.0000 - val_loss: 0.1462 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1097 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1060 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1043 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1026 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1009 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0977 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0946 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0917 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0903 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0890 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0876 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0863 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0826 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0814 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0803 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0769 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0759 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0738 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0728 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0657 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0641 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.0847 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0527 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.0822 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0511 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0505 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0495 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0476 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 0.0755 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0449 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.0696 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0380 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0346 - accuracy: 1.0000\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 1s 259ms/step - loss: 0.7739 - accuracy: 0.4340 - val_loss: 0.6786 - val_accuracy: 0.6000\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7684 - accuracy: 0.4340 - val_loss: 0.6775 - val_accuracy: 0.6000\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7631 - accuracy: 0.4340 - val_loss: 0.6767 - val_accuracy: 0.6000\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7575 - accuracy: 0.4340 - val_loss: 0.6760 - val_accuracy: 0.6000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7518 - accuracy: 0.4340 - val_loss: 0.6755 - val_accuracy: 0.6000\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7474 - accuracy: 0.4340 - val_loss: 0.6751 - val_accuracy: 0.6000\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7426 - accuracy: 0.4340 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7382 - accuracy: 0.4340 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7333 - accuracy: 0.4340 - val_loss: 0.6750 - val_accuracy: 0.6000\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7287 - accuracy: 0.4340 - val_loss: 0.6753 - val_accuracy: 0.6000\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7260 - accuracy: 0.4340 - val_loss: 0.6758 - val_accuracy: 0.6000\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7219 - accuracy: 0.4340 - val_loss: 0.6763 - val_accuracy: 0.6000\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.7194 - accuracy: 0.4340 - val_loss: 0.6770 - val_accuracy: 0.6000\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7154 - accuracy: 0.4340 - val_loss: 0.6777 - val_accuracy: 0.6000\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7122 - accuracy: 0.4340 - val_loss: 0.6784 - val_accuracy: 0.6000\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7093 - accuracy: 0.4340 - val_loss: 0.6793 - val_accuracy: 0.6000\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7066 - accuracy: 0.4340 - val_loss: 0.6802 - val_accuracy: 0.6000\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7043 - accuracy: 0.4340 - val_loss: 0.6813 - val_accuracy: 0.6000\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7018 - accuracy: 0.4340 - val_loss: 0.6824 - val_accuracy: 0.6000\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7001 - accuracy: 0.4340 - val_loss: 0.6837 - val_accuracy: 0.6000\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6976 - accuracy: 0.4340 - val_loss: 0.6849 - val_accuracy: 0.6000\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6963 - accuracy: 0.4340 - val_loss: 0.6862 - val_accuracy: 0.6000\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6944 - accuracy: 0.4340 - val_loss: 0.6875 - val_accuracy: 0.6000\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6927 - accuracy: 0.4340 - val_loss: 0.6887 - val_accuracy: 0.7000\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6905 - accuracy: 0.5660 - val_loss: 0.6897 - val_accuracy: 0.8000\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6893 - accuracy: 0.7925 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6883 - accuracy: 0.6038 - val_loss: 0.6921 - val_accuracy: 0.4000\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6868 - accuracy: 0.5660 - val_loss: 0.6933 - val_accuracy: 0.4000\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6859 - accuracy: 0.5660 - val_loss: 0.6944 - val_accuracy: 0.4000\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6849 - accuracy: 0.5660 - val_loss: 0.6955 - val_accuracy: 0.4000\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6837 - accuracy: 0.5660 - val_loss: 0.6964 - val_accuracy: 0.4000\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.6827 - accuracy: 0.5660 - val_loss: 0.6972 - val_accuracy: 0.4000\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6819 - accuracy: 0.5660 - val_loss: 0.6980 - val_accuracy: 0.4000\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6808 - accuracy: 0.5660 - val_loss: 0.6986 - val_accuracy: 0.4000\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6798 - accuracy: 0.5660 - val_loss: 0.6991 - val_accuracy: 0.4000\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6792 - accuracy: 0.5660 - val_loss: 0.6998 - val_accuracy: 0.4000\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6787 - accuracy: 0.5660 - val_loss: 0.7006 - val_accuracy: 0.4000\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6776 - accuracy: 0.5660 - val_loss: 0.7011 - val_accuracy: 0.4000\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6768 - accuracy: 0.5660 - val_loss: 0.7015 - val_accuracy: 0.4000\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6759 - accuracy: 0.5660 - val_loss: 0.7018 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6955 - accuracy: 0.4444\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 1s 234ms/step - loss: 0.7682 - accuracy: 0.4340 - val_loss: 0.7806 - val_accuracy: 0.4000\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7611 - accuracy: 0.4340 - val_loss: 0.7725 - val_accuracy: 0.4000\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.7543 - accuracy: 0.4340 - val_loss: 0.7648 - val_accuracy: 0.4000\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.7473 - accuracy: 0.4340 - val_loss: 0.7576 - val_accuracy: 0.4000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7428 - accuracy: 0.4340 - val_loss: 0.7507 - val_accuracy: 0.4000\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7366 - accuracy: 0.4340 - val_loss: 0.7445 - val_accuracy: 0.4000\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7299 - accuracy: 0.4340 - val_loss: 0.7389 - val_accuracy: 0.4000\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.7264 - accuracy: 0.4340 - val_loss: 0.7334 - val_accuracy: 0.4000\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.7222 - accuracy: 0.4340 - val_loss: 0.7282 - val_accuracy: 0.4000\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7180 - accuracy: 0.4340 - val_loss: 0.7233 - val_accuracy: 0.4000\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.7134 - accuracy: 0.4340 - val_loss: 0.7187 - val_accuracy: 0.4000\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.7104 - accuracy: 0.4340 - val_loss: 0.7144 - val_accuracy: 0.4000\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.7070 - accuracy: 0.4340 - val_loss: 0.7103 - val_accuracy: 0.4000\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7033 - accuracy: 0.4340 - val_loss: 0.7066 - val_accuracy: 0.4000\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.7016 - accuracy: 0.4340 - val_loss: 0.7030 - val_accuracy: 0.4000\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6990 - accuracy: 0.4340 - val_loss: 0.6998 - val_accuracy: 0.4000\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6962 - accuracy: 0.4340 - val_loss: 0.6969 - val_accuracy: 0.4000\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6943 - accuracy: 0.4340 - val_loss: 0.6941 - val_accuracy: 0.4000\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6924 - accuracy: 0.4340 - val_loss: 0.6917 - val_accuracy: 0.4000\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6907 - accuracy: 0.6604 - val_loss: 0.6894 - val_accuracy: 1.0000\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6895 - accuracy: 0.7925 - val_loss: 0.6873 - val_accuracy: 0.6000\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6875 - accuracy: 0.5660 - val_loss: 0.6855 - val_accuracy: 0.6000\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6863 - accuracy: 0.5660 - val_loss: 0.6837 - val_accuracy: 0.6000\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6862 - accuracy: 0.5660 - val_loss: 0.6821 - val_accuracy: 0.6000\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6844 - accuracy: 0.5660 - val_loss: 0.6807 - val_accuracy: 0.6000\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6834 - accuracy: 0.5660 - val_loss: 0.6794 - val_accuracy: 0.6000\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6828 - accuracy: 0.5660 - val_loss: 0.6782 - val_accuracy: 0.6000\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6819 - accuracy: 0.5660 - val_loss: 0.6771 - val_accuracy: 0.6000\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6813 - accuracy: 0.5660 - val_loss: 0.6761 - val_accuracy: 0.6000\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6807 - accuracy: 0.5660 - val_loss: 0.6751 - val_accuracy: 0.6000\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6799 - accuracy: 0.5660 - val_loss: 0.6743 - val_accuracy: 0.6000\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6793 - accuracy: 0.5660 - val_loss: 0.6734 - val_accuracy: 0.6000\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6789 - accuracy: 0.5660 - val_loss: 0.6726 - val_accuracy: 0.6000\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6788 - accuracy: 0.5660 - val_loss: 0.6717 - val_accuracy: 0.6000\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6778 - accuracy: 0.5660 - val_loss: 0.6711 - val_accuracy: 0.6000\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.6773 - accuracy: 0.5660 - val_loss: 0.6704 - val_accuracy: 0.6000\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6768 - accuracy: 0.5660 - val_loss: 0.6697 - val_accuracy: 0.6000\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6767 - accuracy: 0.5660 - val_loss: 0.6690 - val_accuracy: 0.6000\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6760 - accuracy: 0.5660 - val_loss: 0.6684 - val_accuracy: 0.6000\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6755 - accuracy: 0.5660 - val_loss: 0.6678 - val_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7347 - accuracy: 0.2963\n",
      "Epoch 1/40\n",
      "2/2 [==============================] - 1s 245ms/step - loss: 0.7056 - accuracy: 0.4259 - val_loss: 0.6894 - val_accuracy: 0.6000\n",
      "Epoch 2/40\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7032 - accuracy: 0.4259 - val_loss: 0.6912 - val_accuracy: 0.6000\n",
      "Epoch 3/40\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.7003 - accuracy: 0.4259 - val_loss: 0.6930 - val_accuracy: 0.6000\n",
      "Epoch 4/40\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6979 - accuracy: 0.3889 - val_loss: 0.6949 - val_accuracy: 0.4000\n",
      "Epoch 5/40\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6959 - accuracy: 0.3333 - val_loss: 0.6970 - val_accuracy: 0.3500\n",
      "Epoch 6/40\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6944 - accuracy: 0.5741 - val_loss: 0.6993 - val_accuracy: 0.4000\n",
      "Epoch 7/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6928 - accuracy: 0.5741 - val_loss: 0.7016 - val_accuracy: 0.4000\n",
      "Epoch 8/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6905 - accuracy: 0.5741 - val_loss: 0.7038 - val_accuracy: 0.4000\n",
      "Epoch 9/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6893 - accuracy: 0.5741 - val_loss: 0.7061 - val_accuracy: 0.4000\n",
      "Epoch 10/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6886 - accuracy: 0.5741 - val_loss: 0.7085 - val_accuracy: 0.4000\n",
      "Epoch 11/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6871 - accuracy: 0.5741 - val_loss: 0.7107 - val_accuracy: 0.4000\n",
      "Epoch 12/40\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6864 - accuracy: 0.5741 - val_loss: 0.7130 - val_accuracy: 0.4000\n",
      "Epoch 13/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6855 - accuracy: 0.5741 - val_loss: 0.7150 - val_accuracy: 0.4000\n",
      "Epoch 14/40\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6846 - accuracy: 0.5741 - val_loss: 0.7169 - val_accuracy: 0.4000\n",
      "Epoch 15/40\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6839 - accuracy: 0.5741 - val_loss: 0.7186 - val_accuracy: 0.4000\n",
      "Epoch 16/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6831 - accuracy: 0.5741 - val_loss: 0.7201 - val_accuracy: 0.4000\n",
      "Epoch 17/40\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6827 - accuracy: 0.5741 - val_loss: 0.7217 - val_accuracy: 0.4000\n",
      "Epoch 18/40\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6821 - accuracy: 0.5741 - val_loss: 0.7232 - val_accuracy: 0.4000\n",
      "Epoch 19/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6821 - accuracy: 0.5741 - val_loss: 0.7248 - val_accuracy: 0.4000\n",
      "Epoch 20/40\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6814 - accuracy: 0.5741 - val_loss: 0.7259 - val_accuracy: 0.4000\n",
      "Epoch 21/40\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6812 - accuracy: 0.5741 - val_loss: 0.7270 - val_accuracy: 0.4000\n",
      "Epoch 22/40\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6807 - accuracy: 0.5741 - val_loss: 0.7278 - val_accuracy: 0.4000\n",
      "Epoch 23/40\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6803 - accuracy: 0.5741 - val_loss: 0.7284 - val_accuracy: 0.4000\n",
      "Epoch 24/40\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6803 - accuracy: 0.5741 - val_loss: 0.7290 - val_accuracy: 0.4000\n",
      "Epoch 25/40\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6797 - accuracy: 0.5741 - val_loss: 0.7292 - val_accuracy: 0.4000\n",
      "Epoch 26/40\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6795 - accuracy: 0.5741 - val_loss: 0.7293 - val_accuracy: 0.4000\n",
      "Epoch 27/40\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6792 - accuracy: 0.5741 - val_loss: 0.7291 - val_accuracy: 0.4000\n",
      "Epoch 28/40\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6788 - accuracy: 0.5741 - val_loss: 0.7286 - val_accuracy: 0.4000\n",
      "Epoch 29/40\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6786 - accuracy: 0.5741 - val_loss: 0.7283 - val_accuracy: 0.4000\n",
      "Epoch 30/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6782 - accuracy: 0.5741 - val_loss: 0.7283 - val_accuracy: 0.4000\n",
      "Epoch 31/40\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6780 - accuracy: 0.5741 - val_loss: 0.7284 - val_accuracy: 0.4000\n",
      "Epoch 32/40\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6775 - accuracy: 0.5741 - val_loss: 0.7281 - val_accuracy: 0.4000\n",
      "Epoch 33/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6773 - accuracy: 0.5741 - val_loss: 0.7276 - val_accuracy: 0.4000\n",
      "Epoch 34/40\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6770 - accuracy: 0.5741 - val_loss: 0.7273 - val_accuracy: 0.4000\n",
      "Epoch 35/40\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6765 - accuracy: 0.5741 - val_loss: 0.7274 - val_accuracy: 0.4000\n",
      "Epoch 36/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6762 - accuracy: 0.5741 - val_loss: 0.7275 - val_accuracy: 0.4000\n",
      "Epoch 37/40\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6760 - accuracy: 0.5741 - val_loss: 0.7281 - val_accuracy: 0.4000\n",
      "Epoch 38/40\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.6755 - accuracy: 0.5741 - val_loss: 0.7281 - val_accuracy: 0.4000\n",
      "Epoch 39/40\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6751 - accuracy: 0.5741 - val_loss: 0.7284 - val_accuracy: 0.4000\n",
      "Epoch 40/40\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6748 - accuracy: 0.5741 - val_loss: 0.7286 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7208 - accuracy: 0.4231\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 241ms/step - loss: 0.6940 - accuracy: 0.4340 - val_loss: 0.6506 - val_accuracy: 0.5500\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6700 - accuracy: 0.4528 - val_loss: 0.6303 - val_accuracy: 0.5500\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6444 - accuracy: 0.4717 - val_loss: 0.6110 - val_accuracy: 0.9000\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6224 - accuracy: 0.6415 - val_loss: 0.5928 - val_accuracy: 0.9000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6003 - accuracy: 0.9057 - val_loss: 0.5747 - val_accuracy: 0.9500\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5788 - accuracy: 0.9811 - val_loss: 0.5575 - val_accuracy: 0.9500\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5577 - accuracy: 0.9811 - val_loss: 0.5406 - val_accuracy: 0.9500\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5379 - accuracy: 0.9811 - val_loss: 0.5243 - val_accuracy: 0.9500\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5179 - accuracy: 0.9811 - val_loss: 0.5079 - val_accuracy: 0.9500\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4987 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.9500\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4801 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9500\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4624 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.9500\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4444 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9500\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4272 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9500\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4100 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.9500\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3931 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9500\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3764 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9500\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3596 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9500\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3433 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3273 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3116 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2963 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2813 - accuracy: 1.0000 - val_loss: 0.2905 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2666 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2523 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2386 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.2252 - accuracy: 1.0000 - val_loss: 0.2362 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2124 - accuracy: 1.0000 - val_loss: 0.2240 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2001 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.1882 - accuracy: 1.0000 - val_loss: 0.2008 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.1769 - accuracy: 1.0000 - val_loss: 0.1901 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1662 - accuracy: 1.0000 - val_loss: 0.1800 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1559 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.1462 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.1372 - accuracy: 1.0000 - val_loss: 0.1525 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1285 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1205 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.1129 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1057 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.0992 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0721 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0679 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.0639 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0585 - accuracy: 1.0000\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 232ms/step - loss: 0.7941 - accuracy: 0.2642 - val_loss: 0.7853 - val_accuracy: 0.4000\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.7796 - accuracy: 0.3019 - val_loss: 0.7717 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7657 - accuracy: 0.3585 - val_loss: 0.7584 - val_accuracy: 0.5500\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.7531 - accuracy: 0.4528 - val_loss: 0.7458 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7400 - accuracy: 0.5283 - val_loss: 0.7338 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7269 - accuracy: 0.5660 - val_loss: 0.7226 - val_accuracy: 0.5500\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7148 - accuracy: 0.6226 - val_loss: 0.7128 - val_accuracy: 0.6000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.7040 - accuracy: 0.6792 - val_loss: 0.7035 - val_accuracy: 0.7000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6947 - accuracy: 0.7170 - val_loss: 0.6944 - val_accuracy: 0.7500\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6860 - accuracy: 0.7547 - val_loss: 0.6864 - val_accuracy: 0.7500\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6788 - accuracy: 0.7547 - val_loss: 0.6790 - val_accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6726 - accuracy: 0.8113 - val_loss: 0.6730 - val_accuracy: 0.8000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6663 - accuracy: 0.8113 - val_loss: 0.6674 - val_accuracy: 0.8000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.6607 - accuracy: 0.8113 - val_loss: 0.6619 - val_accuracy: 0.8000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6547 - accuracy: 0.8302 - val_loss: 0.6565 - val_accuracy: 0.8000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6487 - accuracy: 0.8302 - val_loss: 0.6512 - val_accuracy: 0.8000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6428 - accuracy: 0.8491 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6369 - accuracy: 0.8491 - val_loss: 0.6402 - val_accuracy: 0.8000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6310 - accuracy: 0.8491 - val_loss: 0.6345 - val_accuracy: 0.8000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6249 - accuracy: 0.8491 - val_loss: 0.6288 - val_accuracy: 0.8000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6186 - accuracy: 0.8491 - val_loss: 0.6232 - val_accuracy: 0.8000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6122 - accuracy: 0.8491 - val_loss: 0.6172 - val_accuracy: 0.8000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6060 - accuracy: 0.8679 - val_loss: 0.6111 - val_accuracy: 0.8000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5992 - accuracy: 0.9057 - val_loss: 0.6047 - val_accuracy: 0.8500\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5928 - accuracy: 0.9057 - val_loss: 0.5982 - val_accuracy: 0.9000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5858 - accuracy: 0.9057 - val_loss: 0.5914 - val_accuracy: 0.9000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5788 - accuracy: 0.9057 - val_loss: 0.5843 - val_accuracy: 0.9000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.5717 - accuracy: 0.9057 - val_loss: 0.5767 - val_accuracy: 0.9000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5644 - accuracy: 0.9057 - val_loss: 0.5691 - val_accuracy: 0.9000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5566 - accuracy: 0.9057 - val_loss: 0.5613 - val_accuracy: 0.9000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5487 - accuracy: 0.9057 - val_loss: 0.5534 - val_accuracy: 0.9500\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5409 - accuracy: 0.9057 - val_loss: 0.5451 - val_accuracy: 0.9500\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5327 - accuracy: 0.9245 - val_loss: 0.5366 - val_accuracy: 0.9500\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5245 - accuracy: 0.9245 - val_loss: 0.5276 - val_accuracy: 0.9500\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5158 - accuracy: 0.9434 - val_loss: 0.5185 - val_accuracy: 0.9500\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5072 - accuracy: 0.9434 - val_loss: 0.5088 - val_accuracy: 0.9500\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4983 - accuracy: 0.9623 - val_loss: 0.4988 - val_accuracy: 0.9500\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4893 - accuracy: 0.9623 - val_loss: 0.4886 - val_accuracy: 0.9500\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4798 - accuracy: 0.9623 - val_loss: 0.4782 - val_accuracy: 0.9500\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4703 - accuracy: 0.9623 - val_loss: 0.4673 - val_accuracy: 0.9500\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4603 - accuracy: 0.9811 - val_loss: 0.4564 - val_accuracy: 0.9500\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4501 - accuracy: 0.9811 - val_loss: 0.4453 - val_accuracy: 0.9500\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4394 - accuracy: 0.9811 - val_loss: 0.4338 - val_accuracy: 0.9500\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4282 - accuracy: 0.9811 - val_loss: 0.4220 - val_accuracy: 0.9500\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4164 - accuracy: 0.9811 - val_loss: 0.4103 - val_accuracy: 0.9500\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4045 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9500\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3922 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3798 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.3665 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3531 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3800 - accuracy: 1.0000\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 239ms/step - loss: 0.7035 - accuracy: 0.5370 - val_loss: 0.7003 - val_accuracy: 0.3500\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6885 - accuracy: 0.5556 - val_loss: 0.6873 - val_accuracy: 0.4500\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.6740 - accuracy: 0.5741 - val_loss: 0.6750 - val_accuracy: 0.4500\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6592 - accuracy: 0.6111 - val_loss: 0.6627 - val_accuracy: 0.4500\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6445 - accuracy: 0.6111 - val_loss: 0.6508 - val_accuracy: 0.4500\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6305 - accuracy: 0.6481 - val_loss: 0.6396 - val_accuracy: 0.4500\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6168 - accuracy: 0.6852 - val_loss: 0.6293 - val_accuracy: 0.4500\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6048 - accuracy: 0.7963 - val_loss: 0.6194 - val_accuracy: 0.5500\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5924 - accuracy: 0.8148 - val_loss: 0.6099 - val_accuracy: 0.5500\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5813 - accuracy: 0.8519 - val_loss: 0.6010 - val_accuracy: 0.6000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5710 - accuracy: 0.8333 - val_loss: 0.5927 - val_accuracy: 0.7000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5596 - accuracy: 0.8333 - val_loss: 0.5847 - val_accuracy: 0.7000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.5489 - accuracy: 0.8519 - val_loss: 0.5771 - val_accuracy: 0.7000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5393 - accuracy: 0.8889 - val_loss: 0.5697 - val_accuracy: 0.7000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5297 - accuracy: 0.8889 - val_loss: 0.5623 - val_accuracy: 0.7000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5199 - accuracy: 0.8889 - val_loss: 0.5552 - val_accuracy: 0.7500\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5101 - accuracy: 0.8889 - val_loss: 0.5481 - val_accuracy: 0.7500\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4999 - accuracy: 0.9074 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4910 - accuracy: 0.9259 - val_loss: 0.5346 - val_accuracy: 0.8000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4822 - accuracy: 0.9444 - val_loss: 0.5280 - val_accuracy: 0.8500\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4723 - accuracy: 0.9815 - val_loss: 0.5214 - val_accuracy: 0.8500\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4638 - accuracy: 0.9815 - val_loss: 0.5149 - val_accuracy: 0.8500\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4551 - accuracy: 0.9815 - val_loss: 0.5085 - val_accuracy: 0.9000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4467 - accuracy: 0.9815 - val_loss: 0.5021 - val_accuracy: 0.9500\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4381 - accuracy: 0.9815 - val_loss: 0.4958 - val_accuracy: 0.9500\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4299 - accuracy: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.9500\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4221 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9500\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4138 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9500\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4062 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3981 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3905 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3830 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3754 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3682 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3608 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3537 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3464 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3394 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3322 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3253 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3183 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3111 - accuracy: 1.0000 - val_loss: 0.3909 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3040 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2966 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2896 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2823 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.2752 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.2677 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.2602 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2528 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3093 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 1s 239ms/step - loss: 0.6850 - accuracy: 0.7170 - val_loss: 0.6773 - val_accuracy: 0.8500\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6762 - accuracy: 0.8113 - val_loss: 0.6701 - val_accuracy: 0.9000\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6690 - accuracy: 0.9245 - val_loss: 0.6628 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6612 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6542 - accuracy: 1.0000 - val_loss: 0.6491 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6470 - accuracy: 1.0000 - val_loss: 0.6426 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6401 - accuracy: 1.0000 - val_loss: 0.6362 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6324 - accuracy: 1.0000 - val_loss: 0.6293 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6244 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6161 - accuracy: 1.0000 - val_loss: 0.6152 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6076 - accuracy: 1.0000 - val_loss: 0.6080 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5990 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5904 - accuracy: 1.0000 - val_loss: 0.5934 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5817 - accuracy: 1.0000 - val_loss: 0.5859 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5728 - accuracy: 1.0000 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5637 - accuracy: 1.0000 - val_loss: 0.5708 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5545 - accuracy: 1.0000 - val_loss: 0.5628 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5449 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5349 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5249 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5148 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5039 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4933 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4827 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4714 - accuracy: 1.0000 - val_loss: 0.4930 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4601 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4482 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4363 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4242 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4118 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4368 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 1s 236ms/step - loss: 0.6681 - accuracy: 0.5660 - val_loss: 0.6576 - val_accuracy: 0.6000\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6592 - accuracy: 0.5660 - val_loss: 0.6502 - val_accuracy: 0.6000\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6512 - accuracy: 0.5660 - val_loss: 0.6430 - val_accuracy: 0.6000\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6432 - accuracy: 0.5660 - val_loss: 0.6357 - val_accuracy: 0.6000\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6347 - accuracy: 0.5660 - val_loss: 0.6284 - val_accuracy: 0.6000\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6259 - accuracy: 0.5660 - val_loss: 0.6208 - val_accuracy: 0.6000\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.6172 - accuracy: 0.5660 - val_loss: 0.6128 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6077 - accuracy: 0.5660 - val_loss: 0.6045 - val_accuracy: 0.6000\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5982 - accuracy: 0.5660 - val_loss: 0.5955 - val_accuracy: 0.6000\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5885 - accuracy: 0.5660 - val_loss: 0.5861 - val_accuracy: 0.6000\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5784 - accuracy: 0.5660 - val_loss: 0.5767 - val_accuracy: 0.6000\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.5684 - accuracy: 0.5660 - val_loss: 0.5672 - val_accuracy: 0.7000\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5584 - accuracy: 0.5660 - val_loss: 0.5576 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5482 - accuracy: 0.6226 - val_loss: 0.5482 - val_accuracy: 0.8000\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5377 - accuracy: 0.6415 - val_loss: 0.5387 - val_accuracy: 0.8000\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.5283 - accuracy: 0.6792 - val_loss: 0.5294 - val_accuracy: 0.8500\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5181 - accuracy: 0.7170 - val_loss: 0.5200 - val_accuracy: 0.8500\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5080 - accuracy: 0.7358 - val_loss: 0.5108 - val_accuracy: 0.8500\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4985 - accuracy: 0.7358 - val_loss: 0.5019 - val_accuracy: 0.8500\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4886 - accuracy: 0.8302 - val_loss: 0.4931 - val_accuracy: 0.8500\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4789 - accuracy: 0.8491 - val_loss: 0.4844 - val_accuracy: 0.8500\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4691 - accuracy: 0.8679 - val_loss: 0.4758 - val_accuracy: 0.9000\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4596 - accuracy: 0.8679 - val_loss: 0.4672 - val_accuracy: 0.9500\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4501 - accuracy: 0.8868 - val_loss: 0.4584 - val_accuracy: 0.9500\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4406 - accuracy: 0.9057 - val_loss: 0.4500 - val_accuracy: 0.9500\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4314 - accuracy: 0.9245 - val_loss: 0.4417 - val_accuracy: 0.9500\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4226 - accuracy: 0.9245 - val_loss: 0.4333 - val_accuracy: 0.9500\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4138 - accuracy: 0.9434 - val_loss: 0.4250 - val_accuracy: 0.9500\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4051 - accuracy: 0.9434 - val_loss: 0.4169 - val_accuracy: 0.9500\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3965 - accuracy: 0.9434 - val_loss: 0.4088 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5363 - accuracy: 0.8519\n",
      "Epoch 1/30\n",
      "2/2 [==============================] - 1s 249ms/step - loss: 0.6601 - accuracy: 0.7037 - val_loss: 0.6593 - val_accuracy: 0.6000\n",
      "Epoch 2/30\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6504 - accuracy: 0.7593 - val_loss: 0.6519 - val_accuracy: 0.6000\n",
      "Epoch 3/30\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6411 - accuracy: 0.7963 - val_loss: 0.6444 - val_accuracy: 0.9000\n",
      "Epoch 4/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6315 - accuracy: 0.9444 - val_loss: 0.6370 - val_accuracy: 0.9500\n",
      "Epoch 5/30\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6223 - accuracy: 1.0000 - val_loss: 0.6296 - val_accuracy: 0.9500\n",
      "Epoch 6/30\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6129 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.9500\n",
      "Epoch 7/30\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6036 - accuracy: 1.0000 - val_loss: 0.6140 - val_accuracy: 0.9500\n",
      "Epoch 8/30\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5939 - accuracy: 1.0000 - val_loss: 0.6059 - val_accuracy: 0.9500\n",
      "Epoch 9/30\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5843 - accuracy: 1.0000 - val_loss: 0.5977 - val_accuracy: 0.9500\n",
      "Epoch 10/30\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5744 - accuracy: 1.0000 - val_loss: 0.5894 - val_accuracy: 0.9500\n",
      "Epoch 11/30\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5645 - accuracy: 1.0000 - val_loss: 0.5808 - val_accuracy: 0.9500\n",
      "Epoch 12/30\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5545 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.9500\n",
      "Epoch 13/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5444 - accuracy: 1.0000 - val_loss: 0.5632 - val_accuracy: 0.9500\n",
      "Epoch 14/30\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5342 - accuracy: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.9500\n",
      "Epoch 15/30\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5240 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.9500\n",
      "Epoch 16/30\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5131 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.9500\n",
      "Epoch 17/30\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5025 - accuracy: 1.0000 - val_loss: 0.5257 - val_accuracy: 0.9500\n",
      "Epoch 18/30\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4917 - accuracy: 1.0000 - val_loss: 0.5159 - val_accuracy: 0.9500\n",
      "Epoch 19/30\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4808 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.9500\n",
      "Epoch 20/30\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4696 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.9500\n",
      "Epoch 21/30\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4580 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.9500\n",
      "Epoch 22/30\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4465 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.9500\n",
      "Epoch 23/30\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4346 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.9500\n",
      "Epoch 24/30\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4225 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9500\n",
      "Epoch 25/30\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4103 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9500\n",
      "Epoch 26/30\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3980 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.9500\n",
      "Epoch 27/30\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3856 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9500\n",
      "Epoch 28/30\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3730 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9500\n",
      "Epoch 29/30\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3605 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9500\n",
      "Epoch 30/30\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3480 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3507 - accuracy: 1.0000\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 827ms/step - loss: 0.7212 - accuracy: 0.5660 - val_loss: 0.8594 - val_accuracy: 0.4000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7187 - accuracy: 0.5660 - val_loss: 0.8540 - val_accuracy: 0.4000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7162 - accuracy: 0.5660 - val_loss: 0.8487 - val_accuracy: 0.4000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.7137 - accuracy: 0.5660 - val_loss: 0.8434 - val_accuracy: 0.4000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.7113 - accuracy: 0.5660 - val_loss: 0.8383 - val_accuracy: 0.4000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7090 - accuracy: 0.5660 - val_loss: 0.8332 - val_accuracy: 0.4000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7068 - accuracy: 0.5660 - val_loss: 0.8282 - val_accuracy: 0.4000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7047 - accuracy: 0.5660 - val_loss: 0.8233 - val_accuracy: 0.4000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7026 - accuracy: 0.5660 - val_loss: 0.8185 - val_accuracy: 0.4000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.7006 - accuracy: 0.5660 - val_loss: 0.8138 - val_accuracy: 0.4000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6986 - accuracy: 0.5660 - val_loss: 0.8093 - val_accuracy: 0.4000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6967 - accuracy: 0.5660 - val_loss: 0.8048 - val_accuracy: 0.4000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6949 - accuracy: 0.5660 - val_loss: 0.8004 - val_accuracy: 0.4000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6932 - accuracy: 0.5660 - val_loss: 0.7962 - val_accuracy: 0.4000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6915 - accuracy: 0.5660 - val_loss: 0.7921 - val_accuracy: 0.4000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6899 - accuracy: 0.5660 - val_loss: 0.7880 - val_accuracy: 0.4000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6884 - accuracy: 0.5660 - val_loss: 0.7842 - val_accuracy: 0.4000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6869 - accuracy: 0.5660 - val_loss: 0.7804 - val_accuracy: 0.4000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6855 - accuracy: 0.5660 - val_loss: 0.7767 - val_accuracy: 0.4000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6841 - accuracy: 0.5660 - val_loss: 0.7731 - val_accuracy: 0.4000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6828 - accuracy: 0.5660 - val_loss: 0.7697 - val_accuracy: 0.4000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6816 - accuracy: 0.5660 - val_loss: 0.7664 - val_accuracy: 0.4000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6804 - accuracy: 0.5660 - val_loss: 0.7632 - val_accuracy: 0.4000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6792 - accuracy: 0.5660 - val_loss: 0.7600 - val_accuracy: 0.4000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6781 - accuracy: 0.5660 - val_loss: 0.7571 - val_accuracy: 0.4000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6771 - accuracy: 0.5660 - val_loss: 0.7542 - val_accuracy: 0.4000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6760 - accuracy: 0.5660 - val_loss: 0.7514 - val_accuracy: 0.4000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6750 - accuracy: 0.5660 - val_loss: 0.7488 - val_accuracy: 0.4000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6741 - accuracy: 0.5660 - val_loss: 0.7462 - val_accuracy: 0.4000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6732 - accuracy: 0.5660 - val_loss: 0.7438 - val_accuracy: 0.4000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6723 - accuracy: 0.5660 - val_loss: 0.7414 - val_accuracy: 0.4000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6714 - accuracy: 0.5660 - val_loss: 0.7391 - val_accuracy: 0.4000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6706 - accuracy: 0.5660 - val_loss: 0.7370 - val_accuracy: 0.4000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6697 - accuracy: 0.5660 - val_loss: 0.7349 - val_accuracy: 0.4000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6689 - accuracy: 0.5660 - val_loss: 0.7329 - val_accuracy: 0.4000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6681 - accuracy: 0.5660 - val_loss: 0.7310 - val_accuracy: 0.4000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6673 - accuracy: 0.5660 - val_loss: 0.7292 - val_accuracy: 0.4000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6665 - accuracy: 0.5660 - val_loss: 0.7274 - val_accuracy: 0.4000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6658 - accuracy: 0.5660 - val_loss: 0.7258 - val_accuracy: 0.4000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6650 - accuracy: 0.5660 - val_loss: 0.7242 - val_accuracy: 0.4000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6642 - accuracy: 0.5660 - val_loss: 0.7227 - val_accuracy: 0.4000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6635 - accuracy: 0.5660 - val_loss: 0.7212 - val_accuracy: 0.4000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6627 - accuracy: 0.5660 - val_loss: 0.7198 - val_accuracy: 0.4000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6619 - accuracy: 0.5660 - val_loss: 0.7184 - val_accuracy: 0.4000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6611 - accuracy: 0.5660 - val_loss: 0.7172 - val_accuracy: 0.4000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6604 - accuracy: 0.5660 - val_loss: 0.7159 - val_accuracy: 0.4000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6596 - accuracy: 0.5660 - val_loss: 0.7147 - val_accuracy: 0.4000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6588 - accuracy: 0.5660 - val_loss: 0.7136 - val_accuracy: 0.4000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6580 - accuracy: 0.5660 - val_loss: 0.7125 - val_accuracy: 0.4000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6572 - accuracy: 0.5660 - val_loss: 0.7114 - val_accuracy: 0.4000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6564 - accuracy: 0.5660 - val_loss: 0.7104 - val_accuracy: 0.4000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6556 - accuracy: 0.5660 - val_loss: 0.7094 - val_accuracy: 0.4000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6548 - accuracy: 0.5660 - val_loss: 0.7085 - val_accuracy: 0.4000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6539 - accuracy: 0.5660 - val_loss: 0.7075 - val_accuracy: 0.4000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6531 - accuracy: 0.5660 - val_loss: 0.7066 - val_accuracy: 0.4000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6523 - accuracy: 0.5660 - val_loss: 0.7057 - val_accuracy: 0.4000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6514 - accuracy: 0.5660 - val_loss: 0.7049 - val_accuracy: 0.4000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6505 - accuracy: 0.5660 - val_loss: 0.7040 - val_accuracy: 0.4000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6496 - accuracy: 0.5660 - val_loss: 0.7031 - val_accuracy: 0.4000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6488 - accuracy: 0.5660 - val_loss: 0.7023 - val_accuracy: 0.4000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6479 - accuracy: 0.5660 - val_loss: 0.7015 - val_accuracy: 0.4000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6469 - accuracy: 0.5660 - val_loss: 0.7006 - val_accuracy: 0.4000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6460 - accuracy: 0.5660 - val_loss: 0.6998 - val_accuracy: 0.4000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6451 - accuracy: 0.5660 - val_loss: 0.6990 - val_accuracy: 0.4000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6441 - accuracy: 0.5660 - val_loss: 0.6982 - val_accuracy: 0.4000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6432 - accuracy: 0.5660 - val_loss: 0.6973 - val_accuracy: 0.4000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6422 - accuracy: 0.5660 - val_loss: 0.6965 - val_accuracy: 0.4000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6412 - accuracy: 0.5660 - val_loss: 0.6956 - val_accuracy: 0.4000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6402 - accuracy: 0.5660 - val_loss: 0.6948 - val_accuracy: 0.4000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6392 - accuracy: 0.5660 - val_loss: 0.6939 - val_accuracy: 0.4000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6382 - accuracy: 0.5660 - val_loss: 0.6930 - val_accuracy: 0.4000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6372 - accuracy: 0.5660 - val_loss: 0.6922 - val_accuracy: 0.4000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6361 - accuracy: 0.5660 - val_loss: 0.6913 - val_accuracy: 0.4000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6350 - accuracy: 0.5660 - val_loss: 0.6903 - val_accuracy: 0.4000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6340 - accuracy: 0.5660 - val_loss: 0.6894 - val_accuracy: 0.4000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6329 - accuracy: 0.5660 - val_loss: 0.6884 - val_accuracy: 0.4000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6318 - accuracy: 0.5660 - val_loss: 0.6875 - val_accuracy: 0.4000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6306 - accuracy: 0.5660 - val_loss: 0.6864 - val_accuracy: 0.4000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6295 - accuracy: 0.5660 - val_loss: 0.6854 - val_accuracy: 0.4000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6283 - accuracy: 0.5660 - val_loss: 0.6844 - val_accuracy: 0.4000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6271 - accuracy: 0.5660 - val_loss: 0.6833 - val_accuracy: 0.4000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6260 - accuracy: 0.5660 - val_loss: 0.6822 - val_accuracy: 0.4000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6247 - accuracy: 0.5660 - val_loss: 0.6811 - val_accuracy: 0.4000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6235 - accuracy: 0.5660 - val_loss: 0.6800 - val_accuracy: 0.4000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6223 - accuracy: 0.5660 - val_loss: 0.6788 - val_accuracy: 0.4000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6210 - accuracy: 0.5660 - val_loss: 0.6776 - val_accuracy: 0.4000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6197 - accuracy: 0.5660 - val_loss: 0.6764 - val_accuracy: 0.4000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6184 - accuracy: 0.5660 - val_loss: 0.6752 - val_accuracy: 0.4000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6171 - accuracy: 0.5660 - val_loss: 0.6739 - val_accuracy: 0.4000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6157 - accuracy: 0.5660 - val_loss: 0.6726 - val_accuracy: 0.4000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6144 - accuracy: 0.5660 - val_loss: 0.6713 - val_accuracy: 0.4000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6130 - accuracy: 0.5660 - val_loss: 0.6700 - val_accuracy: 0.4000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6116 - accuracy: 0.5660 - val_loss: 0.6686 - val_accuracy: 0.4000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6102 - accuracy: 0.5660 - val_loss: 0.6672 - val_accuracy: 0.4000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6087 - accuracy: 0.5660 - val_loss: 0.6658 - val_accuracy: 0.4000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6072 - accuracy: 0.5660 - val_loss: 0.6644 - val_accuracy: 0.4000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6057 - accuracy: 0.5660 - val_loss: 0.6629 - val_accuracy: 0.4000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6042 - accuracy: 0.5660 - val_loss: 0.6614 - val_accuracy: 0.4000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6027 - accuracy: 0.5660 - val_loss: 0.6599 - val_accuracy: 0.4000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6011 - accuracy: 0.5660 - val_loss: 0.6584 - val_accuracy: 0.4000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5995 - accuracy: 0.5660 - val_loss: 0.6568 - val_accuracy: 0.4000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5979 - accuracy: 0.5660 - val_loss: 0.6552 - val_accuracy: 0.4000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5963 - accuracy: 0.5660 - val_loss: 0.6536 - val_accuracy: 0.4000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5946 - accuracy: 0.5660 - val_loss: 0.6520 - val_accuracy: 0.4000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5930 - accuracy: 0.5660 - val_loss: 0.6503 - val_accuracy: 0.4000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5913 - accuracy: 0.5660 - val_loss: 0.6486 - val_accuracy: 0.4000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5895 - accuracy: 0.5660 - val_loss: 0.6469 - val_accuracy: 0.4000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5877 - accuracy: 0.5660 - val_loss: 0.6452 - val_accuracy: 0.4000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5860 - accuracy: 0.5660 - val_loss: 0.6434 - val_accuracy: 0.4000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5841 - accuracy: 0.5660 - val_loss: 0.6416 - val_accuracy: 0.4000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5823 - accuracy: 0.5660 - val_loss: 0.6397 - val_accuracy: 0.4000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5804 - accuracy: 0.5660 - val_loss: 0.6379 - val_accuracy: 0.4000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5786 - accuracy: 0.5660 - val_loss: 0.6360 - val_accuracy: 0.4000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5766 - accuracy: 0.5660 - val_loss: 0.6341 - val_accuracy: 0.4500\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5747 - accuracy: 0.5849 - val_loss: 0.6322 - val_accuracy: 0.4500\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5727 - accuracy: 0.5849 - val_loss: 0.6302 - val_accuracy: 0.5000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5707 - accuracy: 0.5849 - val_loss: 0.6283 - val_accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5686 - accuracy: 0.6226 - val_loss: 0.6263 - val_accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5666 - accuracy: 0.6792 - val_loss: 0.6242 - val_accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5645 - accuracy: 0.6792 - val_loss: 0.6221 - val_accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5623 - accuracy: 0.7170 - val_loss: 0.6201 - val_accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5602 - accuracy: 0.7358 - val_loss: 0.6179 - val_accuracy: 0.5500\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5580 - accuracy: 0.7736 - val_loss: 0.6158 - val_accuracy: 0.5500\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5558 - accuracy: 0.8113 - val_loss: 0.6136 - val_accuracy: 0.5500\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5535 - accuracy: 0.8302 - val_loss: 0.6114 - val_accuracy: 0.5500\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5513 - accuracy: 0.8491 - val_loss: 0.6092 - val_accuracy: 0.6000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5490 - accuracy: 0.8491 - val_loss: 0.6069 - val_accuracy: 0.6000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5466 - accuracy: 0.8491 - val_loss: 0.6046 - val_accuracy: 0.6000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5443 - accuracy: 0.8868 - val_loss: 0.6023 - val_accuracy: 0.6000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5418 - accuracy: 0.8868 - val_loss: 0.6000 - val_accuracy: 0.6000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5394 - accuracy: 0.9057 - val_loss: 0.5976 - val_accuracy: 0.6000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5369 - accuracy: 0.9245 - val_loss: 0.5952 - val_accuracy: 0.6000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5345 - accuracy: 0.9434 - val_loss: 0.5927 - val_accuracy: 0.6500\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5319 - accuracy: 0.9434 - val_loss: 0.5902 - val_accuracy: 0.6500\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5294 - accuracy: 0.9623 - val_loss: 0.5878 - val_accuracy: 0.6500\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5268 - accuracy: 0.9623 - val_loss: 0.5852 - val_accuracy: 0.7000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5241 - accuracy: 0.9623 - val_loss: 0.5827 - val_accuracy: 0.7000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5215 - accuracy: 0.9811 - val_loss: 0.5801 - val_accuracy: 0.7500\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5188 - accuracy: 0.9811 - val_loss: 0.5774 - val_accuracy: 0.7500\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5161 - accuracy: 0.9811 - val_loss: 0.5748 - val_accuracy: 0.7500\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5134 - accuracy: 0.9811 - val_loss: 0.5721 - val_accuracy: 0.7500\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5106 - accuracy: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.8000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5078 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 0.8000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5049 - accuracy: 1.0000 - val_loss: 0.5639 - val_accuracy: 0.8000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5020 - accuracy: 1.0000 - val_loss: 0.5612 - val_accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4992 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.8000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4962 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4933 - accuracy: 1.0000 - val_loss: 0.5526 - val_accuracy: 0.8000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4903 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.8000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4873 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.8500\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4842 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.8500\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4812 - accuracy: 1.0000 - val_loss: 0.5408 - val_accuracy: 0.8500\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4781 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4749 - accuracy: 1.0000 - val_loss: 0.5347 - val_accuracy: 0.8500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4718 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.9000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4686 - accuracy: 1.0000 - val_loss: 0.5285 - val_accuracy: 0.9000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4654 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.9000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4622 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4589 - accuracy: 1.0000 - val_loss: 0.5191 - val_accuracy: 0.9000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4557 - accuracy: 1.0000 - val_loss: 0.5159 - val_accuracy: 0.9000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4524 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.9000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4490 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.9000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4457 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.9000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4423 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4390 - accuracy: 1.0000 - val_loss: 0.4996 - val_accuracy: 0.9000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4356 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.9000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4322 - accuracy: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.9000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4288 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4253 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9500\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4219 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9500\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4184 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9500\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4149 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9500\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4114 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9500\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4079 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9500\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4044 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.9500\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4009 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9500\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3973 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9500\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3938 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.9500\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3903 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.9500\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3867 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9500\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3832 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9500\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3796 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9500\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3761 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3725 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.9500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3690 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3654 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3619 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9500\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3584 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9500\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3548 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3513 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9500\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3478 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.9500\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3443 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.9500\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3408 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9500\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3373 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.9500\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3339 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3304 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3270 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.9500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3235 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3201 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3168 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.3384 - accuracy: 1.0000\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 0.6907 - accuracy: 0.5660 - val_loss: 0.6719 - val_accuracy: 0.6000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6896 - accuracy: 0.5660 - val_loss: 0.6714 - val_accuracy: 0.6000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6885 - accuracy: 0.5660 - val_loss: 0.6710 - val_accuracy: 0.6000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6875 - accuracy: 0.5660 - val_loss: 0.6706 - val_accuracy: 0.6000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6866 - accuracy: 0.5660 - val_loss: 0.6703 - val_accuracy: 0.6000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6857 - accuracy: 0.5660 - val_loss: 0.6700 - val_accuracy: 0.6000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6849 - accuracy: 0.5660 - val_loss: 0.6698 - val_accuracy: 0.6000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6841 - accuracy: 0.5660 - val_loss: 0.6696 - val_accuracy: 0.6000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6835 - accuracy: 0.5660 - val_loss: 0.6695 - val_accuracy: 0.6000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6828 - accuracy: 0.5660 - val_loss: 0.6694 - val_accuracy: 0.6000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6823 - accuracy: 0.5660 - val_loss: 0.6693 - val_accuracy: 0.6000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6817 - accuracy: 0.5660 - val_loss: 0.6692 - val_accuracy: 0.6000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6812 - accuracy: 0.5660 - val_loss: 0.6691 - val_accuracy: 0.6000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6807 - accuracy: 0.5660 - val_loss: 0.6690 - val_accuracy: 0.6000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6803 - accuracy: 0.5660 - val_loss: 0.6689 - val_accuracy: 0.6000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6798 - accuracy: 0.5660 - val_loss: 0.6687 - val_accuracy: 0.6000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6794 - accuracy: 0.5660 - val_loss: 0.6686 - val_accuracy: 0.6000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6790 - accuracy: 0.5660 - val_loss: 0.6684 - val_accuracy: 0.6000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6786 - accuracy: 0.5660 - val_loss: 0.6682 - val_accuracy: 0.6000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6782 - accuracy: 0.5660 - val_loss: 0.6680 - val_accuracy: 0.6000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6778 - accuracy: 0.5660 - val_loss: 0.6678 - val_accuracy: 0.6000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6774 - accuracy: 0.5660 - val_loss: 0.6675 - val_accuracy: 0.6000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6769 - accuracy: 0.5660 - val_loss: 0.6672 - val_accuracy: 0.6000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6765 - accuracy: 0.5660 - val_loss: 0.6669 - val_accuracy: 0.6000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6761 - accuracy: 0.5660 - val_loss: 0.6666 - val_accuracy: 0.6000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6757 - accuracy: 0.5660 - val_loss: 0.6662 - val_accuracy: 0.6000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6752 - accuracy: 0.5660 - val_loss: 0.6658 - val_accuracy: 0.6000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6747 - accuracy: 0.5660 - val_loss: 0.6654 - val_accuracy: 0.6000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6743 - accuracy: 0.5660 - val_loss: 0.6649 - val_accuracy: 0.6000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6738 - accuracy: 0.5660 - val_loss: 0.6644 - val_accuracy: 0.6000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6733 - accuracy: 0.5660 - val_loss: 0.6640 - val_accuracy: 0.6000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6728 - accuracy: 0.5660 - val_loss: 0.6635 - val_accuracy: 0.6000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6723 - accuracy: 0.5660 - val_loss: 0.6629 - val_accuracy: 0.6000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6718 - accuracy: 0.5660 - val_loss: 0.6624 - val_accuracy: 0.6000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6713 - accuracy: 0.5660 - val_loss: 0.6619 - val_accuracy: 0.6000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6708 - accuracy: 0.5660 - val_loss: 0.6613 - val_accuracy: 0.6000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6702 - accuracy: 0.5660 - val_loss: 0.6607 - val_accuracy: 0.6000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6697 - accuracy: 0.5660 - val_loss: 0.6602 - val_accuracy: 0.6000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6691 - accuracy: 0.5660 - val_loss: 0.6596 - val_accuracy: 0.6000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6685 - accuracy: 0.5660 - val_loss: 0.6590 - val_accuracy: 0.6000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6679 - accuracy: 0.5660 - val_loss: 0.6584 - val_accuracy: 0.6000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6673 - accuracy: 0.5660 - val_loss: 0.6578 - val_accuracy: 0.6000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6667 - accuracy: 0.5660 - val_loss: 0.6572 - val_accuracy: 0.6000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6661 - accuracy: 0.5660 - val_loss: 0.6565 - val_accuracy: 0.6000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6655 - accuracy: 0.5660 - val_loss: 0.6559 - val_accuracy: 0.6000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6648 - accuracy: 0.5660 - val_loss: 0.6552 - val_accuracy: 0.6000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6642 - accuracy: 0.5660 - val_loss: 0.6546 - val_accuracy: 0.6000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6635 - accuracy: 0.5660 - val_loss: 0.6539 - val_accuracy: 0.6000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6628 - accuracy: 0.5660 - val_loss: 0.6532 - val_accuracy: 0.6000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6620 - accuracy: 0.5660 - val_loss: 0.6525 - val_accuracy: 0.6000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6613 - accuracy: 0.5660 - val_loss: 0.6518 - val_accuracy: 0.6000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6605 - accuracy: 0.5660 - val_loss: 0.6511 - val_accuracy: 0.6000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6597 - accuracy: 0.5660 - val_loss: 0.6504 - val_accuracy: 0.6000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6589 - accuracy: 0.5660 - val_loss: 0.6496 - val_accuracy: 0.6000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6581 - accuracy: 0.5660 - val_loss: 0.6488 - val_accuracy: 0.6000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6572 - accuracy: 0.5660 - val_loss: 0.6480 - val_accuracy: 0.6000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6564 - accuracy: 0.5660 - val_loss: 0.6472 - val_accuracy: 0.6000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6555 - accuracy: 0.5660 - val_loss: 0.6464 - val_accuracy: 0.6000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6545 - accuracy: 0.5660 - val_loss: 0.6455 - val_accuracy: 0.6000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6536 - accuracy: 0.5660 - val_loss: 0.6447 - val_accuracy: 0.6000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6526 - accuracy: 0.5660 - val_loss: 0.6438 - val_accuracy: 0.6000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6516 - accuracy: 0.5660 - val_loss: 0.6428 - val_accuracy: 0.6000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6506 - accuracy: 0.5660 - val_loss: 0.6419 - val_accuracy: 0.6000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6495 - accuracy: 0.5660 - val_loss: 0.6409 - val_accuracy: 0.6000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6484 - accuracy: 0.5660 - val_loss: 0.6399 - val_accuracy: 0.6000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6473 - accuracy: 0.5660 - val_loss: 0.6389 - val_accuracy: 0.6000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6461 - accuracy: 0.5660 - val_loss: 0.6378 - val_accuracy: 0.6000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6449 - accuracy: 0.5660 - val_loss: 0.6367 - val_accuracy: 0.6000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6437 - accuracy: 0.5660 - val_loss: 0.6355 - val_accuracy: 0.6000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6424 - accuracy: 0.5660 - val_loss: 0.6344 - val_accuracy: 0.6000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6411 - accuracy: 0.5660 - val_loss: 0.6332 - val_accuracy: 0.6000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6398 - accuracy: 0.5660 - val_loss: 0.6319 - val_accuracy: 0.6000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6384 - accuracy: 0.5660 - val_loss: 0.6307 - val_accuracy: 0.6000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6370 - accuracy: 0.5660 - val_loss: 0.6293 - val_accuracy: 0.6000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6356 - accuracy: 0.5660 - val_loss: 0.6280 - val_accuracy: 0.6000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6341 - accuracy: 0.5660 - val_loss: 0.6266 - val_accuracy: 0.6000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6326 - accuracy: 0.5660 - val_loss: 0.6252 - val_accuracy: 0.6000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6310 - accuracy: 0.5660 - val_loss: 0.6237 - val_accuracy: 0.6000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6294 - accuracy: 0.5660 - val_loss: 0.6222 - val_accuracy: 0.6000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6277 - accuracy: 0.5660 - val_loss: 0.6207 - val_accuracy: 0.6000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6261 - accuracy: 0.5660 - val_loss: 0.6191 - val_accuracy: 0.6000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6243 - accuracy: 0.5660 - val_loss: 0.6174 - val_accuracy: 0.6000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6225 - accuracy: 0.5660 - val_loss: 0.6158 - val_accuracy: 0.6000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6207 - accuracy: 0.5660 - val_loss: 0.6140 - val_accuracy: 0.6000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6188 - accuracy: 0.5660 - val_loss: 0.6123 - val_accuracy: 0.6000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6169 - accuracy: 0.5660 - val_loss: 0.6105 - val_accuracy: 0.6000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6149 - accuracy: 0.5660 - val_loss: 0.6086 - val_accuracy: 0.6000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6129 - accuracy: 0.5660 - val_loss: 0.6067 - val_accuracy: 0.6000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6108 - accuracy: 0.5660 - val_loss: 0.6048 - val_accuracy: 0.6000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6087 - accuracy: 0.5660 - val_loss: 0.6028 - val_accuracy: 0.6000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6065 - accuracy: 0.5660 - val_loss: 0.6007 - val_accuracy: 0.6000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6043 - accuracy: 0.5660 - val_loss: 0.5987 - val_accuracy: 0.6000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6020 - accuracy: 0.5660 - val_loss: 0.5965 - val_accuracy: 0.6000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5996 - accuracy: 0.5660 - val_loss: 0.5944 - val_accuracy: 0.6000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5973 - accuracy: 0.5660 - val_loss: 0.5921 - val_accuracy: 0.6000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5948 - accuracy: 0.5660 - val_loss: 0.5898 - val_accuracy: 0.6000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5923 - accuracy: 0.5660 - val_loss: 0.5875 - val_accuracy: 0.6000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5897 - accuracy: 0.5660 - val_loss: 0.5851 - val_accuracy: 0.6000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5871 - accuracy: 0.5660 - val_loss: 0.5827 - val_accuracy: 0.6500\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5844 - accuracy: 0.5849 - val_loss: 0.5802 - val_accuracy: 0.6500\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5817 - accuracy: 0.5849 - val_loss: 0.5776 - val_accuracy: 0.8000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5789 - accuracy: 0.6226 - val_loss: 0.5750 - val_accuracy: 0.8000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5761 - accuracy: 0.6415 - val_loss: 0.5724 - val_accuracy: 0.9500\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5732 - accuracy: 0.6604 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5702 - accuracy: 0.6981 - val_loss: 0.5670 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5672 - accuracy: 0.7358 - val_loss: 0.5642 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5641 - accuracy: 0.8302 - val_loss: 0.5613 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5610 - accuracy: 0.8491 - val_loss: 0.5584 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5578 - accuracy: 0.8868 - val_loss: 0.5554 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5545 - accuracy: 0.9057 - val_loss: 0.5524 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5512 - accuracy: 0.9057 - val_loss: 0.5493 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5478 - accuracy: 0.9245 - val_loss: 0.5462 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5444 - accuracy: 0.9623 - val_loss: 0.5431 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5409 - accuracy: 0.9623 - val_loss: 0.5398 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5373 - accuracy: 0.9811 - val_loss: 0.5366 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5337 - accuracy: 0.9811 - val_loss: 0.5332 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5300 - accuracy: 0.9811 - val_loss: 0.5298 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5263 - accuracy: 0.9811 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5225 - accuracy: 0.9811 - val_loss: 0.5230 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5187 - accuracy: 0.9811 - val_loss: 0.5194 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5148 - accuracy: 0.9811 - val_loss: 0.5158 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5109 - accuracy: 0.9811 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5069 - accuracy: 0.9811 - val_loss: 0.5085 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5029 - accuracy: 0.9811 - val_loss: 0.5048 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4988 - accuracy: 0.9811 - val_loss: 0.5011 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4946 - accuracy: 0.9811 - val_loss: 0.4973 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4904 - accuracy: 0.9811 - val_loss: 0.4934 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4862 - accuracy: 0.9811 - val_loss: 0.4896 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4820 - accuracy: 0.9811 - val_loss: 0.4857 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4776 - accuracy: 0.9811 - val_loss: 0.4817 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4733 - accuracy: 0.9811 - val_loss: 0.4777 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4689 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4644 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4600 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4555 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4509 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4464 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4418 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4372 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4326 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4279 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4232 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4185 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4138 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4091 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4044 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3997 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3950 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3902 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3855 - accuracy: 1.0000 - val_loss: 0.3976 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3808 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3760 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3713 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3666 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3620 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3573 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3527 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3480 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3434 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3388 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3343 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3298 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3253 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3208 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3164 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3120 - accuracy: 1.0000 - val_loss: 0.3305 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3076 - accuracy: 1.0000 - val_loss: 0.3264 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3033 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2990 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2948 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2906 - accuracy: 1.0000 - val_loss: 0.3108 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2864 - accuracy: 1.0000 - val_loss: 0.3070 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2823 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2783 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2743 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2703 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2664 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2625 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2587 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2550 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2513 - accuracy: 1.0000 - val_loss: 0.2745 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2476 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2440 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2405 - accuracy: 1.0000 - val_loss: 0.2644 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2370 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2335 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2301 - accuracy: 1.0000 - val_loss: 0.2548 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2268 - accuracy: 1.0000 - val_loss: 0.2516 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2235 - accuracy: 1.0000 - val_loss: 0.2486 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2203 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2171 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2140 - accuracy: 1.0000 - val_loss: 0.2396 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2079 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2049 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2020 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1991 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1963 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1936 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1908 - accuracy: 1.0000 - val_loss: 0.2176 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1954 - accuracy: 1.0000\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 833ms/step - loss: 0.7136 - accuracy: 0.5741 - val_loss: 0.8509 - val_accuracy: 0.4000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.7112 - accuracy: 0.5741 - val_loss: 0.8454 - val_accuracy: 0.4000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7088 - accuracy: 0.5741 - val_loss: 0.8399 - val_accuracy: 0.4000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7065 - accuracy: 0.5741 - val_loss: 0.8345 - val_accuracy: 0.4000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.7043 - accuracy: 0.5741 - val_loss: 0.8292 - val_accuracy: 0.4000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.7021 - accuracy: 0.5741 - val_loss: 0.8241 - val_accuracy: 0.4000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7001 - accuracy: 0.5741 - val_loss: 0.8190 - val_accuracy: 0.4000\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6981 - accuracy: 0.5741 - val_loss: 0.8141 - val_accuracy: 0.4000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6962 - accuracy: 0.5741 - val_loss: 0.8093 - val_accuracy: 0.4000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6944 - accuracy: 0.5741 - val_loss: 0.8046 - val_accuracy: 0.4000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6927 - accuracy: 0.5741 - val_loss: 0.8000 - val_accuracy: 0.4000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6911 - accuracy: 0.5741 - val_loss: 0.7956 - val_accuracy: 0.4000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6895 - accuracy: 0.5741 - val_loss: 0.7913 - val_accuracy: 0.4000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6880 - accuracy: 0.5741 - val_loss: 0.7871 - val_accuracy: 0.4000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6867 - accuracy: 0.5741 - val_loss: 0.7830 - val_accuracy: 0.4000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6853 - accuracy: 0.5741 - val_loss: 0.7791 - val_accuracy: 0.4000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6841 - accuracy: 0.5741 - val_loss: 0.7753 - val_accuracy: 0.4000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6829 - accuracy: 0.5741 - val_loss: 0.7716 - val_accuracy: 0.4000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6818 - accuracy: 0.5741 - val_loss: 0.7681 - val_accuracy: 0.4000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6808 - accuracy: 0.5741 - val_loss: 0.7647 - val_accuracy: 0.4000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6798 - accuracy: 0.5741 - val_loss: 0.7614 - val_accuracy: 0.4000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6789 - accuracy: 0.5741 - val_loss: 0.7583 - val_accuracy: 0.4000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6780 - accuracy: 0.5741 - val_loss: 0.7553 - val_accuracy: 0.4000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6772 - accuracy: 0.5741 - val_loss: 0.7524 - val_accuracy: 0.4000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6764 - accuracy: 0.5741 - val_loss: 0.7497 - val_accuracy: 0.4000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6757 - accuracy: 0.5741 - val_loss: 0.7471 - val_accuracy: 0.4000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6750 - accuracy: 0.5741 - val_loss: 0.7446 - val_accuracy: 0.4000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6744 - accuracy: 0.5741 - val_loss: 0.7422 - val_accuracy: 0.4000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6737 - accuracy: 0.5741 - val_loss: 0.7400 - val_accuracy: 0.4000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6731 - accuracy: 0.5741 - val_loss: 0.7378 - val_accuracy: 0.4000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6726 - accuracy: 0.5741 - val_loss: 0.7358 - val_accuracy: 0.4000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6720 - accuracy: 0.5741 - val_loss: 0.7339 - val_accuracy: 0.4000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6715 - accuracy: 0.5741 - val_loss: 0.7321 - val_accuracy: 0.4000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6710 - accuracy: 0.5741 - val_loss: 0.7303 - val_accuracy: 0.4000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6705 - accuracy: 0.5741 - val_loss: 0.7287 - val_accuracy: 0.4000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6700 - accuracy: 0.5741 - val_loss: 0.7272 - val_accuracy: 0.4000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6695 - accuracy: 0.5741 - val_loss: 0.7257 - val_accuracy: 0.4000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6691 - accuracy: 0.5741 - val_loss: 0.7243 - val_accuracy: 0.4000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6686 - accuracy: 0.5741 - val_loss: 0.7230 - val_accuracy: 0.4000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6681 - accuracy: 0.5741 - val_loss: 0.7218 - val_accuracy: 0.4000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6676 - accuracy: 0.5741 - val_loss: 0.7207 - val_accuracy: 0.4000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6672 - accuracy: 0.5741 - val_loss: 0.7196 - val_accuracy: 0.4000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6667 - accuracy: 0.5741 - val_loss: 0.7186 - val_accuracy: 0.4000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6662 - accuracy: 0.5741 - val_loss: 0.7176 - val_accuracy: 0.4000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6657 - accuracy: 0.5741 - val_loss: 0.7167 - val_accuracy: 0.4000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6652 - accuracy: 0.5741 - val_loss: 0.7158 - val_accuracy: 0.4000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6647 - accuracy: 0.5741 - val_loss: 0.7150 - val_accuracy: 0.4000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6642 - accuracy: 0.5741 - val_loss: 0.7142 - val_accuracy: 0.4000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6637 - accuracy: 0.5741 - val_loss: 0.7135 - val_accuracy: 0.4000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6632 - accuracy: 0.5741 - val_loss: 0.7128 - val_accuracy: 0.4000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6626 - accuracy: 0.5741 - val_loss: 0.7122 - val_accuracy: 0.4000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6621 - accuracy: 0.5741 - val_loss: 0.7115 - val_accuracy: 0.4000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6615 - accuracy: 0.5741 - val_loss: 0.7109 - val_accuracy: 0.4000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6610 - accuracy: 0.5741 - val_loss: 0.7103 - val_accuracy: 0.4000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6604 - accuracy: 0.5741 - val_loss: 0.7097 - val_accuracy: 0.4000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6598 - accuracy: 0.5741 - val_loss: 0.7092 - val_accuracy: 0.4000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6593 - accuracy: 0.5741 - val_loss: 0.7086 - val_accuracy: 0.4000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6587 - accuracy: 0.5741 - val_loss: 0.7081 - val_accuracy: 0.4000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6581 - accuracy: 0.5741 - val_loss: 0.7076 - val_accuracy: 0.4000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6575 - accuracy: 0.5741 - val_loss: 0.7071 - val_accuracy: 0.4000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6568 - accuracy: 0.5741 - val_loss: 0.7066 - val_accuracy: 0.4000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6562 - accuracy: 0.5741 - val_loss: 0.7061 - val_accuracy: 0.4000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6556 - accuracy: 0.5741 - val_loss: 0.7056 - val_accuracy: 0.4000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6549 - accuracy: 0.5741 - val_loss: 0.7050 - val_accuracy: 0.4000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6542 - accuracy: 0.5741 - val_loss: 0.7045 - val_accuracy: 0.4000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6536 - accuracy: 0.5741 - val_loss: 0.7040 - val_accuracy: 0.4000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6529 - accuracy: 0.5741 - val_loss: 0.7035 - val_accuracy: 0.4000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6522 - accuracy: 0.5741 - val_loss: 0.7029 - val_accuracy: 0.4000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6515 - accuracy: 0.5741 - val_loss: 0.7023 - val_accuracy: 0.4000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6508 - accuracy: 0.5741 - val_loss: 0.7018 - val_accuracy: 0.4000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6501 - accuracy: 0.5741 - val_loss: 0.7012 - val_accuracy: 0.4000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6493 - accuracy: 0.5741 - val_loss: 0.7006 - val_accuracy: 0.4000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6486 - accuracy: 0.5741 - val_loss: 0.7000 - val_accuracy: 0.4000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6478 - accuracy: 0.5741 - val_loss: 0.6993 - val_accuracy: 0.4000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6470 - accuracy: 0.5741 - val_loss: 0.6987 - val_accuracy: 0.4000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6462 - accuracy: 0.5741 - val_loss: 0.6980 - val_accuracy: 0.4000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6454 - accuracy: 0.5741 - val_loss: 0.6973 - val_accuracy: 0.4000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6446 - accuracy: 0.5741 - val_loss: 0.6965 - val_accuracy: 0.4000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6438 - accuracy: 0.5741 - val_loss: 0.6958 - val_accuracy: 0.4000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6429 - accuracy: 0.5741 - val_loss: 0.6950 - val_accuracy: 0.4000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6420 - accuracy: 0.5741 - val_loss: 0.6942 - val_accuracy: 0.4000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6411 - accuracy: 0.5741 - val_loss: 0.6934 - val_accuracy: 0.4000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6403 - accuracy: 0.5741 - val_loss: 0.6925 - val_accuracy: 0.4000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6393 - accuracy: 0.5741 - val_loss: 0.6916 - val_accuracy: 0.4000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6384 - accuracy: 0.5741 - val_loss: 0.6907 - val_accuracy: 0.4000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6375 - accuracy: 0.5741 - val_loss: 0.6898 - val_accuracy: 0.4000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6365 - accuracy: 0.5741 - val_loss: 0.6889 - val_accuracy: 0.4000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6355 - accuracy: 0.5741 - val_loss: 0.6879 - val_accuracy: 0.4000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6345 - accuracy: 0.5741 - val_loss: 0.6869 - val_accuracy: 0.4000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6335 - accuracy: 0.5741 - val_loss: 0.6859 - val_accuracy: 0.4000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6324 - accuracy: 0.5741 - val_loss: 0.6848 - val_accuracy: 0.4000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6314 - accuracy: 0.5741 - val_loss: 0.6837 - val_accuracy: 0.4000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6303 - accuracy: 0.5741 - val_loss: 0.6826 - val_accuracy: 0.4000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6292 - accuracy: 0.5741 - val_loss: 0.6815 - val_accuracy: 0.4000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6280 - accuracy: 0.5741 - val_loss: 0.6804 - val_accuracy: 0.4000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6269 - accuracy: 0.5741 - val_loss: 0.6792 - val_accuracy: 0.4000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6257 - accuracy: 0.5741 - val_loss: 0.6780 - val_accuracy: 0.4000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6245 - accuracy: 0.5741 - val_loss: 0.6768 - val_accuracy: 0.4000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6233 - accuracy: 0.5741 - val_loss: 0.6756 - val_accuracy: 0.4000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6220 - accuracy: 0.5741 - val_loss: 0.6743 - val_accuracy: 0.4000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6208 - accuracy: 0.5741 - val_loss: 0.6730 - val_accuracy: 0.4000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6195 - accuracy: 0.5741 - val_loss: 0.6717 - val_accuracy: 0.4000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6182 - accuracy: 0.5741 - val_loss: 0.6703 - val_accuracy: 0.4000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6168 - accuracy: 0.5741 - val_loss: 0.6690 - val_accuracy: 0.4000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6155 - accuracy: 0.5741 - val_loss: 0.6676 - val_accuracy: 0.4000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6141 - accuracy: 0.5741 - val_loss: 0.6662 - val_accuracy: 0.4000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6127 - accuracy: 0.5741 - val_loss: 0.6648 - val_accuracy: 0.4000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6112 - accuracy: 0.5741 - val_loss: 0.6633 - val_accuracy: 0.4000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6097 - accuracy: 0.5741 - val_loss: 0.6618 - val_accuracy: 0.4000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6082 - accuracy: 0.5741 - val_loss: 0.6603 - val_accuracy: 0.4000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6067 - accuracy: 0.5741 - val_loss: 0.6587 - val_accuracy: 0.4000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6052 - accuracy: 0.5741 - val_loss: 0.6572 - val_accuracy: 0.4000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6036 - accuracy: 0.5741 - val_loss: 0.6556 - val_accuracy: 0.4000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6019 - accuracy: 0.5741 - val_loss: 0.6540 - val_accuracy: 0.4000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6003 - accuracy: 0.5741 - val_loss: 0.6524 - val_accuracy: 0.4000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5986 - accuracy: 0.5741 - val_loss: 0.6507 - val_accuracy: 0.4000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5969 - accuracy: 0.5741 - val_loss: 0.6490 - val_accuracy: 0.4000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5952 - accuracy: 0.5741 - val_loss: 0.6473 - val_accuracy: 0.4000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5934 - accuracy: 0.5741 - val_loss: 0.6456 - val_accuracy: 0.4000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5916 - accuracy: 0.5741 - val_loss: 0.6438 - val_accuracy: 0.4000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5898 - accuracy: 0.5741 - val_loss: 0.6420 - val_accuracy: 0.4000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5880 - accuracy: 0.5741 - val_loss: 0.6402 - val_accuracy: 0.4000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5861 - accuracy: 0.5741 - val_loss: 0.6384 - val_accuracy: 0.4000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5841 - accuracy: 0.5741 - val_loss: 0.6365 - val_accuracy: 0.4000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5822 - accuracy: 0.5741 - val_loss: 0.6346 - val_accuracy: 0.4000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5802 - accuracy: 0.5741 - val_loss: 0.6327 - val_accuracy: 0.4000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5782 - accuracy: 0.5741 - val_loss: 0.6307 - val_accuracy: 0.4000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5761 - accuracy: 0.5741 - val_loss: 0.6287 - val_accuracy: 0.4500\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5740 - accuracy: 0.6111 - val_loss: 0.6267 - val_accuracy: 0.4500\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5719 - accuracy: 0.6111 - val_loss: 0.6246 - val_accuracy: 0.4500\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5698 - accuracy: 0.6111 - val_loss: 0.6226 - val_accuracy: 0.4500\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5676 - accuracy: 0.6111 - val_loss: 0.6204 - val_accuracy: 0.4500\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5654 - accuracy: 0.6296 - val_loss: 0.6183 - val_accuracy: 0.5000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5631 - accuracy: 0.6296 - val_loss: 0.6161 - val_accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5608 - accuracy: 0.6667 - val_loss: 0.6140 - val_accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5585 - accuracy: 0.7222 - val_loss: 0.6117 - val_accuracy: 0.5000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5562 - accuracy: 0.7407 - val_loss: 0.6094 - val_accuracy: 0.5000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5538 - accuracy: 0.7778 - val_loss: 0.6072 - val_accuracy: 0.5000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5513 - accuracy: 0.7778 - val_loss: 0.6048 - val_accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5489 - accuracy: 0.7778 - val_loss: 0.6025 - val_accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5464 - accuracy: 0.7963 - val_loss: 0.6001 - val_accuracy: 0.5500\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5439 - accuracy: 0.8519 - val_loss: 0.5977 - val_accuracy: 0.5500\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5413 - accuracy: 0.8889 - val_loss: 0.5953 - val_accuracy: 0.5500\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5387 - accuracy: 0.8889 - val_loss: 0.5928 - val_accuracy: 0.6000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5361 - accuracy: 0.9074 - val_loss: 0.5903 - val_accuracy: 0.6000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5335 - accuracy: 0.9259 - val_loss: 0.5877 - val_accuracy: 0.6000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5308 - accuracy: 0.9630 - val_loss: 0.5852 - val_accuracy: 0.6500\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5281 - accuracy: 0.9630 - val_loss: 0.5826 - val_accuracy: 0.6500\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5253 - accuracy: 0.9815 - val_loss: 0.5799 - val_accuracy: 0.6500\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5225 - accuracy: 0.9815 - val_loss: 0.5773 - val_accuracy: 0.7000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5197 - accuracy: 0.9815 - val_loss: 0.5746 - val_accuracy: 0.7000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5169 - accuracy: 0.9815 - val_loss: 0.5719 - val_accuracy: 0.7000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5140 - accuracy: 0.9815 - val_loss: 0.5692 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5111 - accuracy: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5082 - accuracy: 1.0000 - val_loss: 0.5636 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5052 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5023 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4992 - accuracy: 1.0000 - val_loss: 0.5551 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4962 - accuracy: 1.0000 - val_loss: 0.5522 - val_accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4931 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.8000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4900 - accuracy: 1.0000 - val_loss: 0.5463 - val_accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4869 - accuracy: 1.0000 - val_loss: 0.5433 - val_accuracy: 0.8500\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4838 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.8500\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4806 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.8500\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4774 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.9000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4742 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.9000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4709 - accuracy: 1.0000 - val_loss: 0.5281 - val_accuracy: 0.9000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4677 - accuracy: 1.0000 - val_loss: 0.5250 - val_accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4644 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 0.9000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4611 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.9000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4578 - accuracy: 1.0000 - val_loss: 0.5157 - val_accuracy: 0.9000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4545 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.9000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4511 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.9000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4478 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.9000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4444 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.9000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4411 - accuracy: 1.0000 - val_loss: 0.4996 - val_accuracy: 0.9000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4376 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4342 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.9000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4308 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4274 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4239 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.9000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4205 - accuracy: 1.0000 - val_loss: 0.4801 - val_accuracy: 0.9500\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4170 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9500\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4136 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9500\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4101 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9500\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4067 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.9500\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4032 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.9500\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3998 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9500\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3963 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9500\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3928 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9500\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3894 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.9500\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3859 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.9500\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3825 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9500\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3791 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9500\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3756 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9500\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3722 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.9500\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3688 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9500\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3653 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9500\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3620 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9500\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3586 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3829 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 839ms/step - loss: 0.6959 - accuracy: 0.5660 - val_loss: 0.7674 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6951 - accuracy: 0.5660 - val_loss: 0.7649 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6944 - accuracy: 0.5660 - val_loss: 0.7625 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6937 - accuracy: 0.5660 - val_loss: 0.7602 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6931 - accuracy: 0.5660 - val_loss: 0.7579 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6925 - accuracy: 0.5660 - val_loss: 0.7556 - val_accuracy: 0.4000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6919 - accuracy: 0.5660 - val_loss: 0.7534 - val_accuracy: 0.4000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6913 - accuracy: 0.5660 - val_loss: 0.7513 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6908 - accuracy: 0.5660 - val_loss: 0.7492 - val_accuracy: 0.4000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6903 - accuracy: 0.5660 - val_loss: 0.7472 - val_accuracy: 0.4000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6898 - accuracy: 0.5660 - val_loss: 0.7453 - val_accuracy: 0.4000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6893 - accuracy: 0.5660 - val_loss: 0.7435 - val_accuracy: 0.4000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6889 - accuracy: 0.5660 - val_loss: 0.7418 - val_accuracy: 0.4000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6884 - accuracy: 0.5660 - val_loss: 0.7401 - val_accuracy: 0.4000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6880 - accuracy: 0.5660 - val_loss: 0.7385 - val_accuracy: 0.4000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6876 - accuracy: 0.5660 - val_loss: 0.7370 - val_accuracy: 0.4000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6872 - accuracy: 0.5660 - val_loss: 0.7356 - val_accuracy: 0.4000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6869 - accuracy: 0.5660 - val_loss: 0.7343 - val_accuracy: 0.4000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6865 - accuracy: 0.5660 - val_loss: 0.7331 - val_accuracy: 0.4000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6861 - accuracy: 0.5660 - val_loss: 0.7319 - val_accuracy: 0.4000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6858 - accuracy: 0.5660 - val_loss: 0.7308 - val_accuracy: 0.4000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6855 - accuracy: 0.5660 - val_loss: 0.7299 - val_accuracy: 0.4000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6851 - accuracy: 0.5660 - val_loss: 0.7290 - val_accuracy: 0.4000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6848 - accuracy: 0.5660 - val_loss: 0.7281 - val_accuracy: 0.4000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6844 - accuracy: 0.5660 - val_loss: 0.7274 - val_accuracy: 0.4000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6841 - accuracy: 0.5660 - val_loss: 0.7267 - val_accuracy: 0.4000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6838 - accuracy: 0.5660 - val_loss: 0.7261 - val_accuracy: 0.4000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6834 - accuracy: 0.5660 - val_loss: 0.7255 - val_accuracy: 0.4000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6831 - accuracy: 0.5660 - val_loss: 0.7250 - val_accuracy: 0.4000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6828 - accuracy: 0.5660 - val_loss: 0.7246 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7127 - accuracy: 0.4444\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.7029 - accuracy: 0.4340 - val_loss: 0.7027 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7011 - accuracy: 0.4340 - val_loss: 0.7003 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6994 - accuracy: 0.4340 - val_loss: 0.6981 - val_accuracy: 0.3500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6977 - accuracy: 0.4151 - val_loss: 0.6960 - val_accuracy: 0.3000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6962 - accuracy: 0.2264 - val_loss: 0.6939 - val_accuracy: 0.6000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6948 - accuracy: 0.5660 - val_loss: 0.6920 - val_accuracy: 0.6000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6934 - accuracy: 0.5660 - val_loss: 0.6901 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6922 - accuracy: 0.5660 - val_loss: 0.6884 - val_accuracy: 0.6000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6910 - accuracy: 0.5660 - val_loss: 0.6867 - val_accuracy: 0.6000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6900 - accuracy: 0.5660 - val_loss: 0.6852 - val_accuracy: 0.6000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6890 - accuracy: 0.5660 - val_loss: 0.6838 - val_accuracy: 0.6000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6881 - accuracy: 0.5660 - val_loss: 0.6825 - val_accuracy: 0.6000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6873 - accuracy: 0.5660 - val_loss: 0.6812 - val_accuracy: 0.6000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6866 - accuracy: 0.5660 - val_loss: 0.6801 - val_accuracy: 0.6000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6860 - accuracy: 0.5660 - val_loss: 0.6790 - val_accuracy: 0.6000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6854 - accuracy: 0.5660 - val_loss: 0.6781 - val_accuracy: 0.6000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6848 - accuracy: 0.5660 - val_loss: 0.6771 - val_accuracy: 0.6000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6844 - accuracy: 0.5660 - val_loss: 0.6763 - val_accuracy: 0.6000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6839 - accuracy: 0.5660 - val_loss: 0.6755 - val_accuracy: 0.6000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6835 - accuracy: 0.5660 - val_loss: 0.6748 - val_accuracy: 0.6000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6831 - accuracy: 0.5660 - val_loss: 0.6742 - val_accuracy: 0.6000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6827 - accuracy: 0.5660 - val_loss: 0.6735 - val_accuracy: 0.6000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6823 - accuracy: 0.5660 - val_loss: 0.6730 - val_accuracy: 0.6000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6820 - accuracy: 0.5660 - val_loss: 0.6724 - val_accuracy: 0.6000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6816 - accuracy: 0.5660 - val_loss: 0.6719 - val_accuracy: 0.6000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6813 - accuracy: 0.5660 - val_loss: 0.6714 - val_accuracy: 0.6000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6809 - accuracy: 0.5660 - val_loss: 0.6709 - val_accuracy: 0.6000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6805 - accuracy: 0.5660 - val_loss: 0.6705 - val_accuracy: 0.6000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6802 - accuracy: 0.5660 - val_loss: 0.6700 - val_accuracy: 0.6000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6798 - accuracy: 0.5660 - val_loss: 0.6696 - val_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7594 - accuracy: 0.2963\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 813ms/step - loss: 0.7292 - accuracy: 0.4259 - val_loss: 0.6666 - val_accuracy: 0.6000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.7258 - accuracy: 0.4259 - val_loss: 0.6668 - val_accuracy: 0.6000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7225 - accuracy: 0.4259 - val_loss: 0.6671 - val_accuracy: 0.6000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.7193 - accuracy: 0.4259 - val_loss: 0.6675 - val_accuracy: 0.6000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.7163 - accuracy: 0.4259 - val_loss: 0.6680 - val_accuracy: 0.6000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.7133 - accuracy: 0.4259 - val_loss: 0.6686 - val_accuracy: 0.6000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7104 - accuracy: 0.4259 - val_loss: 0.6692 - val_accuracy: 0.6000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7076 - accuracy: 0.4259 - val_loss: 0.6700 - val_accuracy: 0.6000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.7050 - accuracy: 0.4259 - val_loss: 0.6708 - val_accuracy: 0.6000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7025 - accuracy: 0.4259 - val_loss: 0.6717 - val_accuracy: 0.6000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7000 - accuracy: 0.4259 - val_loss: 0.6727 - val_accuracy: 0.6000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6977 - accuracy: 0.4259 - val_loss: 0.6738 - val_accuracy: 0.6000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6955 - accuracy: 0.4259 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6934 - accuracy: 0.4259 - val_loss: 0.6761 - val_accuracy: 0.6000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6914 - accuracy: 0.4259 - val_loss: 0.6773 - val_accuracy: 0.6000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6895 - accuracy: 0.4259 - val_loss: 0.6786 - val_accuracy: 0.6000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6877 - accuracy: 0.4259 - val_loss: 0.6799 - val_accuracy: 0.6000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6860 - accuracy: 0.4259 - val_loss: 0.6812 - val_accuracy: 0.6500\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6844 - accuracy: 0.5370 - val_loss: 0.6826 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6829 - accuracy: 0.9815 - val_loss: 0.6840 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6815 - accuracy: 1.0000 - val_loss: 0.6854 - val_accuracy: 0.5500\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6802 - accuracy: 0.8333 - val_loss: 0.6868 - val_accuracy: 0.4000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6789 - accuracy: 0.5741 - val_loss: 0.6883 - val_accuracy: 0.4000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6777 - accuracy: 0.5741 - val_loss: 0.6897 - val_accuracy: 0.4000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6766 - accuracy: 0.5741 - val_loss: 0.6911 - val_accuracy: 0.4000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6756 - accuracy: 0.5741 - val_loss: 0.6924 - val_accuracy: 0.4000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6746 - accuracy: 0.5741 - val_loss: 0.6938 - val_accuracy: 0.4000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6737 - accuracy: 0.5741 - val_loss: 0.6951 - val_accuracy: 0.4000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6728 - accuracy: 0.5741 - val_loss: 0.6964 - val_accuracy: 0.4000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6720 - accuracy: 0.5741 - val_loss: 0.6976 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6924 - accuracy: 0.4231\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 821ms/step - loss: 0.6887 - accuracy: 0.5094 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6627 - accuracy: 0.5660 - val_loss: 0.6700 - val_accuracy: 0.5500\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6374 - accuracy: 0.6792 - val_loss: 0.6484 - val_accuracy: 0.6000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6129 - accuracy: 0.7358 - val_loss: 0.6272 - val_accuracy: 0.7000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5889 - accuracy: 0.7736 - val_loss: 0.6065 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5658 - accuracy: 0.8302 - val_loss: 0.5864 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5434 - accuracy: 0.8491 - val_loss: 0.5670 - val_accuracy: 0.8500\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5218 - accuracy: 0.8868 - val_loss: 0.5480 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5010 - accuracy: 0.9245 - val_loss: 0.5297 - val_accuracy: 0.8500\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4810 - accuracy: 0.9245 - val_loss: 0.5120 - val_accuracy: 0.8500\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4616 - accuracy: 0.9623 - val_loss: 0.4948 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4431 - accuracy: 0.9623 - val_loss: 0.4782 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4253 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.9500\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4082 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9500\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3919 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3762 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3613 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3470 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3333 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3202 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3198 - accuracy: 0.9630\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.8177 - accuracy: 0.0000e+00 - val_loss: 0.7784 - val_accuracy: 0.0500\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.7896 - accuracy: 0.0000e+00 - val_loss: 0.7539 - val_accuracy: 0.2000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7625 - accuracy: 0.0377 - val_loss: 0.7300 - val_accuracy: 0.3500\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7361 - accuracy: 0.1321 - val_loss: 0.7067 - val_accuracy: 0.4000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7106 - accuracy: 0.3774 - val_loss: 0.6839 - val_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6859 - accuracy: 0.5660 - val_loss: 0.6618 - val_accuracy: 0.7000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.6619 - accuracy: 0.6981 - val_loss: 0.6405 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6387 - accuracy: 0.7736 - val_loss: 0.6198 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6164 - accuracy: 0.8491 - val_loss: 0.5999 - val_accuracy: 0.8500\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5949 - accuracy: 0.9434 - val_loss: 0.5806 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5741 - accuracy: 0.9623 - val_loss: 0.5620 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5541 - accuracy: 0.9623 - val_loss: 0.5439 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5347 - accuracy: 0.9811 - val_loss: 0.5265 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5162 - accuracy: 0.9811 - val_loss: 0.5098 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4982 - accuracy: 0.9811 - val_loss: 0.4938 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4811 - accuracy: 0.9811 - val_loss: 0.4782 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4644 - accuracy: 0.9811 - val_loss: 0.4634 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4486 - accuracy: 0.9811 - val_loss: 0.4490 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4332 - accuracy: 0.9811 - val_loss: 0.4352 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4184 - accuracy: 0.9811 - val_loss: 0.4219 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4383 - accuracy: 1.0000\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 0.5083 - accuracy: 0.9815 - val_loss: 0.4723 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4917 - accuracy: 0.9815 - val_loss: 0.4602 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4756 - accuracy: 0.9815 - val_loss: 0.4483 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4599 - accuracy: 0.9815 - val_loss: 0.4367 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4446 - accuracy: 0.9815 - val_loss: 0.4255 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4299 - accuracy: 0.9815 - val_loss: 0.4145 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4156 - accuracy: 0.9815 - val_loss: 0.4039 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4017 - accuracy: 0.9815 - val_loss: 0.3935 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3883 - accuracy: 0.9815 - val_loss: 0.3834 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3753 - accuracy: 0.9815 - val_loss: 0.3736 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3628 - accuracy: 0.9815 - val_loss: 0.3640 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3506 - accuracy: 0.9815 - val_loss: 0.3546 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3389 - accuracy: 0.9815 - val_loss: 0.3455 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3275 - accuracy: 0.9815 - val_loss: 0.3366 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3166 - accuracy: 0.9815 - val_loss: 0.3279 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3061 - accuracy: 0.9815 - val_loss: 0.3194 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2959 - accuracy: 0.9815 - val_loss: 0.3112 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2861 - accuracy: 0.9815 - val_loss: 0.3032 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2767 - accuracy: 0.9815 - val_loss: 0.2953 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2676 - accuracy: 0.9815 - val_loss: 0.2876 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2476 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 829ms/step - loss: 0.7121 - accuracy: 0.3585 - val_loss: 0.6877 - val_accuracy: 0.6000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7039 - accuracy: 0.4151 - val_loss: 0.6811 - val_accuracy: 0.6000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6960 - accuracy: 0.4151 - val_loss: 0.6747 - val_accuracy: 0.6000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6883 - accuracy: 0.4340 - val_loss: 0.6686 - val_accuracy: 0.6500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6807 - accuracy: 0.4340 - val_loss: 0.6627 - val_accuracy: 0.6500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6734 - accuracy: 0.4528 - val_loss: 0.6570 - val_accuracy: 0.7000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6663 - accuracy: 0.4906 - val_loss: 0.6514 - val_accuracy: 0.7000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6594 - accuracy: 0.5094 - val_loss: 0.6461 - val_accuracy: 0.7000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6527 - accuracy: 0.5472 - val_loss: 0.6407 - val_accuracy: 0.7000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6463 - accuracy: 0.5849 - val_loss: 0.6354 - val_accuracy: 0.7000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6399 - accuracy: 0.6415 - val_loss: 0.6302 - val_accuracy: 0.7000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6335 - accuracy: 0.6415 - val_loss: 0.6250 - val_accuracy: 0.7000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6273 - accuracy: 0.6604 - val_loss: 0.6199 - val_accuracy: 0.7500\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6209 - accuracy: 0.6604 - val_loss: 0.6145 - val_accuracy: 0.7500\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6147 - accuracy: 0.6792 - val_loss: 0.6091 - val_accuracy: 0.7000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6083 - accuracy: 0.6981 - val_loss: 0.6038 - val_accuracy: 0.7000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6020 - accuracy: 0.7170 - val_loss: 0.5985 - val_accuracy: 0.7000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5957 - accuracy: 0.7358 - val_loss: 0.5932 - val_accuracy: 0.7000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5892 - accuracy: 0.7547 - val_loss: 0.5879 - val_accuracy: 0.7500\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5827 - accuracy: 0.8302 - val_loss: 0.5825 - val_accuracy: 0.8000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5762 - accuracy: 0.8491 - val_loss: 0.5771 - val_accuracy: 0.8000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5696 - accuracy: 0.8679 - val_loss: 0.5715 - val_accuracy: 0.9000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5631 - accuracy: 0.8868 - val_loss: 0.5660 - val_accuracy: 0.9000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5566 - accuracy: 0.9245 - val_loss: 0.5602 - val_accuracy: 0.9000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5498 - accuracy: 0.9623 - val_loss: 0.5542 - val_accuracy: 0.9000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5430 - accuracy: 0.9623 - val_loss: 0.5481 - val_accuracy: 0.9000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5362 - accuracy: 0.9811 - val_loss: 0.5419 - val_accuracy: 0.9000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5293 - accuracy: 0.9811 - val_loss: 0.5357 - val_accuracy: 0.9000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5223 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.9000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5149 - accuracy: 1.0000 - val_loss: 0.5229 - val_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5201 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 0.6504 - accuracy: 0.4340 - val_loss: 0.6342 - val_accuracy: 0.4000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6456 - accuracy: 0.4340 - val_loss: 0.6300 - val_accuracy: 0.4000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6407 - accuracy: 0.4340 - val_loss: 0.6259 - val_accuracy: 0.4000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6357 - accuracy: 0.4340 - val_loss: 0.6218 - val_accuracy: 0.4000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6309 - accuracy: 0.4340 - val_loss: 0.6177 - val_accuracy: 0.4000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6262 - accuracy: 0.4340 - val_loss: 0.6135 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6216 - accuracy: 0.4340 - val_loss: 0.6094 - val_accuracy: 0.5500\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6169 - accuracy: 0.4528 - val_loss: 0.6052 - val_accuracy: 0.6000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6123 - accuracy: 0.5283 - val_loss: 0.6011 - val_accuracy: 0.6500\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6079 - accuracy: 0.6226 - val_loss: 0.5971 - val_accuracy: 0.6500\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6036 - accuracy: 0.6792 - val_loss: 0.5931 - val_accuracy: 0.7000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5993 - accuracy: 0.7547 - val_loss: 0.5892 - val_accuracy: 0.8000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5950 - accuracy: 0.8113 - val_loss: 0.5854 - val_accuracy: 0.9000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5908 - accuracy: 0.9057 - val_loss: 0.5816 - val_accuracy: 0.9000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5868 - accuracy: 0.9245 - val_loss: 0.5779 - val_accuracy: 0.9000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5829 - accuracy: 0.9245 - val_loss: 0.5742 - val_accuracy: 0.9000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5792 - accuracy: 0.9245 - val_loss: 0.5706 - val_accuracy: 0.9000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5755 - accuracy: 0.9434 - val_loss: 0.5670 - val_accuracy: 0.9500\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5718 - accuracy: 0.9434 - val_loss: 0.5634 - val_accuracy: 0.9500\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5681 - accuracy: 0.9434 - val_loss: 0.5598 - val_accuracy: 0.9500\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5644 - accuracy: 0.9623 - val_loss: 0.5562 - val_accuracy: 0.9500\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5607 - accuracy: 0.9623 - val_loss: 0.5526 - val_accuracy: 0.9500\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5569 - accuracy: 0.9623 - val_loss: 0.5490 - val_accuracy: 0.9500\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5531 - accuracy: 0.9623 - val_loss: 0.5453 - val_accuracy: 0.9500\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5492 - accuracy: 0.9623 - val_loss: 0.5417 - val_accuracy: 0.9500\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5453 - accuracy: 0.9623 - val_loss: 0.5380 - val_accuracy: 0.9500\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5414 - accuracy: 0.9623 - val_loss: 0.5344 - val_accuracy: 0.9500\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5374 - accuracy: 0.9623 - val_loss: 0.5307 - val_accuracy: 0.9500\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5335 - accuracy: 0.9623 - val_loss: 0.5271 - val_accuracy: 0.9500\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5295 - accuracy: 0.9623 - val_loss: 0.5234 - val_accuracy: 0.9500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4438 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 811ms/step - loss: 0.6588 - accuracy: 0.7037 - val_loss: 0.6423 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6501 - accuracy: 0.7222 - val_loss: 0.6348 - val_accuracy: 0.7500\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6416 - accuracy: 0.8148 - val_loss: 0.6274 - val_accuracy: 0.7500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6332 - accuracy: 0.8333 - val_loss: 0.6197 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6249 - accuracy: 0.8333 - val_loss: 0.6121 - val_accuracy: 0.7500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6166 - accuracy: 0.8519 - val_loss: 0.6045 - val_accuracy: 0.8000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6084 - accuracy: 0.8704 - val_loss: 0.5968 - val_accuracy: 0.9000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6002 - accuracy: 0.8704 - val_loss: 0.5891 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5920 - accuracy: 0.8704 - val_loss: 0.5818 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5836 - accuracy: 0.8704 - val_loss: 0.5746 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5750 - accuracy: 0.8704 - val_loss: 0.5672 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5666 - accuracy: 0.8704 - val_loss: 0.5598 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5582 - accuracy: 0.8889 - val_loss: 0.5524 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5500 - accuracy: 0.8889 - val_loss: 0.5454 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5418 - accuracy: 0.8889 - val_loss: 0.5385 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5337 - accuracy: 0.8889 - val_loss: 0.5315 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5257 - accuracy: 0.8889 - val_loss: 0.5246 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5177 - accuracy: 0.9074 - val_loss: 0.5177 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5098 - accuracy: 0.9074 - val_loss: 0.5106 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5021 - accuracy: 0.9074 - val_loss: 0.5036 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4944 - accuracy: 0.9074 - val_loss: 0.4966 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4867 - accuracy: 0.9444 - val_loss: 0.4896 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4791 - accuracy: 0.9444 - val_loss: 0.4825 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4716 - accuracy: 0.9444 - val_loss: 0.4756 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4643 - accuracy: 0.9444 - val_loss: 0.4686 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4568 - accuracy: 0.9444 - val_loss: 0.4616 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4493 - accuracy: 0.9444 - val_loss: 0.4546 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4420 - accuracy: 0.9444 - val_loss: 0.4472 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4345 - accuracy: 0.9815 - val_loss: 0.4399 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4271 - accuracy: 0.9815 - val_loss: 0.4326 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.3921 - accuracy: 1.0000\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.6994 - accuracy: 0.4340 - val_loss: 0.6865 - val_accuracy: 0.6000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6979 - accuracy: 0.4340 - val_loss: 0.6877 - val_accuracy: 0.6000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6965 - accuracy: 0.4340 - val_loss: 0.6888 - val_accuracy: 0.6000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6952 - accuracy: 0.4340 - val_loss: 0.6901 - val_accuracy: 0.6000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6939 - accuracy: 0.4340 - val_loss: 0.6913 - val_accuracy: 0.6500\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6927 - accuracy: 0.4528 - val_loss: 0.6926 - val_accuracy: 0.6000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6916 - accuracy: 0.6981 - val_loss: 0.6940 - val_accuracy: 0.4000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6905 - accuracy: 0.5660 - val_loss: 0.6954 - val_accuracy: 0.4000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6894 - accuracy: 0.5660 - val_loss: 0.6968 - val_accuracy: 0.4000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6884 - accuracy: 0.5660 - val_loss: 0.6983 - val_accuracy: 0.4000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6875 - accuracy: 0.5660 - val_loss: 0.6998 - val_accuracy: 0.4000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6866 - accuracy: 0.5660 - val_loss: 0.7012 - val_accuracy: 0.4000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6858 - accuracy: 0.5660 - val_loss: 0.7027 - val_accuracy: 0.4000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6851 - accuracy: 0.5660 - val_loss: 0.7042 - val_accuracy: 0.4000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6844 - accuracy: 0.5660 - val_loss: 0.7057 - val_accuracy: 0.4000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6837 - accuracy: 0.5660 - val_loss: 0.7072 - val_accuracy: 0.4000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6831 - accuracy: 0.5660 - val_loss: 0.7087 - val_accuracy: 0.4000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6826 - accuracy: 0.5660 - val_loss: 0.7101 - val_accuracy: 0.4000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6820 - accuracy: 0.5660 - val_loss: 0.7115 - val_accuracy: 0.4000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6815 - accuracy: 0.5660 - val_loss: 0.7128 - val_accuracy: 0.4000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6811 - accuracy: 0.5660 - val_loss: 0.7141 - val_accuracy: 0.4000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6807 - accuracy: 0.5660 - val_loss: 0.7153 - val_accuracy: 0.4000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6803 - accuracy: 0.5660 - val_loss: 0.7165 - val_accuracy: 0.4000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6799 - accuracy: 0.5660 - val_loss: 0.7175 - val_accuracy: 0.4000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6795 - accuracy: 0.5660 - val_loss: 0.7185 - val_accuracy: 0.4000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6792 - accuracy: 0.5660 - val_loss: 0.7194 - val_accuracy: 0.4000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6789 - accuracy: 0.5660 - val_loss: 0.7202 - val_accuracy: 0.4000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6785 - accuracy: 0.5660 - val_loss: 0.7210 - val_accuracy: 0.4000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6782 - accuracy: 0.5660 - val_loss: 0.7216 - val_accuracy: 0.4000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6779 - accuracy: 0.5660 - val_loss: 0.7221 - val_accuracy: 0.4000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6776 - accuracy: 0.5660 - val_loss: 0.7226 - val_accuracy: 0.4000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6773 - accuracy: 0.5660 - val_loss: 0.7229 - val_accuracy: 0.4000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6770 - accuracy: 0.5660 - val_loss: 0.7232 - val_accuracy: 0.4000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6766 - accuracy: 0.5660 - val_loss: 0.7233 - val_accuracy: 0.4000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6763 - accuracy: 0.5660 - val_loss: 0.7234 - val_accuracy: 0.4000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6760 - accuracy: 0.5660 - val_loss: 0.7234 - val_accuracy: 0.4000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6756 - accuracy: 0.5660 - val_loss: 0.7233 - val_accuracy: 0.4000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6753 - accuracy: 0.5660 - val_loss: 0.7232 - val_accuracy: 0.4000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6749 - accuracy: 0.5660 - val_loss: 0.7230 - val_accuracy: 0.4000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6745 - accuracy: 0.5660 - val_loss: 0.7227 - val_accuracy: 0.4000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6742 - accuracy: 0.5660 - val_loss: 0.7223 - val_accuracy: 0.4000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6738 - accuracy: 0.5660 - val_loss: 0.7219 - val_accuracy: 0.4000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6734 - accuracy: 0.5660 - val_loss: 0.7215 - val_accuracy: 0.4000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6730 - accuracy: 0.5660 - val_loss: 0.7210 - val_accuracy: 0.4000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6726 - accuracy: 0.5660 - val_loss: 0.7205 - val_accuracy: 0.4000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6721 - accuracy: 0.5660 - val_loss: 0.7199 - val_accuracy: 0.4000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6717 - accuracy: 0.5660 - val_loss: 0.7193 - val_accuracy: 0.4000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6713 - accuracy: 0.5660 - val_loss: 0.7187 - val_accuracy: 0.4000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6708 - accuracy: 0.5660 - val_loss: 0.7180 - val_accuracy: 0.4000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6704 - accuracy: 0.5660 - val_loss: 0.7174 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7031 - accuracy: 0.4444\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 0.6851 - accuracy: 0.5660 - val_loss: 0.6777 - val_accuracy: 0.6000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6849 - accuracy: 0.5660 - val_loss: 0.6771 - val_accuracy: 0.6000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6846 - accuracy: 0.5660 - val_loss: 0.6766 - val_accuracy: 0.6000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6844 - accuracy: 0.5660 - val_loss: 0.6762 - val_accuracy: 0.6000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6842 - accuracy: 0.5660 - val_loss: 0.6758 - val_accuracy: 0.6000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6841 - accuracy: 0.5660 - val_loss: 0.6754 - val_accuracy: 0.6000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6839 - accuracy: 0.5660 - val_loss: 0.6750 - val_accuracy: 0.6000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6838 - accuracy: 0.5660 - val_loss: 0.6748 - val_accuracy: 0.6000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6836 - accuracy: 0.5660 - val_loss: 0.6745 - val_accuracy: 0.6000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6835 - accuracy: 0.5660 - val_loss: 0.6743 - val_accuracy: 0.6000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6833 - accuracy: 0.5660 - val_loss: 0.6741 - val_accuracy: 0.6000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6832 - accuracy: 0.5660 - val_loss: 0.6739 - val_accuracy: 0.6000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6830 - accuracy: 0.5660 - val_loss: 0.6737 - val_accuracy: 0.6000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6829 - accuracy: 0.5660 - val_loss: 0.6735 - val_accuracy: 0.6000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6827 - accuracy: 0.5660 - val_loss: 0.6734 - val_accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6825 - accuracy: 0.5660 - val_loss: 0.6733 - val_accuracy: 0.6000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6824 - accuracy: 0.5660 - val_loss: 0.6732 - val_accuracy: 0.6000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6822 - accuracy: 0.5660 - val_loss: 0.6730 - val_accuracy: 0.6000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6820 - accuracy: 0.5660 - val_loss: 0.6729 - val_accuracy: 0.6000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6819 - accuracy: 0.5660 - val_loss: 0.6728 - val_accuracy: 0.6000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6817 - accuracy: 0.5660 - val_loss: 0.6727 - val_accuracy: 0.6000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6815 - accuracy: 0.5660 - val_loss: 0.6726 - val_accuracy: 0.6000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6813 - accuracy: 0.5660 - val_loss: 0.6725 - val_accuracy: 0.6000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6812 - accuracy: 0.5660 - val_loss: 0.6723 - val_accuracy: 0.6000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6810 - accuracy: 0.5660 - val_loss: 0.6722 - val_accuracy: 0.6000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6808 - accuracy: 0.5660 - val_loss: 0.6720 - val_accuracy: 0.6000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6806 - accuracy: 0.5660 - val_loss: 0.6719 - val_accuracy: 0.6000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6804 - accuracy: 0.5660 - val_loss: 0.6717 - val_accuracy: 0.6000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6802 - accuracy: 0.5660 - val_loss: 0.6715 - val_accuracy: 0.6000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6800 - accuracy: 0.5660 - val_loss: 0.6713 - val_accuracy: 0.6000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6798 - accuracy: 0.5660 - val_loss: 0.6711 - val_accuracy: 0.6000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6795 - accuracy: 0.5660 - val_loss: 0.6708 - val_accuracy: 0.6000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6793 - accuracy: 0.5660 - val_loss: 0.6706 - val_accuracy: 0.6000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6791 - accuracy: 0.5660 - val_loss: 0.6703 - val_accuracy: 0.6000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6788 - accuracy: 0.5660 - val_loss: 0.6700 - val_accuracy: 0.6000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6786 - accuracy: 0.5660 - val_loss: 0.6698 - val_accuracy: 0.6000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6783 - accuracy: 0.5660 - val_loss: 0.6695 - val_accuracy: 0.6000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6780 - accuracy: 0.5660 - val_loss: 0.6692 - val_accuracy: 0.6000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6778 - accuracy: 0.5660 - val_loss: 0.6689 - val_accuracy: 0.6000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6775 - accuracy: 0.5660 - val_loss: 0.6686 - val_accuracy: 0.6000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6772 - accuracy: 0.5660 - val_loss: 0.6683 - val_accuracy: 0.6000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6769 - accuracy: 0.5660 - val_loss: 0.6680 - val_accuracy: 0.6000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6766 - accuracy: 0.5660 - val_loss: 0.6677 - val_accuracy: 0.6000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6763 - accuracy: 0.5660 - val_loss: 0.6673 - val_accuracy: 0.6000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6759 - accuracy: 0.5660 - val_loss: 0.6670 - val_accuracy: 0.6000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6756 - accuracy: 0.5660 - val_loss: 0.6667 - val_accuracy: 0.6000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6752 - accuracy: 0.5660 - val_loss: 0.6663 - val_accuracy: 0.6000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6749 - accuracy: 0.5660 - val_loss: 0.6660 - val_accuracy: 0.6000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6745 - accuracy: 0.5660 - val_loss: 0.6656 - val_accuracy: 0.6000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6741 - accuracy: 0.5660 - val_loss: 0.6652 - val_accuracy: 0.6000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7456 - accuracy: 0.2963\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6893 - accuracy: 0.5185 - val_loss: 0.6890 - val_accuracy: 0.9000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6879 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.4000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6865 - accuracy: 0.5741 - val_loss: 0.6922 - val_accuracy: 0.4000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6852 - accuracy: 0.5741 - val_loss: 0.6939 - val_accuracy: 0.4000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6840 - accuracy: 0.5741 - val_loss: 0.6956 - val_accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6828 - accuracy: 0.5741 - val_loss: 0.6973 - val_accuracy: 0.4000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6817 - accuracy: 0.5741 - val_loss: 0.6991 - val_accuracy: 0.4000\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6807 - accuracy: 0.5741 - val_loss: 0.7009 - val_accuracy: 0.4000\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6798 - accuracy: 0.5741 - val_loss: 0.7027 - val_accuracy: 0.4000\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6789 - accuracy: 0.5741 - val_loss: 0.7044 - val_accuracy: 0.4000\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6781 - accuracy: 0.5741 - val_loss: 0.7062 - val_accuracy: 0.4000\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6774 - accuracy: 0.5741 - val_loss: 0.7079 - val_accuracy: 0.4000\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6767 - accuracy: 0.5741 - val_loss: 0.7095 - val_accuracy: 0.4000\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6760 - accuracy: 0.5741 - val_loss: 0.7112 - val_accuracy: 0.4000\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6754 - accuracy: 0.5741 - val_loss: 0.7127 - val_accuracy: 0.4000\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6749 - accuracy: 0.5741 - val_loss: 0.7141 - val_accuracy: 0.4000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6744 - accuracy: 0.5741 - val_loss: 0.7155 - val_accuracy: 0.4000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6739 - accuracy: 0.5741 - val_loss: 0.7167 - val_accuracy: 0.4000\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6734 - accuracy: 0.5741 - val_loss: 0.7178 - val_accuracy: 0.4000\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6730 - accuracy: 0.5741 - val_loss: 0.7188 - val_accuracy: 0.4000\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6725 - accuracy: 0.5741 - val_loss: 0.7197 - val_accuracy: 0.4000\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6721 - accuracy: 0.5741 - val_loss: 0.7204 - val_accuracy: 0.4000\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6717 - accuracy: 0.5741 - val_loss: 0.7211 - val_accuracy: 0.4000\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6713 - accuracy: 0.5741 - val_loss: 0.7216 - val_accuracy: 0.4000\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6708 - accuracy: 0.5741 - val_loss: 0.7219 - val_accuracy: 0.4000\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6704 - accuracy: 0.5741 - val_loss: 0.7222 - val_accuracy: 0.4000\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6700 - accuracy: 0.5741 - val_loss: 0.7223 - val_accuracy: 0.4000\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6695 - accuracy: 0.5741 - val_loss: 0.7223 - val_accuracy: 0.4000\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6691 - accuracy: 0.5741 - val_loss: 0.7222 - val_accuracy: 0.4000\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6687 - accuracy: 0.5741 - val_loss: 0.7219 - val_accuracy: 0.4000\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6682 - accuracy: 0.5741 - val_loss: 0.7216 - val_accuracy: 0.4000\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6677 - accuracy: 0.5741 - val_loss: 0.7212 - val_accuracy: 0.4000\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6672 - accuracy: 0.5741 - val_loss: 0.7207 - val_accuracy: 0.4000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6667 - accuracy: 0.5741 - val_loss: 0.7202 - val_accuracy: 0.4000\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6663 - accuracy: 0.5741 - val_loss: 0.7195 - val_accuracy: 0.4000\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6657 - accuracy: 0.5741 - val_loss: 0.7188 - val_accuracy: 0.4000\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6652 - accuracy: 0.5741 - val_loss: 0.7181 - val_accuracy: 0.4000\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6647 - accuracy: 0.5741 - val_loss: 0.7173 - val_accuracy: 0.4000\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6642 - accuracy: 0.5741 - val_loss: 0.7165 - val_accuracy: 0.4000\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6636 - accuracy: 0.5741 - val_loss: 0.7157 - val_accuracy: 0.4000\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6631 - accuracy: 0.5741 - val_loss: 0.7148 - val_accuracy: 0.4000\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6625 - accuracy: 0.5741 - val_loss: 0.7139 - val_accuracy: 0.4000\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6619 - accuracy: 0.5741 - val_loss: 0.7130 - val_accuracy: 0.4000\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6613 - accuracy: 0.5741 - val_loss: 0.7121 - val_accuracy: 0.4000\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6608 - accuracy: 0.5741 - val_loss: 0.7112 - val_accuracy: 0.4000\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6602 - accuracy: 0.5741 - val_loss: 0.7103 - val_accuracy: 0.4000\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6596 - accuracy: 0.5741 - val_loss: 0.7094 - val_accuracy: 0.4000\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6589 - accuracy: 0.5741 - val_loss: 0.7085 - val_accuracy: 0.4000\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6583 - accuracy: 0.5741 - val_loss: 0.7076 - val_accuracy: 0.4000\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6577 - accuracy: 0.5741 - val_loss: 0.7068 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6972 - accuracy: 0.4231\n",
      "Epoch 1/200\n",
      "1/1 [==============================] - 1s 834ms/step - loss: 0.6908 - accuracy: 0.5250 - val_loss: 0.6500 - val_accuracy: 0.7000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6679 - accuracy: 0.6625 - val_loss: 0.6313 - val_accuracy: 0.7000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6454 - accuracy: 0.7500 - val_loss: 0.6131 - val_accuracy: 0.7500\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6237 - accuracy: 0.8375 - val_loss: 0.5952 - val_accuracy: 0.9000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6022 - accuracy: 0.8750 - val_loss: 0.5779 - val_accuracy: 0.9000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5816 - accuracy: 0.9000 - val_loss: 0.5610 - val_accuracy: 0.9000\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5615 - accuracy: 0.9375 - val_loss: 0.5444 - val_accuracy: 0.9500\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5420 - accuracy: 0.9750 - val_loss: 0.5283 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5231 - accuracy: 0.9750 - val_loss: 0.5128 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5049 - accuracy: 0.9875 - val_loss: 0.4976 - val_accuracy: 1.0000\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4873 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4703 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4540 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4381 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4228 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4080 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 1.0000\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3939 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3802 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3670 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 1.0000\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3545 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 1.0000\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3424 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3308 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3196 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3090 - accuracy: 1.0000 - val_loss: 0.3231 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2988 - accuracy: 1.0000 - val_loss: 0.3135 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2890 - accuracy: 1.0000 - val_loss: 0.3042 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2797 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2706 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2622 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2540 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2461 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2387 - accuracy: 1.0000 - val_loss: 0.2559 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2316 - accuracy: 1.0000 - val_loss: 0.2491 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2247 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2182 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2120 - accuracy: 1.0000 - val_loss: 0.2303 - val_accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2061 - accuracy: 1.0000 - val_loss: 0.2245 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2004 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1949 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1897 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1847 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1800 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1754 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1710 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1669 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1628 - accuracy: 1.0000 - val_loss: 0.1832 - val_accuracy: 1.0000\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1590 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1553 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 1.0000\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1518 - accuracy: 1.0000 - val_loss: 0.1725 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1483 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1451 - accuracy: 1.0000 - val_loss: 0.1660 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1420 - accuracy: 1.0000 - val_loss: 0.1630 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1389 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1360 - accuracy: 1.0000 - val_loss: 0.1572 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 0.1544 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.1518 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1279 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1207 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1184 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1163 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1141 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1121 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1102 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1082 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1029 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0980 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0964 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0949 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0920 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0880 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0855 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0843 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0831 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0819 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0808 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0797 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0786 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0746 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0736 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0727 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0700 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0691 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0643 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0551 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0533 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.0675 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.0669 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0507 - accuracy: 1.0000 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0502 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0483 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0440 - accuracy: 1.0000 - val_loss: 0.0583 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0407 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0384 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0352 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 0.7284 - accuracy: 0.0769\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.7267 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 0.7474 - accuracy: 0.1538\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.7045 - accuracy: 0.2857\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 0.6844 - accuracy: 0.5714\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.6143 - accuracy: 0.5000\n",
      "Best: 1.000000 using {'learning_rate': 0.01, 'epochs': 200, 'batch_size': 128, 'activation': 'tanh'}\n",
      "0.790123 (0.246296) with: {'learning_rate': 0.1, 'epochs': 20, 'batch_size': 128, 'activation': 'relu'}\n",
      "1.000000 (0.000000) with: {'learning_rate': 0.01, 'epochs': 200, 'batch_size': 128, 'activation': 'tanh'}\n",
      "0.387939 (0.065386) with: {'learning_rate': 0.001, 'epochs': 40, 'batch_size': 32, 'activation': 'sigmoid'}\n",
      "1.000000 (0.000000) with: {'learning_rate': 0.001, 'epochs': 50, 'batch_size': 32, 'activation': 'relu'}\n",
      "0.950617 (0.069838) with: {'learning_rate': 0.1, 'epochs': 30, 'batch_size': 32, 'activation': 'relu'}\n",
      "1.000000 (0.000000) with: {'learning_rate': 0.001, 'epochs': 200, 'batch_size': 128, 'activation': 'sigmoid'}\n",
      "0.387939 (0.065386) with: {'learning_rate': 0.001, 'epochs': 30, 'batch_size': 256, 'activation': 'sigmoid'}\n",
      "0.987654 (0.017459) with: {'learning_rate': 0.1, 'epochs': 20, 'batch_size': 256, 'activation': 'tanh'}\n",
      "1.000000 (0.000000) with: {'learning_rate': 0.001, 'epochs': 30, 'batch_size': 128, 'activation': 'relu'}\n",
      "0.387939 (0.065386) with: {'learning_rate': 0.001, 'epochs': 50, 'batch_size': 256, 'activation': 'sigmoid'}\n",
      "WARNING:tensorflow:5 out of the last 204 calls to <function Model.make_test_function.<locals>.test_function at 0x0000024176D28670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24251affb80>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Import KerasClassifier from tensorflow.keras scikit learn wrappers\n",
    "from tensorflow.keras.wrappers.scikit_learn  import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Creates a model given an activation and learning rate\n",
    "def create_model(learning_rate = 0.1, activation = 'relu', optomizer = 'Adam'):\n",
    "    # Create an Adam optimizer with the given learning rate\n",
    "    # opt = optomizer(lr = learning_rate)\n",
    "  \t# Create model  \n",
    "    model = Sequential() \n",
    "    model.add(Dense(10, input_dim=4, activation=activation)) \n",
    "    model.add(Dense(20, activation=activation)) \n",
    "    model.add(Dense(10, activation=activation)) \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "  \t\n",
    "  \t# Compile your model with your optimizer, loss, and metrics\n",
    "    model.compile(optimizer = optomizer, loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a KerasClassifier\n",
    "model = KerasClassifier(build_fn = create_model)\n",
    "\n",
    "# Define the parameters to try out\n",
    "params = {\n",
    "    'activation': ['relu', 'tanh','sigmoid'], \n",
    "    'batch_size': [32, 128, 256], \n",
    "    'epochs': [20,30,40,50, 100, 200], \n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Create a randomize search cv object passing in the parameters to try\n",
    "random_search = RandomizedSearchCV(model, param_distributions = params, cv = KFold(3))\n",
    "h_callback = random_search.fit(x_train, y_train,validation_data=(x_test, y_test))\n",
    "# h_callback = random_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the accuracy score for each fold\n",
    "kfolds = cross_val_score(model, x_test, y_test, cv = 3)\n",
    "\n",
    "# Extract best parameters\n",
    "best_params = h_callback.best_params_\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (h_callback.best_score_, h_callback.best_params_))\n",
    "\n",
    "means = h_callback.cv_results_['mean_test_score']\n",
    "stds = h_callback.cv_results_['std_test_score']\n",
    "params = h_callback.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "# Build the model with best parameters\n",
    "model = create_model(optomizer = 'Adam', activation=best_params['activation'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, verbose=0,validation_data=(x_test, y_test))\n",
    "# Plot train vs test loss during training\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "# Plot train vs test accuracy during training\n",
    "plt.plot(history.history['val_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model with keras without hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:6 out of the last 207 calls to <function Model.make_train_function.<locals>.train_function at 0x0000024262C34040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/3 [=========>....................] - ETA: 1s - loss: 0.7610 - accuracy: 0.4375WARNING:tensorflow:5 out of the last 204 calls to <function Model.make_test_function.<locals>.test_function at 0x000002424B1E6700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 123ms/step - loss: 0.7380 - accuracy: 0.4625 - val_loss: 0.7157 - val_accuracy: 0.4000\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7075 - accuracy: 0.4625 - val_loss: 0.6886 - val_accuracy: 0.4500\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.6778 - accuracy: 0.4875 - val_loss: 0.6629 - val_accuracy: 0.5500\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.6505 - accuracy: 0.5500 - val_loss: 0.6381 - val_accuracy: 0.6500\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6238 - accuracy: 0.6125 - val_loss: 0.6141 - val_accuracy: 0.7000\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5978 - accuracy: 0.7250 - val_loss: 0.5907 - val_accuracy: 0.8500\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.5731 - accuracy: 0.9500 - val_loss: 0.5679 - val_accuracy: 0.9500\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.5487 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.9500\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.5254 - accuracy: 1.0000 - val_loss: 0.5246 - val_accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.5033 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.9500\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4812 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4600 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.4393 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4189 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.3991 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3806 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3623 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3443 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.3265 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3094 - accuracy: 1.0000 - val_loss: 0.3244 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3244 - accuracy: 1.0000\n",
      "\n",
      "accuracy: 100.00%\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "[0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_145 (Dense)           (None, 10)                50        \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 20)                220       \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 10)                210       \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create model \n",
    "model = Sequential() \n",
    "model.add(Dense(10, input_dim=4, activation='relu')) \n",
    "model.add(Dense(20, activation='relu')) \n",
    "model.add(Dense(10, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compile model \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# Train your model and save its history\n",
    "h_callback = model.fit(x_train, y_train, epochs = 20,\n",
    "               validation_data=(x_test, y_test))\n",
    "\n",
    "# Plot train vs test loss during training\n",
    "plt.plot(h_callback.history['val_loss'])\n",
    "\n",
    "# Plot train vs test accuracy during training\n",
    "plt.plot(h_callback.history['val_accuracy'])\n",
    "\n",
    "# eval model \n",
    "scores = model.evaluate(x_test, y_test) \n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# calculate predictions \n",
    "predictions = model.predict(x_test) \n",
    "\n",
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions] \n",
    "print(rounded) \n",
    "\n",
    "# Display a summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model using keras functional api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 9ms/step - loss: 0.5244 - accuracy: 0.9250\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2170 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1430 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0927 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0599 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0389 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0252 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2424fe1e190>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense \n",
    "from tensorflow.keras.models import Model \n",
    "\n",
    "# This returns a tensor \n",
    "inputs = Input(shape=(4,)) \n",
    "print(inputs)\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor \n",
    "x = Dense(64, activation='relu')(inputs) \n",
    "x = Dense(64, activation='relu')(x) \n",
    "predictions = Dense(1, activation='sigmoid')(x) \n",
    "\n",
    "# This creates a model that includes \n",
    "# the Input layer and three Dense layers \n",
    "model = Model(inputs=inputs, outputs=predictions) \n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "model.fit(x_train, y_train,epochs=10, batch_size=10)  # starts training "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
